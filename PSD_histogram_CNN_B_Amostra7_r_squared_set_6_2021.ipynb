{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_Amostra7_r_squared_set_6_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/PSD_histogram_CNN_B_Amostra7_r_squared_set_6_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4074687f-aa1a-4775-a902-27f45c82963a"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5bdf2a-adde-4810-b09a-6e19f64993e9"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903cb925-443e-455b-d06d-b369a6256cfd"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "a6820264-5e07-4fb9-bbf7-64eeeee42fe0"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[2] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421947cd-98e5-44da-a94f-07a6d75617e4"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN5MN5a_v4np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1085e4e1-0a3f-4b4e-a056-18186a4ff373"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     148  108.631126  110.287079  ...  123.307533  119.997818  121.616516\n",
            "1     169  149.173721  157.983795  ...  145.091263  102.499733   91.349915\n",
            "2     120   66.067780   64.335556  ...   95.597778   94.783340   93.358894\n",
            "3     160    0.000000    0.000000  ...   78.318123   74.573746   72.021873\n",
            "4     190   75.207863   81.320435  ...  100.571640   96.506470   99.855614\n",
            "5     152  111.671738  110.587944  ...  152.688354  152.710526  150.029083\n",
            "6     106   72.692780   73.147751  ...  180.989685  105.886444   73.162331\n",
            "7     109  137.937958  135.645905  ...   67.053360   66.770645   64.979546\n",
            "8     181  173.074463  176.576309  ...  110.482956  111.498062  118.578491\n",
            "9     102  126.689369  121.602089  ...  159.438309  159.318359  157.764328\n",
            "10    135  105.433075  105.885986  ...  121.334534  123.215179  127.546936\n",
            "11    184  144.961700  124.238647  ...  104.435715  103.202728  107.116249\n",
            "12    176  187.217453  213.706604  ...  134.574387  134.633774  126.522209\n",
            "13    151  219.399017  208.200470  ...  121.171524  122.863312  125.977112\n",
            "14    152   60.011772   58.042938  ...    9.856648    9.717451    8.376731\n",
            "15    171  150.306458  148.806976  ...  156.245804  160.027817  156.235870\n",
            "16    155   91.741325   96.769669  ...  133.980988  140.814362  145.882187\n",
            "17    177   81.695526   92.233040  ...   59.379734   57.327904   54.650448\n",
            "18    152   79.396812   81.789474  ...  138.966751  137.297089  135.064392\n",
            "19    167  171.202454  244.104752  ...  149.504471  146.366577  141.646729\n",
            "20    178  104.000641  111.917572  ...  146.061874  151.019714  151.098984\n",
            "21    117   64.952148   67.691719  ...   91.126373   44.801594   42.637665\n",
            "22    140   78.959999   79.040001  ...  125.199997  130.559998  136.720001\n",
            "23    186  169.413574  163.471405  ...    7.517748    7.447567    7.308360\n",
            "24    130   61.298702   62.451836  ...  138.375870  139.477875  142.350769\n",
            "25    136  160.621979  160.351212  ...  115.110725  110.920410  106.091698\n",
            "26    183   97.090355   99.456627  ...  135.816971  131.578964  118.313118\n",
            "27    110  136.204285  139.461823  ...  145.163635  129.536530  107.580154\n",
            "28    182    0.000000    0.000000  ...   42.840240    6.467456    0.786982\n",
            "29    121  109.508507  108.016953  ...  176.322861  187.671341  198.492737\n",
            "30    129    0.000000    0.000000  ...   78.030403   75.788895   73.694305\n",
            "31    152  125.773544  125.002075  ...  108.029770  106.522850  105.150970\n",
            "32    112  113.437500  115.437500  ...   90.000000  113.312500  120.875000\n",
            "33    163  140.880432  143.331406  ...   92.705597   94.794121   97.713470\n",
            "34    164  120.787033  123.405121  ...  139.208801  144.481842  144.825699\n",
            "35    130  113.414444  112.373970  ...  154.673126  158.326385  161.364975\n",
            "36    133   98.448746  101.673126  ...  141.149582  115.221611  123.703613\n",
            "37    162   43.122234   45.686787  ...  112.580246  114.377075  113.380577\n",
            "38    155  154.585297  168.058075  ...    8.735068    8.646452    9.126701\n",
            "39    158    0.000000    0.000000  ...  122.984138  121.459702  120.803070\n",
            "40    141  114.693024  118.900169  ...  107.033554  106.552338   81.132187\n",
            "41    164   80.167755   79.842361  ...  108.886375   96.844734   96.358124\n",
            "42    141  161.786133  167.963669  ...  105.064285  101.386047   98.422607\n",
            "43    123   98.855576  102.191162  ...   38.071983    7.497058    1.000000\n",
            "44    132  152.259872  143.045929  ...  122.977966  148.268158  150.508728\n",
            "45    132  126.922867  126.917374  ...  126.377411  132.902679  137.953171\n",
            "46    175   97.868805   86.150391  ...   84.457596   74.739197   73.702400\n",
            "47    153   97.453499   99.750229  ...    0.000000    0.000000    0.000000\n",
            "48    152  135.690445  138.288086  ...  163.873947  165.378113  177.756927\n",
            "49    132   70.269066   66.904503  ...  123.591370  120.879715  117.893486\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpQ1Pz0fX5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9b039c2f-79e4-42e4-c8e3-8cc06c955fbf"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "a09db0da-3882-4fb5-aed8-ae0b210d95c9"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "68f10322-c3df-4cbd-dfc5-922c6322ec51"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.5784 - accuracy: 0.7026 - val_loss: 0.6933 - val_accuracy: 0.4898\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.3510 - accuracy: 0.8280 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.1936 - accuracy: 0.9359 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.1837 - accuracy: 0.9329 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0965 - accuracy: 0.9738 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0855 - accuracy: 0.9592 - val_loss: 0.6933 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0558 - accuracy: 0.9825 - val_loss: 0.6945 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0671 - accuracy: 0.9708 - val_loss: 0.6935 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 0.6937 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0251 - accuracy: 0.9971 - val_loss: 0.6934 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.6938 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.6946 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 0.7011 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0099 - accuracy: 0.9942 - val_loss: 0.7029 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0054 - accuracy: 0.9971 - val_loss: 0.7002 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.6972 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 6.7271e-04 - accuracy: 1.0000 - val_loss: 0.7385 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 8.2210e-04 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8229 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 6.6061e-04 - accuracy: 1.0000 - val_loss: 0.8397 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 5.7490e-04 - accuracy: 1.0000 - val_loss: 0.8698 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8694 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0039 - accuracy: 0.9971 - val_loss: 1.1809 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0045 - accuracy: 0.9971 - val_loss: 0.8127 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 1.9976 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0176 - accuracy: 0.9883 - val_loss: 2.4812 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0736 - accuracy: 0.9825 - val_loss: 3.3504 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.1258 - accuracy: 0.9504 - val_loss: 1.5218 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0450 - accuracy: 0.9796 - val_loss: 10.3743 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0513 - accuracy: 0.9796 - val_loss: 13.0741 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0201 - accuracy: 0.9971 - val_loss: 14.9965 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 0.0410 - accuracy: 0.9854 - val_loss: 15.9985 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 17.3669 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 20.8178 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 19.3466 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 12.5161 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 11.2745 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 9.7222e-04 - accuracy: 1.0000 - val_loss: 11.0801 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 10.8218 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 9.0494e-04 - accuracy: 1.0000 - val_loss: 10.6120 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 8.4051e-04 - accuracy: 1.0000 - val_loss: 9.9856 - val_accuracy: 0.5102\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 8.0405e-04 - accuracy: 1.0000 - val_loss: 9.5510 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 8.4866e-04 - accuracy: 1.0000 - val_loss: 9.3540 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 6.9091e-04 - accuracy: 1.0000 - val_loss: 8.8082 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.6236e-04 - accuracy: 1.0000 - val_loss: 8.5935 - val_accuracy: 0.5102\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 8.4104e-04 - accuracy: 1.0000 - val_loss: 8.1302 - val_accuracy: 0.5102\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.6908e-04 - accuracy: 1.0000 - val_loss: 7.9200 - val_accuracy: 0.5102\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 5.5570e-04 - accuracy: 1.0000 - val_loss: 7.7071 - val_accuracy: 0.5102\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4.1726e-04 - accuracy: 1.0000 - val_loss: 7.4688 - val_accuracy: 0.5102\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.7548 - val_accuracy: 0.5102\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 3.3246e-04 - accuracy: 1.0000 - val_loss: 6.4103 - val_accuracy: 0.5102\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 7.0330e-04 - accuracy: 1.0000 - val_loss: 6.3283 - val_accuracy: 0.5102\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4.4980e-04 - accuracy: 1.0000 - val_loss: 6.4779 - val_accuracy: 0.5102\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 5.4841e-04 - accuracy: 1.0000 - val_loss: 6.8626 - val_accuracy: 0.5102\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.3611 - val_accuracy: 0.5102\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 5.2666e-04 - accuracy: 1.0000 - val_loss: 5.4476 - val_accuracy: 0.5102\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.8327e-04 - accuracy: 1.0000 - val_loss: 5.5719 - val_accuracy: 0.5102\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 3.5156e-04 - accuracy: 1.0000 - val_loss: 4.8226 - val_accuracy: 0.5102\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 4.1109e-04 - accuracy: 1.0000 - val_loss: 4.3049 - val_accuracy: 0.5102\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 4.0554e-04 - accuracy: 1.0000 - val_loss: 3.9440 - val_accuracy: 0.5102\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 3.0635e-04 - accuracy: 1.0000 - val_loss: 4.4427 - val_accuracy: 0.5102\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 6.3281e-04 - accuracy: 1.0000 - val_loss: 4.7670 - val_accuracy: 0.5102\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.4824e-04 - accuracy: 1.0000 - val_loss: 4.5227 - val_accuracy: 0.5102\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 2.8993e-04 - accuracy: 1.0000 - val_loss: 3.9616 - val_accuracy: 0.5102\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4.5031e-04 - accuracy: 1.0000 - val_loss: 2.9640 - val_accuracy: 0.5306\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 9.1720e-05 - accuracy: 1.0000 - val_loss: 2.0704 - val_accuracy: 0.5714\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 2.6827e-04 - accuracy: 1.0000 - val_loss: 1.0568 - val_accuracy: 0.7075\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.7767e-04 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.7619\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.3776e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8571\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 3.3935e-04 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.8912\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 2.0914e-04 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9252\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.9770e-04 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9592\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 6.4190e-05 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9592\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 2.5887e-04 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9796\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 3.6127e-04 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9660\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.8526e-04 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9456\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 9.3399e-05 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9524\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.8863e-04 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9524\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 1.3882e-04 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9456\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 7.7042e-05 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9592\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.6832e-04 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9388\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 9.8829e-05 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9320\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.5101e-04 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9592\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 9.8557e-05 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9796\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 5.4174e-04 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9592\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 3.9044e-04 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.8503\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.5439e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8231\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.6053e-04 - accuracy: 1.0000 - val_loss: 0.7310 - val_accuracy: 0.8231\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.3055e-04 - accuracy: 1.0000 - val_loss: 0.9091 - val_accuracy: 0.8095\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.8171e-04 - accuracy: 1.0000 - val_loss: 0.7874 - val_accuracy: 0.8231\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 3.0830e-04 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.8844\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 5.0107e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9116\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 7.2173e-05 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9116\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 1.4076e-04 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9388\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 9.4843e-05 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9456\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.7441e-04 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9252\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 9.3274e-05 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8776\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.5388e-04 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.8707\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 6.7219e-05 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.8776\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 3.8965e-05 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.8707\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.0744e-04 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.8707\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 5.2744e-04 - accuracy: 1.0000 - val_loss: 0.5597 - val_accuracy: 0.8776\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.7549e-04 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.8912\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 0.0043 - accuracy: 0.9971 - val_loss: 0.2662 - val_accuracy: 0.8571\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.0305 - accuracy: 0.9913 - val_loss: 27.1116 - val_accuracy: 0.5102\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 0.0886 - accuracy: 0.9767 - val_loss: 115.7489 - val_accuracy: 0.5102\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.0305 - accuracy: 0.9854 - val_loss: 350.3128 - val_accuracy: 0.5102\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 369.3996 - val_accuracy: 0.5102\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0214 - accuracy: 0.9913 - val_loss: 471.0090 - val_accuracy: 0.5102\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.0632 - accuracy: 0.9796 - val_loss: 750.9546 - val_accuracy: 0.5102\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.0396 - accuracy: 0.9942 - val_loss: 178.8316 - val_accuracy: 0.5102\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.0378 - accuracy: 0.9854 - val_loss: 324.1046 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 0.0524 - accuracy: 0.9796 - val_loss: 395.8932 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 168.7759 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0110 - accuracy: 0.9942 - val_loss: 147.6519 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 8.8046e-04 - accuracy: 1.0000 - val_loss: 131.8230 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 113.6253 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 103.9026 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 91.0096 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 78.6564 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 4.5433e-04 - accuracy: 1.0000 - val_loss: 70.1328 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 3.7569e-04 - accuracy: 1.0000 - val_loss: 61.5074 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 5.7977e-04 - accuracy: 1.0000 - val_loss: 54.7477 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 50.2733 - val_accuracy: 0.5102\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 47.0829 - val_accuracy: 0.5102\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 2.5631e-04 - accuracy: 1.0000 - val_loss: 46.4810 - val_accuracy: 0.5102\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.4627e-04 - accuracy: 1.0000 - val_loss: 42.7204 - val_accuracy: 0.5102\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 39.3760 - val_accuracy: 0.5102\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 5.1659e-04 - accuracy: 1.0000 - val_loss: 35.1068 - val_accuracy: 0.5102\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 3.5513e-04 - accuracy: 1.0000 - val_loss: 30.4720 - val_accuracy: 0.5102\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 1.9197e-04 - accuracy: 1.0000 - val_loss: 26.0659 - val_accuracy: 0.5102\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 5.9534e-04 - accuracy: 1.0000 - val_loss: 22.1704 - val_accuracy: 0.5102\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 1.4013e-04 - accuracy: 1.0000 - val_loss: 19.3796 - val_accuracy: 0.5102\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 3.4210e-04 - accuracy: 1.0000 - val_loss: 15.6957 - val_accuracy: 0.5102\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 2.2745e-04 - accuracy: 1.0000 - val_loss: 13.2147 - val_accuracy: 0.5102\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 6.5877e-04 - accuracy: 1.0000 - val_loss: 12.0319 - val_accuracy: 0.5102\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.3247e-04 - accuracy: 1.0000 - val_loss: 15.1570 - val_accuracy: 0.5102\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 3.2926e-04 - accuracy: 1.0000 - val_loss: 16.8558 - val_accuracy: 0.5102\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 1.4126e-04 - accuracy: 1.0000 - val_loss: 16.0564 - val_accuracy: 0.5102\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 9.2442e-05 - accuracy: 1.0000 - val_loss: 14.3979 - val_accuracy: 0.5102\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 2.3593e-04 - accuracy: 1.0000 - val_loss: 12.6911 - val_accuracy: 0.5102\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 3.1468e-04 - accuracy: 1.0000 - val_loss: 10.8994 - val_accuracy: 0.5102\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 4.0556e-04 - accuracy: 1.0000 - val_loss: 9.9182 - val_accuracy: 0.5102\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 1.7398e-04 - accuracy: 1.0000 - val_loss: 11.2556 - val_accuracy: 0.5102\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 3.4190e-04 - accuracy: 1.0000 - val_loss: 11.1829 - val_accuracy: 0.5102\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 6.9205e-04 - accuracy: 1.0000 - val_loss: 11.3362 - val_accuracy: 0.5102\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 7.1030e-04 - accuracy: 1.0000 - val_loss: 12.2869 - val_accuracy: 0.5102\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 2.0560e-04 - accuracy: 1.0000 - val_loss: 13.0777 - val_accuracy: 0.5102\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 1.1466e-04 - accuracy: 1.0000 - val_loss: 12.9818 - val_accuracy: 0.5102\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 8.7834e-05 - accuracy: 1.0000 - val_loss: 11.8487 - val_accuracy: 0.5102\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 2.6331e-04 - accuracy: 1.0000 - val_loss: 10.2103 - val_accuracy: 0.5102\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 1.1544e-04 - accuracy: 1.0000 - val_loss: 8.3896 - val_accuracy: 0.5102\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0736 - val_accuracy: 0.5170\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2865 - val_accuracy: 0.5442\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.7483\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 6.7243e-05 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.7823\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 2.8257e-04 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.6190\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 7.0173 - val_accuracy: 0.5102\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 13.9994 - val_accuracy: 0.5102\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 3.4766e-04 - accuracy: 1.0000 - val_loss: 15.4586 - val_accuracy: 0.5102\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 2.0960e-04 - accuracy: 1.0000 - val_loss: 14.2626 - val_accuracy: 0.5102\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 5.8236e-04 - accuracy: 1.0000 - val_loss: 12.4570 - val_accuracy: 0.5102\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 1.4896e-04 - accuracy: 1.0000 - val_loss: 10.7511 - val_accuracy: 0.5102\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 4.4262e-04 - accuracy: 1.0000 - val_loss: 10.3853 - val_accuracy: 0.5102\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 2s 179ms/step - loss: 6.2621e-05 - accuracy: 1.0000 - val_loss: 9.5699 - val_accuracy: 0.5102\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 9.9372e-05 - accuracy: 1.0000 - val_loss: 8.6907 - val_accuracy: 0.5102\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 2.2279e-04 - accuracy: 1.0000 - val_loss: 7.6515 - val_accuracy: 0.5102\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 2.3841e-04 - accuracy: 1.0000 - val_loss: 6.5234 - val_accuracy: 0.5102\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 1.5374e-04 - accuracy: 1.0000 - val_loss: 5.6127 - val_accuracy: 0.5102\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 4.7837e-05 - accuracy: 1.0000 - val_loss: 4.9486 - val_accuracy: 0.5102\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 8.3569e-05 - accuracy: 1.0000 - val_loss: 4.4214 - val_accuracy: 0.5102\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 2s 183ms/step - loss: 7.3593e-05 - accuracy: 1.0000 - val_loss: 3.8750 - val_accuracy: 0.5102\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 5.4044e-05 - accuracy: 1.0000 - val_loss: 3.3040 - val_accuracy: 0.5102\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 2.8373e-04 - accuracy: 1.0000 - val_loss: 3.9518 - val_accuracy: 0.5102\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 3.7774e-04 - accuracy: 1.0000 - val_loss: 3.5612 - val_accuracy: 0.5170\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.2012e-04 - accuracy: 1.0000 - val_loss: 2.9803 - val_accuracy: 0.5306\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 3.4537e-05 - accuracy: 1.0000 - val_loss: 2.4260 - val_accuracy: 0.5714\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 1.5265e-04 - accuracy: 1.0000 - val_loss: 1.9983 - val_accuracy: 0.5850\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 6.5751e-05 - accuracy: 1.0000 - val_loss: 1.4074 - val_accuracy: 0.6463\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 3.8791e-05 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.7551\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 1.1457e-04 - accuracy: 1.0000 - val_loss: 0.5798 - val_accuracy: 0.8095\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 4.4337e-05 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.8639\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 1.7819e-04 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9320\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 3.0492e-05 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9592\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 2.2134e-04 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9592\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 1.2972e-04 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9592\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 6.5066e-05 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9524\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 5.8657e-05 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlTCuKF-Alnh"
      },
      "source": [
        "#pred_test[0,0]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udwjTMHPA83h"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVeiPQLiA86E"
      },
      "source": [
        "#pred_test"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpf0XlSARX78",
        "outputId": "b3409015-dac4-4b55-8bad-cfa45031d488"
      },
      "source": [
        "pred_test= model.predict(X_test)\n",
        "Rows, Cols = pred_test.shape\n",
        "Prediction =[]\n",
        "for i in range(Rows):\n",
        "  if(pred_test[0,0] > pred_test[0,1]):\n",
        "    Prediction.append(0)\n",
        "  else:\n",
        "    Prediction.append(1)\n",
        "  \n",
        "\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': Prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   1\n",
            "Actual     \n",
            "0        72\n",
            "1        75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH"
      },
      "source": [
        "#pred_test"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QISvYcJBgWbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e306b17-affe-4f36-8c70-cf6eca441ac0"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[2] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  prediction_02 = model.predict(result)\n",
        "  Rows, Cols = prediction_02.shape\n",
        "  Prediction =[]\n",
        "  for i in range(Rows):\n",
        "    if(prediction_02[0,0] > prediction_02[0,1]):\n",
        "      Prediction.append(0)\n",
        "    else:\n",
        "      Prediction.append(1)\n",
        "  loc_grao =[];k=0\n",
        "  for i in Prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0   116.0   82.426872   81.253265  ...   95.807373   93.973839   92.532692\n",
            "1   101.0  149.404480  147.883057  ...  182.906311  189.642487  192.783157\n",
            "2   167.0   74.791176   89.491318  ...  125.241638  134.163757  132.242081\n",
            "3   173.0   20.077217   64.674896  ...   21.717396    1.858432    0.083163\n",
            "4   137.0  147.749359  147.697693  ...  129.996857  163.274170  176.036392\n",
            "5   127.0  124.327164   86.075081  ...   78.847168   94.698608  109.050156\n",
            "6   165.0  152.205734  143.723755  ...  100.066307  101.467590   99.861862\n",
            "7   193.0   33.291603  152.129852  ...  143.522263  158.534698  135.323029\n",
            "8   150.0   94.130661   67.596626  ...    9.340266    9.126223    9.843022\n",
            "9   107.0  129.420380  122.450348  ...  113.920959  113.933098  114.498917\n",
            "10  125.0  117.779465  117.548416  ...   59.843399   62.635777   66.501762\n",
            "11  159.0  124.301880  127.988045  ...   39.785213   34.298721   65.573189\n",
            "12  140.0  106.759995  111.040001  ...  186.440002  190.879990  190.919998\n",
            "13  131.0  128.327774  129.030640  ...  117.533234  120.610214  120.699600\n",
            "14  143.0   27.582815   27.223677  ...    9.058096    8.963617    8.717150\n",
            "15  189.0   93.554184  123.485596  ...    7.255145    7.331962    7.178327\n",
            "16  156.0   58.106510   44.546356  ...    0.000000    0.000000    0.000000\n",
            "17  131.0  229.725189  237.530197  ...  120.708115  121.840630  120.675896\n",
            "18  102.0  107.838150  118.655525  ...   98.506355  100.453293  103.309891\n",
            "19  172.0   91.472153   87.393723  ...    6.883181    6.372093    7.757707\n",
            "20  180.0   80.392097  118.645432  ...   90.736794   52.601486    1.554074\n",
            "21  177.0   91.450737   91.350052  ...  113.391983  112.200424  114.752426\n",
            "22  200.0  196.089600  161.533600  ...   88.056000   93.133995  104.372803\n",
            "23  130.0  120.227219  122.655151  ...   85.008530   73.028885   15.131125\n",
            "24  130.0   79.651367   81.901772  ...   50.047810   46.486153   35.519527\n",
            "25  156.0  131.047348  133.431305  ...  123.209732   96.305069   82.490471\n",
            "26  171.0  129.926270  128.401901  ...    7.891556    7.913580    8.156800\n",
            "27  198.0  147.717377  160.503006  ...  174.050705  153.410248  120.019585\n",
            "28  151.0  106.202271  105.115044  ...    5.239858    0.575106    0.045831\n",
            "29  149.0   76.024284   57.388725  ...    6.365164    6.249133    5.356200\n",
            "30  188.0   87.634224   67.683113  ...    0.000000    0.000000    0.000000\n",
            "31  105.0   61.973339   74.995560  ...    8.213334    7.964446    7.395556\n",
            "32  163.0   76.664864   76.352554  ...   53.989273   47.078323   47.929848\n",
            "33  140.0  123.439995  123.199997  ...  118.839996  116.399994  132.759995\n",
            "34  195.0  247.565308  223.431122  ...  107.270691  110.083977   92.456154\n",
            "35  123.0   88.447159   94.318787  ...  123.820282  121.546379  118.578560\n",
            "36  153.0   91.862579   95.557648  ...   86.057159   87.402023   87.962921\n",
            "37  127.0   91.302124   92.350792  ...    0.000000    0.000000    0.000000\n",
            "38  132.0   92.269974   95.561989  ...  132.769516  114.045921   89.136833\n",
            "39  149.0  126.896576  128.343185  ...   94.439484   92.463715   89.513046\n",
            "40  159.0    0.000000    0.000000  ...   93.345711   97.884933   88.628014\n",
            "41  104.0   86.303268   92.858002  ...  129.886108  129.676056  129.695282\n",
            "42  120.0   58.868889   61.588894  ...    7.540000    7.130000    6.250000\n",
            "43  165.0   89.728485   93.390785  ...    6.937337    6.785124    6.975390\n",
            "44  177.0   55.084835   70.782562  ...   44.290749   22.430016    1.330588\n",
            "45  184.0   87.655479   84.010864  ...   63.640827   63.607269   53.347824\n",
            "46  188.0    2.290176   20.338615  ...  118.577637  120.403351  124.240822\n",
            "47  127.0   90.175339   89.989578  ...   86.656464   87.231262   88.741585\n",
            "48  149.0  148.005142  137.650467  ...  150.682816  152.863083  156.558853\n",
            "49  129.0  144.245605  139.660782  ...  163.748215  168.269821  192.977585\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "73a58df8-1ff7-4cee-faa3-141ed7d9de5c"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_paper_fev_2021' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "79e8eb10-e958-4c62-a050-604ede839c56"
      },
      "source": [
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "\n",
        "%cd Doutorado\n",
        "\n",
        "PSD_imageJ = 'Amostra7.csv' \n",
        "PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "   Unnamed: 0   Area\n",
            "0           1  1.387\n",
            "1           2  1.626\n",
            "2           3  1.336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tEPjIBnv_xM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7dfaad1-c935-4d5a-e661-8f3b64c6084f"
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfagXc-Mv3oa"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekBHQOT_6CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "d9ce1fe1-a9f8-43c4-c696-36034a871cca"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>116.0</td>\n",
              "      <td>82.426872</td>\n",
              "      <td>81.253265</td>\n",
              "      <td>82.567177</td>\n",
              "      <td>90.763367</td>\n",
              "      <td>98.898926</td>\n",
              "      <td>104.475616</td>\n",
              "      <td>109.682526</td>\n",
              "      <td>116.837090</td>\n",
              "      <td>128.092743</td>\n",
              "      <td>134.794296</td>\n",
              "      <td>138.678955</td>\n",
              "      <td>142.274658</td>\n",
              "      <td>154.378113</td>\n",
              "      <td>172.193802</td>\n",
              "      <td>182.004745</td>\n",
              "      <td>185.960754</td>\n",
              "      <td>189.252075</td>\n",
              "      <td>77.355522</td>\n",
              "      <td>13.889418</td>\n",
              "      <td>34.338882</td>\n",
              "      <td>46.197380</td>\n",
              "      <td>68.065399</td>\n",
              "      <td>73.105827</td>\n",
              "      <td>75.292511</td>\n",
              "      <td>74.678955</td>\n",
              "      <td>75.384064</td>\n",
              "      <td>74.908440</td>\n",
              "      <td>74.384064</td>\n",
              "      <td>86.117714</td>\n",
              "      <td>86.334129</td>\n",
              "      <td>88.008324</td>\n",
              "      <td>95.404274</td>\n",
              "      <td>99.214043</td>\n",
              "      <td>103.822830</td>\n",
              "      <td>112.083229</td>\n",
              "      <td>121.097496</td>\n",
              "      <td>133.065399</td>\n",
              "      <td>139.323410</td>\n",
              "      <td>141.675369</td>\n",
              "      <td>...</td>\n",
              "      <td>115.362671</td>\n",
              "      <td>110.902496</td>\n",
              "      <td>104.697975</td>\n",
              "      <td>98.715813</td>\n",
              "      <td>96.114143</td>\n",
              "      <td>93.486313</td>\n",
              "      <td>94.249702</td>\n",
              "      <td>97.560051</td>\n",
              "      <td>98.913193</td>\n",
              "      <td>95.808563</td>\n",
              "      <td>94.105820</td>\n",
              "      <td>91.991669</td>\n",
              "      <td>143.090363</td>\n",
              "      <td>138.717010</td>\n",
              "      <td>135.659927</td>\n",
              "      <td>136.946487</td>\n",
              "      <td>135.216400</td>\n",
              "      <td>133.016632</td>\n",
              "      <td>131.017838</td>\n",
              "      <td>125.097496</td>\n",
              "      <td>122.518425</td>\n",
              "      <td>125.938164</td>\n",
              "      <td>128.609985</td>\n",
              "      <td>125.570747</td>\n",
              "      <td>123.365044</td>\n",
              "      <td>115.967888</td>\n",
              "      <td>114.300827</td>\n",
              "      <td>110.674194</td>\n",
              "      <td>105.143875</td>\n",
              "      <td>99.598091</td>\n",
              "      <td>93.318665</td>\n",
              "      <td>91.130798</td>\n",
              "      <td>91.118896</td>\n",
              "      <td>92.369804</td>\n",
              "      <td>94.888222</td>\n",
              "      <td>97.015457</td>\n",
              "      <td>98.262787</td>\n",
              "      <td>95.807373</td>\n",
              "      <td>93.973839</td>\n",
              "      <td>92.532692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101.0</td>\n",
              "      <td>149.404480</td>\n",
              "      <td>147.883057</td>\n",
              "      <td>139.410355</td>\n",
              "      <td>129.008636</td>\n",
              "      <td>128.121277</td>\n",
              "      <td>131.760330</td>\n",
              "      <td>132.971375</td>\n",
              "      <td>134.340851</td>\n",
              "      <td>138.782562</td>\n",
              "      <td>152.074219</td>\n",
              "      <td>187.781693</td>\n",
              "      <td>243.974640</td>\n",
              "      <td>249.967651</td>\n",
              "      <td>252.439194</td>\n",
              "      <td>251.573303</td>\n",
              "      <td>245.145493</td>\n",
              "      <td>234.796783</td>\n",
              "      <td>223.977066</td>\n",
              "      <td>179.369873</td>\n",
              "      <td>117.545731</td>\n",
              "      <td>117.852280</td>\n",
              "      <td>120.916473</td>\n",
              "      <td>121.822769</td>\n",
              "      <td>118.507408</td>\n",
              "      <td>113.934624</td>\n",
              "      <td>114.967453</td>\n",
              "      <td>120.143127</td>\n",
              "      <td>124.464867</td>\n",
              "      <td>147.889328</td>\n",
              "      <td>145.868347</td>\n",
              "      <td>131.683472</td>\n",
              "      <td>123.318024</td>\n",
              "      <td>125.793846</td>\n",
              "      <td>131.047653</td>\n",
              "      <td>135.744644</td>\n",
              "      <td>138.042664</td>\n",
              "      <td>141.863068</td>\n",
              "      <td>150.151657</td>\n",
              "      <td>182.455948</td>\n",
              "      <td>...</td>\n",
              "      <td>162.449387</td>\n",
              "      <td>159.584961</td>\n",
              "      <td>150.311539</td>\n",
              "      <td>148.147842</td>\n",
              "      <td>152.824249</td>\n",
              "      <td>158.574463</td>\n",
              "      <td>166.022949</td>\n",
              "      <td>172.382126</td>\n",
              "      <td>179.159195</td>\n",
              "      <td>186.753952</td>\n",
              "      <td>193.205093</td>\n",
              "      <td>194.556107</td>\n",
              "      <td>149.950592</td>\n",
              "      <td>148.929718</td>\n",
              "      <td>147.650238</td>\n",
              "      <td>150.368591</td>\n",
              "      <td>150.713470</td>\n",
              "      <td>151.134995</td>\n",
              "      <td>154.740417</td>\n",
              "      <td>155.613861</td>\n",
              "      <td>156.069214</td>\n",
              "      <td>153.952942</td>\n",
              "      <td>152.593475</td>\n",
              "      <td>152.474274</td>\n",
              "      <td>153.874344</td>\n",
              "      <td>155.230087</td>\n",
              "      <td>156.709839</td>\n",
              "      <td>162.172836</td>\n",
              "      <td>164.417618</td>\n",
              "      <td>162.208435</td>\n",
              "      <td>157.513977</td>\n",
              "      <td>151.846298</td>\n",
              "      <td>153.099121</td>\n",
              "      <td>156.379776</td>\n",
              "      <td>163.343994</td>\n",
              "      <td>169.443588</td>\n",
              "      <td>174.198715</td>\n",
              "      <td>182.906311</td>\n",
              "      <td>189.642487</td>\n",
              "      <td>192.783157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>167.0</td>\n",
              "      <td>74.791176</td>\n",
              "      <td>89.491318</td>\n",
              "      <td>95.414467</td>\n",
              "      <td>124.966553</td>\n",
              "      <td>152.852249</td>\n",
              "      <td>158.370270</td>\n",
              "      <td>163.440918</td>\n",
              "      <td>163.882294</td>\n",
              "      <td>163.453522</td>\n",
              "      <td>168.393250</td>\n",
              "      <td>174.915894</td>\n",
              "      <td>182.067963</td>\n",
              "      <td>191.473434</td>\n",
              "      <td>197.253906</td>\n",
              "      <td>211.337296</td>\n",
              "      <td>218.301544</td>\n",
              "      <td>217.898987</td>\n",
              "      <td>190.868225</td>\n",
              "      <td>113.423363</td>\n",
              "      <td>111.454697</td>\n",
              "      <td>109.780350</td>\n",
              "      <td>107.522911</td>\n",
              "      <td>108.922348</td>\n",
              "      <td>109.999901</td>\n",
              "      <td>113.166092</td>\n",
              "      <td>115.900574</td>\n",
              "      <td>111.502533</td>\n",
              "      <td>98.120911</td>\n",
              "      <td>121.943321</td>\n",
              "      <td>119.321358</td>\n",
              "      <td>112.420242</td>\n",
              "      <td>126.052933</td>\n",
              "      <td>152.581818</td>\n",
              "      <td>161.159821</td>\n",
              "      <td>164.872498</td>\n",
              "      <td>168.623169</td>\n",
              "      <td>166.993622</td>\n",
              "      <td>168.356613</td>\n",
              "      <td>173.755371</td>\n",
              "      <td>...</td>\n",
              "      <td>141.015228</td>\n",
              "      <td>144.008331</td>\n",
              "      <td>146.277725</td>\n",
              "      <td>152.092911</td>\n",
              "      <td>157.557693</td>\n",
              "      <td>157.977783</td>\n",
              "      <td>150.363663</td>\n",
              "      <td>124.589050</td>\n",
              "      <td>118.280975</td>\n",
              "      <td>132.226822</td>\n",
              "      <td>134.418854</td>\n",
              "      <td>132.561127</td>\n",
              "      <td>108.543297</td>\n",
              "      <td>114.180878</td>\n",
              "      <td>115.037949</td>\n",
              "      <td>112.696808</td>\n",
              "      <td>105.048271</td>\n",
              "      <td>95.368111</td>\n",
              "      <td>108.097290</td>\n",
              "      <td>125.363510</td>\n",
              "      <td>133.052246</td>\n",
              "      <td>135.590317</td>\n",
              "      <td>135.631866</td>\n",
              "      <td>134.729080</td>\n",
              "      <td>134.654968</td>\n",
              "      <td>136.037170</td>\n",
              "      <td>139.013092</td>\n",
              "      <td>142.365112</td>\n",
              "      <td>143.270477</td>\n",
              "      <td>143.416550</td>\n",
              "      <td>148.223862</td>\n",
              "      <td>150.747147</td>\n",
              "      <td>154.481903</td>\n",
              "      <td>156.747467</td>\n",
              "      <td>150.575714</td>\n",
              "      <td>109.231674</td>\n",
              "      <td>98.784767</td>\n",
              "      <td>125.241638</td>\n",
              "      <td>134.163757</td>\n",
              "      <td>132.242081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>173.0</td>\n",
              "      <td>20.077217</td>\n",
              "      <td>64.674896</td>\n",
              "      <td>75.764404</td>\n",
              "      <td>81.246178</td>\n",
              "      <td>86.204117</td>\n",
              "      <td>89.817261</td>\n",
              "      <td>90.326477</td>\n",
              "      <td>93.097771</td>\n",
              "      <td>98.448761</td>\n",
              "      <td>100.311768</td>\n",
              "      <td>102.312202</td>\n",
              "      <td>102.436226</td>\n",
              "      <td>98.891434</td>\n",
              "      <td>94.619400</td>\n",
              "      <td>114.682205</td>\n",
              "      <td>106.844261</td>\n",
              "      <td>1.505095</td>\n",
              "      <td>0.929667</td>\n",
              "      <td>0.723078</td>\n",
              "      <td>0.311571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>67.347427</td>\n",
              "      <td>71.882416</td>\n",
              "      <td>77.050247</td>\n",
              "      <td>82.033508</td>\n",
              "      <td>84.093109</td>\n",
              "      <td>86.721947</td>\n",
              "      <td>87.350159</td>\n",
              "      <td>89.771828</td>\n",
              "      <td>93.087341</td>\n",
              "      <td>94.533493</td>\n",
              "      <td>98.533325</td>\n",
              "      <td>...</td>\n",
              "      <td>105.264175</td>\n",
              "      <td>107.602654</td>\n",
              "      <td>109.269928</td>\n",
              "      <td>108.091553</td>\n",
              "      <td>100.724449</td>\n",
              "      <td>91.932381</td>\n",
              "      <td>86.299812</td>\n",
              "      <td>64.008789</td>\n",
              "      <td>54.391926</td>\n",
              "      <td>43.211800</td>\n",
              "      <td>12.665674</td>\n",
              "      <td>0.949280</td>\n",
              "      <td>94.290855</td>\n",
              "      <td>93.835976</td>\n",
              "      <td>96.056465</td>\n",
              "      <td>96.299049</td>\n",
              "      <td>101.109619</td>\n",
              "      <td>110.368202</td>\n",
              "      <td>110.142693</td>\n",
              "      <td>109.651062</td>\n",
              "      <td>111.056000</td>\n",
              "      <td>106.889328</td>\n",
              "      <td>104.160294</td>\n",
              "      <td>99.251160</td>\n",
              "      <td>97.932739</td>\n",
              "      <td>96.511642</td>\n",
              "      <td>96.737480</td>\n",
              "      <td>99.295853</td>\n",
              "      <td>101.272797</td>\n",
              "      <td>101.073273</td>\n",
              "      <td>100.059479</td>\n",
              "      <td>98.440437</td>\n",
              "      <td>96.259346</td>\n",
              "      <td>97.516655</td>\n",
              "      <td>99.652008</td>\n",
              "      <td>77.803764</td>\n",
              "      <td>38.314877</td>\n",
              "      <td>21.717396</td>\n",
              "      <td>1.858432</td>\n",
              "      <td>0.083163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137.0</td>\n",
              "      <td>147.749359</td>\n",
              "      <td>147.697693</td>\n",
              "      <td>149.262924</td>\n",
              "      <td>148.571472</td>\n",
              "      <td>149.474243</td>\n",
              "      <td>150.936859</td>\n",
              "      <td>152.395111</td>\n",
              "      <td>154.426758</td>\n",
              "      <td>159.082291</td>\n",
              "      <td>162.833084</td>\n",
              "      <td>165.334961</td>\n",
              "      <td>164.555054</td>\n",
              "      <td>160.886780</td>\n",
              "      <td>154.733124</td>\n",
              "      <td>154.695923</td>\n",
              "      <td>159.363083</td>\n",
              "      <td>165.872757</td>\n",
              "      <td>166.655548</td>\n",
              "      <td>164.145248</td>\n",
              "      <td>155.646744</td>\n",
              "      <td>133.352386</td>\n",
              "      <td>119.199585</td>\n",
              "      <td>115.329468</td>\n",
              "      <td>110.705154</td>\n",
              "      <td>101.911560</td>\n",
              "      <td>85.841225</td>\n",
              "      <td>75.981766</td>\n",
              "      <td>70.952415</td>\n",
              "      <td>150.410263</td>\n",
              "      <td>148.392334</td>\n",
              "      <td>147.437042</td>\n",
              "      <td>147.194412</td>\n",
              "      <td>147.957489</td>\n",
              "      <td>149.317795</td>\n",
              "      <td>149.511749</td>\n",
              "      <td>149.333160</td>\n",
              "      <td>153.097870</td>\n",
              "      <td>158.698044</td>\n",
              "      <td>164.448944</td>\n",
              "      <td>...</td>\n",
              "      <td>122.733276</td>\n",
              "      <td>120.574623</td>\n",
              "      <td>116.448387</td>\n",
              "      <td>114.410667</td>\n",
              "      <td>114.813683</td>\n",
              "      <td>115.420959</td>\n",
              "      <td>114.464386</td>\n",
              "      <td>114.867493</td>\n",
              "      <td>114.916565</td>\n",
              "      <td>116.992004</td>\n",
              "      <td>155.906815</td>\n",
              "      <td>174.472000</td>\n",
              "      <td>105.137085</td>\n",
              "      <td>114.125099</td>\n",
              "      <td>120.301239</td>\n",
              "      <td>123.777611</td>\n",
              "      <td>125.683090</td>\n",
              "      <td>126.902344</td>\n",
              "      <td>127.897064</td>\n",
              "      <td>128.610367</td>\n",
              "      <td>129.434280</td>\n",
              "      <td>129.481812</td>\n",
              "      <td>128.700089</td>\n",
              "      <td>127.492142</td>\n",
              "      <td>127.671005</td>\n",
              "      <td>126.119286</td>\n",
              "      <td>120.306030</td>\n",
              "      <td>117.419464</td>\n",
              "      <td>116.290955</td>\n",
              "      <td>113.978844</td>\n",
              "      <td>114.423355</td>\n",
              "      <td>113.845055</td>\n",
              "      <td>112.337898</td>\n",
              "      <td>112.103790</td>\n",
              "      <td>112.704025</td>\n",
              "      <td>112.519356</td>\n",
              "      <td>112.526672</td>\n",
              "      <td>129.996857</td>\n",
              "      <td>163.274170</td>\n",
              "      <td>176.036392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "0  116.0   82.426872   81.253265  ...   95.807373   93.973839   92.532692\n",
              "1  101.0  149.404480  147.883057  ...  182.906311  189.642487  192.783157\n",
              "2  167.0   74.791176   89.491318  ...  125.241638  134.163757  132.242081\n",
              "3  173.0   20.077217   64.674896  ...   21.717396    1.858432    0.083163\n",
              "4  137.0  147.749359  147.697693  ...  129.996857  163.274170  176.036392\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q09DRGPtM75"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "\n",
        "# Area = np.array(PSD_new.iloc[:,1])\n",
        "Area = PSD_new['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aUb2_-jsY1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "244034e5-c700-40a2-e78f-2800fcc75a18"
      },
      "source": [
        "PSD_new.iloc[:,1].values"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.387, 1.626, 1.336, 0.64 , 2.211, 1.12 , 0.974, 1.237, 1.29 ,\n",
              "       3.755, 2.778, 1.256, 1.386, 1.302, 1.071, 1.497, 1.518, 1.244,\n",
              "       1.532, 1.325, 1.519, 1.895, 1.22 , 1.241, 1.301, 1.429, 0.667,\n",
              "       2.157, 1.052, 2.082, 1.517, 1.281, 0.784, 1.067, 2.764, 1.215,\n",
              "       0.943, 2.182, 1.486, 1.569, 2.667, 0.709, 1.006, 1.6  , 1.408,\n",
              "       3.16 , 2.465, 2.284, 1.273, 1.256, 3.021, 1.701, 1.955, 5.248,\n",
              "       1.627, 1.367, 1.592, 2.718, 1.658, 1.128, 2.192, 1.508, 2.547,\n",
              "       1.945, 1.606, 3.482, 1.756, 1.457, 1.864, 1.821, 1.314, 1.715,\n",
              "       1.015, 1.345, 1.265, 1.844, 1.396, 1.785, 1.694, 1.413, 1.368,\n",
              "       2.21 , 1.034, 1.367, 1.943, 1.008, 1.279, 1.579, 1.444, 1.879,\n",
              "       1.466, 2.154, 1.794, 3.149, 1.883, 1.692, 1.163, 1.297, 2.949,\n",
              "       1.09 , 1.444, 1.524])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J705kDqsE8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378cb607-614c-4364-9d16-2b9f828d299f"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK1GBUHWiIr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7acc1f9c-c1b2-4195-a045-c3c4098c7120"
      },
      "source": [
        "Freq = [10.52631579, 24.21052632, 36.84210526, 14.73684211,  7.36842105, 0.]\n",
        "Freq2 = [12.90153, 28.11527, 27.66761, 20.21617, 10.34227, 0.]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434, 0.]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOrUlEQVR4nO3dfYxmZX3G8e/VBYqtL2D3KdmCdq1VkTRlsSOl1RhErUD/ABLSlLZKDcnaVgw2poGatEBfEkyqNI2tzSqUtbFSAlioUVuitISo2EGXZWFrQUQLXdnxrYJNbBZ//eM5W8ZxZp8zz8vM3sP3k5zMOfdzzp7fzUwu7jlzzn1SVUiS2vND612AJGk8BrgkNcoAl6RGGeCS1CgDXJIadcRanmzz5s21devWtTylJDXv7rvv/lpVDZa2r2mAb926lfn5+bU8pSQ1L8mXl2v3EookNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqTZ/E1MaWKzPR8XW5LxeRVsMRuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrUyABPcnSSzya5J8l9Sa7s2q9L8qUku7pl2+zLlSQd1Oc+8O8CZ1TVE0mOBO5M8rHus9+rqhtnV54kaSUjA7yqCnii2zyyW3ziQpLWWa9r4Ek2JdkF7Aduq6q7uo/+NMnuJFcn+eEVjt2eZD7J/MLCwpTKliT1CvCqerKqtgEnAKcm+Rng94ETgZcDzwUuXeHYHVU1V1Vzg8EPvFRZkjSmVd2FUlXfAm4HzqyqfTX0XeBvgFNnUaAkaXl97kIZJDmmW38G8Drg35Ns6doCnAvsmWWhkqTv1+culC3AziSbGAb+DVX1kSSfTDIAAuwCfmuGdUqSluhzF8pu4JRl2s+YSUWSpF58ElOSGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqVJ+30h+d5LNJ7klyX5Iru/YXJLkryYNJ/j7JUbMvV5J0UJ8R+HeBM6rqZGAbcGaS04B3AldX1U8D3wQuml2ZkqSlRgZ4DT3RbR7ZLQWcAdzYte8Ezp1JhZpYMtki6fDU6xp4kk1JdgH7gduALwLfqqoD3S6PAMevcOz2JPNJ5hcWFqZRsySJngFeVU9W1TbgBOBU4MS+J6iqHVU1V1Vzg8FgzDIlSUut6i6UqvoWcDvwC8AxSY7oPjoBeHTKtUmSDqHPXSiDJMd0688AXgfsZRjk53e7XQjcMqsiJUk/6IjRu7AF2JlkE8PAv6GqPpLkfuD6JH8CfB64ZoZ1SpKWGBngVbUbOGWZ9ocYXg+XJK0Dn8SUpEYZ4JLUKANckhplgEtSowxwSWpUn9sIdTgZa3KSmnoZktafI3BJapQjcK2rumLRxhVj/HZR/nahpy9H4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqP6vJX+eUluT3J/kvuSXNK1X5Hk0SS7uuXs2ZcrSTqoz2RWB4C3V9XnkjwLuDvJbd1nV1fVn82uPEnSSvq8lX4fsK9bfzzJXuD4WRcmSTq0VV0DT7IVOAW4q2u6OMnuJNcmOXaFY7YnmU8yv7CwMFGxEkCop5aw6kXaKHoHeJJnAjcBb6uqbwPvBV4IbGM4Qn/XcsdV1Y6qmququcFgMIWSJUnQM8CTHMkwvD9YVTcDVNVjVfVkVX0PeB9w6uzKlCQt1eculADXAHur6t2L2rcs2u08YM/0y5MkraTPXSivAN4A3JtkV9f2DuCCJNsYvjH3YeDNM6lQkrSsPneh3Aks96efj06/nKeXXLn6v6j5BkhJB/kkpiQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RG9ZkL5Wll0vmiy2fdJa0RR+CS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRvV5K/3zktye5P4k9yW5pGt/bpLbkjzQfT129uVKkg7qMwI/ALy9qk4CTgPekuQk4DLgE1X1IuAT3bYkaY2MDPCq2ldVn+vWHwf2AscD5wA7u912AufOqkipKcn4i7QKq7oGnmQrcApwF3BcVe3rPvoqcNwKx2xPMp9kfmFhYYJSJUmL9Q7wJM8EbgLeVlXfXvxZVRWw7DROVbWjquaqam4wGExUrCTpKb0CPMmRDMP7g1V1c9f8WJIt3edbgP2zKVGStJw+d6EEuAbYW1XvXvTRrcCF3fqFwC3TL0+StJI+84G/AngDcG+SXV3bO4CrgBuSXAR8GfiV2ZQobXw5eAVyzL9jOg/909PIAK+qO1n5x+o10y1HktSXT2JKUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjerzVvprk+xPsmdR2xVJHk2yq1vOnm2ZkqSl+ozArwPOXKb96qra1i0fnW5ZkqRRRgZ4Vd0BfGMNapEkrcIk18AvTrK7u8Ry7Eo7JdmeZD7J/MLCwgSnkyQtNm6Avxd4IbAN2Ae8a6Udq2pHVc1V1dxgMBjzdJKkpY4Y56CqeuzgepL3AR+ZWkXSYSRXZtXH1AzqkJYz1gg8yZZFm+cBe1baV5I0GyNH4Ek+BJwObE7yCHA5cHqSbQwHGw8Db55hjZKkZYwM8Kq6YJnma2ZQiyRpFXwSU5IaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqrCcxm5HVP0Xnc3SSWuEIXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNGhngSa5Nsj/JnkVtz01yW5IHuq/HzrZMSdJSfWYjvA54D/CBRW2XAZ+oqquSXNZtXzr98p6SK1c/s6DzCkrayEaOwKvqDuAbS5rPAXZ26zuBc6dcl6TDRTLZopkZ9xr4cVW1r1v/KnDclOqRJPU08R8xq6o4xNWKJNuTzCeZX1hYmPR0kqTOuAH+WJItAN3X/SvtWFU7qmququYGg8GYp5MkLTVugN8KXNitXwjcMp1yJEl99bmN8EPAp4GXJHkkyUXAVcDrkjwAvLbbliStoZG3EVbVBSt89Jop1yJJWgWfxJSkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEb1eaGDpA3CF6NsLI7AJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqokfpkzwMPA48CRyoqrlpFCVJGm0ac6G8uqq+NoV/R5K0Cl5CkaRGTRrgBfxzkruTbF9uhyTbk8wnmV9YWJjwdJKkgyYN8FdW1cuAs4C3JHnV0h2qakdVzVXV3GAwmPB0kqSDJgrwqnq0+7of+DBw6jSKkiSNNnaAJ/nRJM86uA78ErBnWoVJkg5tkrtQjgM+nOTgv/N3VfXxqVQlSRpp7ACvqoeAk6dYiyRpFbyNUJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqGrMRStL3CbV4Y9WqRu8jR+CS1CwDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJatREAZ7kzCRfSPJgksumVZQkabSxAzzJJuAvgbOAk4ALkpw0rcIkSYc2yQj8VODBqnqoqv4XuB44ZzplSZJGmWQ+8OOB/1y0/Qjw80t3SrId2N5tPpHkCxOcc1XGmIa4z1Gbga+tePR4J+1to/Vpo/UHNl6fNlp/ZuiQfZrQTy7XOPMXOlTVDmDHrM+zVpLMV9XcetcxTRutTxutP7Dx+rTR+gPr06dJLqE8Cjxv0fYJXZskaQ1MEuD/BrwoyQuSHAX8KnDrdMqSJI0y9iWUqjqQ5GLgn4BNwLVVdd/UKjt8bZjLQYtstD5ttP7AxuvTRusPrEOfUr49VJKa5JOYktQoA1ySGmWAr2DUNAFJnp/k9iSfT7I7ydnrUWdfSa5Nsj/JnhU+T5K/6Pq7O8nL1rrG1ejRn1/v+nFvkk8lOXmta1ytUX1atN/LkxxIcv5a1TaOPv1JcnqSXUnuS/Kva1nfOHr83D0nyT8muafr05tmWlBVuSxZGP5R9ovATwFHAfcAJy3ZZwfw2936ScDD6133iD69CngZsGeFz88GPsbwCYzTgLvWu+YJ+/OLwLHd+lmHe3/69KnbZxPwSeCjwPnrXfOE36NjgPuB53fbP77eNU+hT+8A3tmtD4BvAEfNqh5H4MvrM01AAc/u1p8D/Nca1rdqVXUHwx+mlZwDfKCGPgMck2TL2lS3eqP6U1WfqqpvdpufYficwmGtx/cI4K3ATcD+2Vc0mR79+TXg5qr6Srf/RuhTAc9KEuCZ3b4HZlWPAb685aYJOH7JPlcAv5HkEYajobeuTWkz06fPrbqI4W8XTUtyPHAe8N71rmVKXgwcm+Rfktyd5I3rXdAUvAd4KcMB3b3AJVX1vVmdzAAf3wXAdVV1AsPLD3+bxP+eh5kkr2YY4Jeudy1T8OfApbMMhDV2BPBzwC8Drwf+IMmL17ekib0e2AX8BLANeE+SZx/6kPHNfC6URvWZJuAi4EyAqvp0kqMZTmZz2P8auIINNzVCkp8F3g+cVVVfX+96pmAOuH742zmbgbOTHKiqf1jfssb2CPD1qvoO8J0kdwAnA/+xvmVN5E3AVTW8CP5gki8BJwKfncXJHDEur880AV8BXgOQ5KXA0cDCmlY5XbcCb+zuRjkN+O+q2rfeRY0ryfOBm4E3VFXLgfD/quoFVbW1qrYCNwK/03B4A9wCvDLJEUl+hOFspnvXuaZJLc6F44CXAA/N6mSOwJdRK0wTkOSPgPmquhV4O/C+JL/L8A8Xv9n9X/ewlORDwOnA5u66/eXAkQBV9dcMr+OfDTwI/A/DkcRhq0d//hD4MeCvuhHrgTrMZ7/r0aemjOpPVe1N8nFgN/A94P1VdchbKNdbj+/RHwPXJbmX4R1dl1bVrKaY9VF6SWqVl1AkqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrU/wGTdmEsXLg07QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "10122d32-793c-48f2-f8f9-13e9e6e189be"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa9ae4cbe90>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "6b86f530-ccf4-48c0-a4d1-777c28d2f53f"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.02941176, 0.08823529, 0.38235294, 0.68627451, 0.8627451 ,\n",
              "         0.91176471, 0.97058824, 0.99019608, 0.99019608, 1.        ],\n",
              "        [0.12      , 0.34      , 0.58      , 0.86      , 0.92      ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.7815261 , 0.96186838, 1.14221067, 1.32255296, 1.50289524,\n",
              "        1.68323753, 1.86357982, 2.0439221 , 2.22426439, 2.40460667,\n",
              "        2.58494896]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xENlBUUxfTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "28de50ca-d5f4-474f-b940-4df9fb777835"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r_squared = 0.8847543469602058\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KukfpGTTKlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "9dae1826-768c-499a-da0b-e7eb59f3e105"
      },
      "source": [
        "df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.884754</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.945578</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.255125</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2  ...  loss test                                 Details\n",
              "0  20  20  ...   0.255125  3 layers of Convolution: 64, 128, 256 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHa1j4HT9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "44ed4d3a-94fe-4178-8cca-38369be83c62"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.7815261  0.96186838 1.14221067 1.32255296 1.50289524 1.68323753\n",
            " 1.86357982 2.0439221  2.22426439 2.40460667 2.58494896]\n",
            "[[ 2.94117647  5.88235294 29.41176471 30.39215686 17.64705882  4.90196078\n",
            "   5.88235294  1.96078431  0.          0.98039216]\n",
            " [12.         22.         24.         28.          6.          8.\n",
            "   0.          0.          0.          0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1979ea66-2312-4ff0-b677-6b3c950dc3f5"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "5913d365-cf50-42c6-db48-4380375df312"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa9ae37af50>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6bd487-9463-40d1-f74c-e5fa365f6734"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.3289030245084366,\n",
              "  1.4388493665910183,\n",
              "  1.3042423209535017,\n",
              "  0.9027033336764101,\n",
              "  1.6778356991700483,\n",
              "  1.1941642642883694,\n",
              "  1.113613629842976,\n",
              "  1.254988970803089,\n",
              "  1.2815923738491737,\n",
              "  2.186553107171316,\n",
              "  1.8807071689325485,\n",
              "  1.2645903954195463,\n",
              "  1.3284238815238665,\n",
              "  1.2875394701698204,\n",
              "  1.1677497815933682,\n",
              "  1.3805939296073044,\n",
              "  1.3902437300372827,\n",
              "  1.2585348599266302,\n",
              "  1.3966398900698307,\n",
              "  1.2988619621707653,\n",
              "  1.3907015741893414,\n",
              "  1.5533154661153457,\n",
              "  1.2463355264843006,\n",
              "  1.2570164179581493,\n",
              "  1.2870449283923413,\n",
              "  1.3488733481786004,\n",
              "  0.9215480325725586,\n",
              "  1.6572198701420842,\n",
              "  1.157345238492556,\n",
              "  1.6281537802488464,\n",
              "  1.3897857350553149,\n",
              "  1.2771138777750963,\n",
              "  0.9991095050455518,\n",
              "  1.165567069812981,\n",
              "  1.875962180228586,\n",
              "  1.2437789380968078,\n",
              "  1.0957485526731296,\n",
              "  1.6667959343039342,\n",
              "  1.3755122549350303,\n",
              "  1.413404699896484,\n",
              "  1.8427506249649406,\n",
              "  0.9501193805081709,\n",
              "  1.1317592420667806,\n",
              "  1.4272992929222168,\n",
              "  1.3389254195014408,\n",
              "  2.0058506827187097,\n",
              "  1.7715912276177528,\n",
              "  1.7053090981329784,\n",
              "  1.273119766733618,\n",
              "  1.2645903954195463,\n",
              "  1.9612385537320356,\n",
              "  1.4716590860639265,\n",
              "  1.5777145844408116,\n",
              "  2.584948960960377,\n",
              "  1.4392917491892008,\n",
              "  1.319287102056625,\n",
              "  1.4237265731938766,\n",
              "  1.8602862904913782,\n",
              "  1.4529388029682806,\n",
              "  1.1984215478959244,\n",
              "  1.6706109906436855,\n",
              "  1.3856569681781365,\n",
              "  1.8008167925806498,\n",
              "  1.5736743355948497,\n",
              "  1.4299729748651446,\n",
              "  2.1055688292639205,\n",
              "  1.4952620641730152,\n",
              "  1.3620242349823046,\n",
              "  1.540557857201846,\n",
              "  1.5226848692236787,\n",
              "  1.293459223084363,\n",
              "  1.4777028859756633,\n",
              "  1.1368105109938904,\n",
              "  1.3086279790944384,\n",
              "  1.269113085619237,\n",
              "  1.5322707725763225,\n",
              "  1.3332075624036517,\n",
              "  1.507558485549488,\n",
              "  1.4686278591874,\n",
              "  1.341300666036808,\n",
              "  1.319769562157615,\n",
              "  1.6774562271083886,\n",
              "  1.1474012764748687,\n",
              "  1.319287102056625,\n",
              "  1.5728650404343092,\n",
              "  1.1328836926591555,\n",
              "  1.2761165219980004,\n",
              "  1.417901703622935,\n",
              "  1.355934328276106,\n",
              "  1.546744033302657,\n",
              "  1.3662244224803437,\n",
              "  1.6560670213972442,\n",
              "  1.5113542745679724,\n",
              "  2.0023564433863985,\n",
              "  1.5483895061438226,\n",
              "  1.467760644550703,\n",
              "  1.2168720518308382,\n",
              "  1.2850648580991957,\n",
              "  1.937726352564777,\n",
              "  1.1780624362746346,\n",
              "  1.355934328276106,\n",
              "  1.3929885377045959],\n",
              " [0.8611173788511493,\n",
              "  0.8254287300560762,\n",
              "  1.484877529234984,\n",
              "  1.3720139005512928,\n",
              "  1.159726613880855,\n",
              "  1.093899329022454,\n",
              "  1.4080915505905327,\n",
              "  1.3492900472714697,\n",
              "  1.1691754920552284,\n",
              "  0.8731884406898137,\n",
              "  1.1804671312723944,\n",
              "  1.4206928665609264,\n",
              "  1.1835107715619562,\n",
              "  1.1987170169312586,\n",
              "  1.1410930518523574,\n",
              "  1.3213254867062578,\n",
              "  1.0256808160967532,\n",
              "  1.3067511557327114,\n",
              "  0.8311674141605476,\n",
              "  1.1410214627656516,\n",
              "  1.6868323573373387,\n",
              "  1.575729327279597,\n",
              "  1.7606891130628535,\n",
              "  1.237032118601595,\n",
              "  1.0452580990461673,\n",
              "  1.395586168147972,\n",
              "  1.4495074125934702,\n",
              "  1.7032097545916218,\n",
              "  1.4568070776903252,\n",
              "  1.3426581211536575,\n",
              "  1.4932808700318143,\n",
              "  1.068701114676104,\n",
              "  1.414992813186367,\n",
              "  1.2493980875371207,\n",
              "  1.7529511226245786,\n",
              "  0.9290734912563144,\n",
              "  1.159614363169837,\n",
              "  1.037915333832888,\n",
              "  1.070886462457,\n",
              "  1.405579827314029,\n",
              "  1.2172828945008871,\n",
              "  0.781526098231774,\n",
              "  1.1781348222488124,\n",
              "  1.3504369507825038,\n",
              "  1.4716298558344385,\n",
              "  1.5723332699692292,\n",
              "  1.589285893240341,\n",
              "  0.996227232829562,\n",
              "  1.0883603132547695,\n",
              "  1.0964474257630799]]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4a6164cb-0e93-4ef4-d900-ae7c7f7fdb95"
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4,1.6, 1.8,2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa9aa160d50>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "241f4610-5982-4f58-fe58-8833ba5db39f"
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a57ad5-4e4b-41c5-9504-3f429d4762a2"
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.92156863, 11.76470588, 40.19607843, 23.52941176,  8.82352941,\n",
              "        6.8627451 ])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed7e840-6788-4a86-a34a-0f8385760b62"
      },
      "source": [
        "bins_list"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "1f685ab4-f18d-4b4d-dc81-4ecd171f2e40"
      },
      "source": [
        "df"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "      <th>0.8</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.4</th>\n",
              "      <th>1.6</th>\n",
              "      <th>1.8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.884754</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.945578</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.255125</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "      <td>12.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2       R^2  acc train  acc test  ...   1.0   1.2   1.4  1.6  1.8\n",
              "0  20  20  0.884754        1.0  0.945578  ...  34.0  20.0  24.0  8.0  0.0\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c43bea9d-4e62-445a-b1c9-185fb608bd09"
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fafc102d-30b9-40e6-9b25-c168d98e8497\", \"output.xlsx\", 5241)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}