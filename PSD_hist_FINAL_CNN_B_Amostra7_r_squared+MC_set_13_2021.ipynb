{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_Amostra7_r_squared+MC_set_13_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/PSD_hist_FINAL_CNN_B_Amostra7_r_squared%2BMC_set_13_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039e3ebe-b307-472a-fa37-643fe991ab41"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.11-cp37-cp37m-manylinux2010_x86_64.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n",
            "Installing collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79160d97-50b6-4290-99d6-d9bbf4f96baf"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marquesgabi_fev_2020'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 73 (delta 37), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n",
            "/content/marquesgabi_fev_2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b49da23-dfa3-4933-d7e6-03c122631730"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 458, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 458 (delta 98), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (458/458), 203.19 MiB | 19.16 MiB/s, done.\n",
            "Resolving deltas: 100% (215/215), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "aaedf41a-81bb-4894-dcf6-dcc0bdc9c140"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[2] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22bc8fe-b237-423c-9b72-6728e4e5334f"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 21.97 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN5MN5a_v4np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05110033-bb36-433f-a4b2-8af01df2f5cd"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     101  103.174889   97.297623  ...   11.677385   11.983727   13.028723\n",
            "1     120  135.070007  134.073334  ...  119.756668  119.318878  118.144447\n",
            "2     137   99.868721   99.036819  ...  121.828056  127.388397  127.369423\n",
            "3     120  116.651115  120.628883  ...   11.074445   11.608890   11.811110\n",
            "4     191  139.489441  141.951660  ...  130.696426  129.628891  127.732658\n",
            "5     197  108.217926  142.040085  ...   94.424240   90.486237   88.290039\n",
            "6     158  111.992943  113.147552  ...  130.241791  124.456497  118.156227\n",
            "7     126  134.716049  131.037048  ...  178.382721  190.234558  199.592590\n",
            "8     179  117.570892  120.173256  ...   67.417030   74.917580   75.857559\n",
            "9     165  147.214996  141.395340  ...  195.383041  208.187485  203.134705\n",
            "10    181   65.331741   71.974152  ...  160.365417  163.839401  162.376938\n",
            "11    151  128.914429  128.391663  ...  136.479187  142.835312  144.772949\n",
            "12    188  123.824806  125.581696  ...  140.146210  138.179260  133.556808\n",
            "13    187  104.796608  100.910492  ...  107.207092  100.552429  101.294746\n",
            "14    189    0.000000    0.000000  ...   48.799728   20.713305    0.984911\n",
            "15    184    0.000000    0.195180  ...  151.549591  148.155472  146.253769\n",
            "16    113   22.783382   48.436756  ...   11.751116   12.218419   11.043074\n",
            "17    152  137.988220  147.346939  ...  114.331718  114.092102  107.790161\n",
            "18    105  122.200012  123.995575  ...  122.120010  123.644470  125.315567\n",
            "19    103   72.234039   71.747475  ...  111.070694   97.305489   88.466011\n",
            "20    184  131.517014  127.003296  ...  144.558578  136.859161  133.308594\n",
            "21    170  147.447205  147.985611  ...   51.469482   47.449417    9.406229\n",
            "22    122  156.703018  161.749527  ...   98.908348  104.549316  107.292664\n",
            "23    117  173.614288  170.142151  ...  198.502090  205.226974  208.525665\n",
            "24    112    0.000000    0.000000  ...  121.062500  119.562500  116.625000\n",
            "25    102  119.203392  121.303345  ...  151.844696  153.042313  152.345642\n",
            "26    113   46.447174   44.525486  ...   59.028740   62.078392   64.173149\n",
            "27    184  104.090263  106.778343  ...  180.362473  189.404526  179.632324\n",
            "28    110   80.911400   77.785446  ...  113.867767  108.103470  102.580170\n",
            "29    154  141.479370  136.752075  ...  122.297523  124.297531  125.818184\n",
            "30    193   80.163101   83.972694  ...   52.492577   39.150852   21.186554\n",
            "31    173  130.167099  141.205612  ...   91.378899   52.693474    1.689432\n",
            "32    133  142.473694  145.764542  ...   53.811638   55.955677   63.673134\n",
            "33    174  109.407593  108.406914  ...  149.922058  149.477234  154.742386\n",
            "34    132  130.917358  134.300293  ...  125.090912  125.839310  126.077133\n",
            "35    195  139.625580  158.483337  ...   67.468384   62.529819   35.644287\n",
            "36    182  104.071007  110.201187  ...  156.384628  153.319550  149.816574\n",
            "37    176  118.468475  114.599174  ...    0.000000    0.000000    0.000000\n",
            "38    108   99.050751  102.112480  ...    1.477366    1.567901    2.124829\n",
            "39    174  163.791550  171.521225  ...  148.508545  173.854141  196.074005\n",
            "40    138  147.385635   98.458511  ...   83.929214   86.829659   84.829651\n",
            "41    133  138.030472  132.878128  ...  104.662056  106.130196  109.243767\n",
            "42    110  121.143143  118.225449  ...   93.914711   91.367264   84.161980\n",
            "43    150   87.313416   91.576546  ...  203.801071  205.020981  216.147018\n",
            "44    121  132.845505  137.349838  ...  129.013596  129.124924  129.393768\n",
            "45    184  117.251884  119.796776  ...  126.503769  131.084579  115.142715\n",
            "46    182  111.171593  100.142021  ...   98.544388  101.047340  100.834320\n",
            "47    124   94.577515   94.953171  ...  128.012482  129.480728  128.876160\n",
            "48    164  106.228447  106.478882  ...    0.000000    0.000000    0.000000\n",
            "49    134  150.362900  145.187119  ...   76.252617   74.843842   76.413902\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpQ1Pz0fX5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d00f973e-c79f-4b05-8e41-e5b385a4d996"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "2c379181-cd86-4d56-9057-a198f0cf83f0"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 22.42 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "0c81010a-585f-47c0-df51-ce943a966440"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 3s 154ms/step - loss: 0.5226 - accuracy: 0.7755 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.2623 - accuracy: 0.8659 - val_loss: 0.6935 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.1494 - accuracy: 0.9329 - val_loss: 0.6949 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0927 - accuracy: 0.9679 - val_loss: 0.6969 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0777 - accuracy: 0.9708 - val_loss: 0.6962 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0941 - accuracy: 0.9708 - val_loss: 0.6955 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0479 - accuracy: 0.9825 - val_loss: 0.6986 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0731 - accuracy: 0.9796 - val_loss: 0.6939 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0591 - accuracy: 0.9767 - val_loss: 0.6953 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.6935 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 0.6932 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0332 - accuracy: 0.9825 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0325 - accuracy: 0.9854 - val_loss: 0.6992 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.6908 - val_accuracy: 0.5170\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0363 - accuracy: 0.9854 - val_loss: 0.6923 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 0.6956 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0089 - accuracy: 0.9942 - val_loss: 0.6939 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.6945 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.6943 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.6909 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 0.6937 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 9.1963e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 9.4357e-04 - accuracy: 1.0000 - val_loss: 0.7330 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 7.0196e-04 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 9.4653e-04 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 5.1336e-04 - accuracy: 1.0000 - val_loss: 0.9209 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 8.5616e-04 - accuracy: 1.0000 - val_loss: 1.1943 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0028 - accuracy: 0.9971 - val_loss: 1.3672 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 1.4748 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 2s 136ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2676 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4168 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 3.3658e-04 - accuracy: 1.0000 - val_loss: 2.3664 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1225 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 3.3900e-04 - accuracy: 1.0000 - val_loss: 1.9924 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 4.3916e-04 - accuracy: 1.0000 - val_loss: 2.0252 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0953 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 5.4560e-04 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.5306\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 7.7212e-04 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.0702e-04 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 3.4870e-04 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.5714\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.6673e-04 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.7211\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 7.2810e-04 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.7755\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 5.4015e-04 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.6054\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 6.5183e-04 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.5714\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 3.2517e-04 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 0.5782\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.5417e-04 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.5918\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 7.9120e-04 - accuracy: 1.0000 - val_loss: 0.8940 - val_accuracy: 0.5374\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 9.2573e-04 - accuracy: 1.0000 - val_loss: 1.2813 - val_accuracy: 0.5170\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 1.8558e-04 - accuracy: 1.0000 - val_loss: 3.4203 - val_accuracy: 0.5102\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 2.5467e-04 - accuracy: 1.0000 - val_loss: 4.6533 - val_accuracy: 0.5102\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.0699e-04 - accuracy: 1.0000 - val_loss: 4.8154 - val_accuracy: 0.5102\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.3271e-04 - accuracy: 1.0000 - val_loss: 4.3603 - val_accuracy: 0.5102\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 2.4288e-04 - accuracy: 1.0000 - val_loss: 3.8439 - val_accuracy: 0.5102\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.3661e-04 - accuracy: 1.0000 - val_loss: 3.4409 - val_accuracy: 0.5102\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.6951e-04 - accuracy: 1.0000 - val_loss: 3.1729 - val_accuracy: 0.5102\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.4633 - val_accuracy: 0.5102\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.2050 - val_accuracy: 0.5102\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.5510\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.7401e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.8912\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.1541e-04 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.7891\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 3.3850e-04 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.7551\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 1.1532e-04 - accuracy: 1.0000 - val_loss: 1.3799 - val_accuracy: 0.5850\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1812 - val_accuracy: 0.6122\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.6923e-04 - accuracy: 1.0000 - val_loss: 1.0530 - val_accuracy: 0.6190\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.8135e-04 - accuracy: 1.0000 - val_loss: 0.8353 - val_accuracy: 0.6599\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 7.4052e-04 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.6190\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 7.4430e-04 - accuracy: 1.0000 - val_loss: 1.3353 - val_accuracy: 0.6327\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 1.8446e-04 - accuracy: 1.0000 - val_loss: 1.6116 - val_accuracy: 0.6259\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 3.6579e-04 - accuracy: 1.0000 - val_loss: 1.6343 - val_accuracy: 0.6327\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 9.5712e-05 - accuracy: 1.0000 - val_loss: 1.4362 - val_accuracy: 0.6463\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 2s 221ms/step - loss: 1.3105e-04 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.6871\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 3.8457e-05 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.7551\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 1.6446e-04 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8027\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.9116e-04 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8231\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 2.6373e-04 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.8503\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.3777e-04 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.8639\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6269 - val_accuracy: 0.7891\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 9.2441e-05 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.7415\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 1.1303e-04 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7755\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 7.3409e-05 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.7891\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.3350e-04 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.8027\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 2.5152e-05 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.8095\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 8.2755e-04 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.7415\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 3.8710e-04 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.7347\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 3.0924e-05 - accuracy: 1.0000 - val_loss: 0.8286 - val_accuracy: 0.7347\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.3911e-04 - accuracy: 1.0000 - val_loss: 1.2473 - val_accuracy: 0.6735\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.2510e-04 - accuracy: 1.0000 - val_loss: 1.8694 - val_accuracy: 0.6531\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 5.6564e-04 - accuracy: 1.0000 - val_loss: 1.7845 - val_accuracy: 0.6599\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.0682e-04 - accuracy: 1.0000 - val_loss: 1.5448 - val_accuracy: 0.6871\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4.6892e-04 - accuracy: 1.0000 - val_loss: 0.9041 - val_accuracy: 0.7347\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 7.1698e-05 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.7687\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5231 - val_accuracy: 0.5102\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0116 - accuracy: 0.9942 - val_loss: 35.5249 - val_accuracy: 0.5102\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0269 - accuracy: 0.9854 - val_loss: 224.7971 - val_accuracy: 0.5102\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 551.6971 - val_accuracy: 0.5102\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0439 - accuracy: 0.9913 - val_loss: 485.3933 - val_accuracy: 0.5102\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.1103 - accuracy: 0.9708 - val_loss: 286.6379 - val_accuracy: 0.5102\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 676.2120 - val_accuracy: 0.5102\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.1275 - accuracy: 0.9563 - val_loss: 365.8629 - val_accuracy: 0.5102\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 0.0880 - accuracy: 0.9650 - val_loss: 164.8560 - val_accuracy: 0.5102\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0404 - accuracy: 0.9825 - val_loss: 487.4574 - val_accuracy: 0.5102\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.0186 - accuracy: 0.9971 - val_loss: 478.7050 - val_accuracy: 0.5102\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 381.6703 - val_accuracy: 0.5102\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 195.8419 - val_accuracy: 0.5102\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 152.1557 - val_accuracy: 0.5102\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0171 - accuracy: 0.9913 - val_loss: 189.2703 - val_accuracy: 0.5102\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 232.5992 - val_accuracy: 0.5102\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 179.4155 - val_accuracy: 0.5102\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 131.3151 - val_accuracy: 0.5102\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 102.2469 - val_accuracy: 0.5102\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 6.9801e-04 - accuracy: 1.0000 - val_loss: 88.7066 - val_accuracy: 0.5102\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 9.7887e-04 - accuracy: 1.0000 - val_loss: 77.0079 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 63.7452 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 9.7924e-04 - accuracy: 1.0000 - val_loss: 61.0717 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 1.9188e-04 - accuracy: 1.0000 - val_loss: 60.3471 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.4234e-04 - accuracy: 1.0000 - val_loss: 55.9737 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 52.0969 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 6.7158e-04 - accuracy: 1.0000 - val_loss: 48.4735 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0032 - accuracy: 0.9971 - val_loss: 33.6575 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.5581e-04 - accuracy: 1.0000 - val_loss: 25.6441 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 25.7485 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 0.0025 - accuracy: 0.9971 - val_loss: 25.0259 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.1852e-04 - accuracy: 1.0000 - val_loss: 16.2578 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.5618 - val_accuracy: 0.5102\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9773 - val_accuracy: 0.6122\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3855 - val_accuracy: 0.5850\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.8027\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0051 - accuracy: 0.9971 - val_loss: 9.2184 - val_accuracy: 0.5102\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 4.4748e-04 - accuracy: 1.0000 - val_loss: 50.1344 - val_accuracy: 0.5102\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.7297e-04 - accuracy: 1.0000 - val_loss: 63.3957 - val_accuracy: 0.5102\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 9.2887e-05 - accuracy: 1.0000 - val_loss: 65.0321 - val_accuracy: 0.5102\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.2065e-04 - accuracy: 1.0000 - val_loss: 60.2290 - val_accuracy: 0.5102\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 7.3697e-05 - accuracy: 1.0000 - val_loss: 52.1415 - val_accuracy: 0.5102\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.2540e-04 - accuracy: 1.0000 - val_loss: 46.2910 - val_accuracy: 0.5102\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.8569e-04 - accuracy: 1.0000 - val_loss: 42.1735 - val_accuracy: 0.5102\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 9.4420e-05 - accuracy: 1.0000 - val_loss: 38.7896 - val_accuracy: 0.5102\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.0641e-04 - accuracy: 1.0000 - val_loss: 34.6971 - val_accuracy: 0.5102\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.9003e-04 - accuracy: 1.0000 - val_loss: 31.0025 - val_accuracy: 0.5102\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 6.1849e-05 - accuracy: 1.0000 - val_loss: 27.6639 - val_accuracy: 0.5102\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 5.8345e-05 - accuracy: 1.0000 - val_loss: 23.6592 - val_accuracy: 0.5102\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 1.7138e-04 - accuracy: 1.0000 - val_loss: 20.3362 - val_accuracy: 0.5102\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 2.1719e-04 - accuracy: 1.0000 - val_loss: 16.8386 - val_accuracy: 0.5102\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.2173e-04 - accuracy: 1.0000 - val_loss: 14.1063 - val_accuracy: 0.5102\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.2520e-04 - accuracy: 1.0000 - val_loss: 11.6058 - val_accuracy: 0.5170\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 2.1339e-04 - accuracy: 1.0000 - val_loss: 8.9033 - val_accuracy: 0.5238\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 5.4505e-05 - accuracy: 1.0000 - val_loss: 7.0009 - val_accuracy: 0.5374\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 6.7130e-05 - accuracy: 1.0000 - val_loss: 5.4214 - val_accuracy: 0.5646\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.5886e-04 - accuracy: 1.0000 - val_loss: 4.4453 - val_accuracy: 0.5986\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 2.0801e-05 - accuracy: 1.0000 - val_loss: 3.4238 - val_accuracy: 0.6327\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 2.3132e-04 - accuracy: 1.0000 - val_loss: 2.1837 - val_accuracy: 0.7007\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 7.2064e-05 - accuracy: 1.0000 - val_loss: 1.5316 - val_accuracy: 0.7415\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 5.2430e-04 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.8912\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 8.4583e-05 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9252\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 6.5839e-05 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9116\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 2s 136ms/step - loss: 5.7762e-05 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.9184\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 4.4569e-05 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9252\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 1.3390e-04 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9252\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 2.3446e-05 - accuracy: 1.0000 - val_loss: 0.5138 - val_accuracy: 0.9048\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 6.1116e-05 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.9048\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 6.9247e-05 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.9048\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 9.8541e-05 - accuracy: 1.0000 - val_loss: 0.6126 - val_accuracy: 0.9048\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.3957e-04 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.8503\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.1870e-05 - accuracy: 1.0000 - val_loss: 1.2729 - val_accuracy: 0.7823\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 4.5712e-05 - accuracy: 1.0000 - val_loss: 1.3751 - val_accuracy: 0.7755\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 4.9660e-05 - accuracy: 1.0000 - val_loss: 1.2068 - val_accuracy: 0.7755\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 2.0064e-04 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9184\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 6.1699e-05 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9660\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1.5109e-05 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9592\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.3945e-05 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9660\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 3.6394e-05 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9660\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 3.6146e-05 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9592\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.2508e-05 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9660\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 4.8712e-05 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9660\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.7232e-04 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9592\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.8676e-05 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9592\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 6.4994e-05 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9728\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 2.2925e-04 - accuracy: 1.0000 - val_loss: 5.2474 - val_accuracy: 0.6054\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 6.3968e-05 - accuracy: 1.0000 - val_loss: 7.8891 - val_accuracy: 0.5510\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.9239e-05 - accuracy: 1.0000 - val_loss: 7.5768 - val_accuracy: 0.5578\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 9.5874e-04 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9320\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 1.5487e-05 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9116\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.8347 - val_accuracy: 0.5238\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.7645e-04 - accuracy: 1.0000 - val_loss: 24.0508 - val_accuracy: 0.5102\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 3.6360e-04 - accuracy: 1.0000 - val_loss: 28.7698 - val_accuracy: 0.5102\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 9.1010e-04 - accuracy: 1.0000 - val_loss: 19.0928 - val_accuracy: 0.5102\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.4079e-04 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.8435\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.8355e-04 - accuracy: 1.0000 - val_loss: 2.7358 - val_accuracy: 0.5578\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0033 - accuracy: 0.9971 - val_loss: 7.5671 - val_accuracy: 0.5102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEE2dRY62O66"
      },
      "source": [
        "pred_test= model.predict(X_test)\n",
        "Rows, Cols = pred_test.shape\n",
        "Prediction =[]\n",
        "for i in range(Rows):\n",
        "  if(pred_test[0,0] > pred_test[0,1]):\n",
        "    Prediction.append(0)\n",
        "  else:\n",
        "    Prediction.append(1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIPQG40CyIXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1efbb15-773d-4f5a-ddc5-0726c09254ce"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   1\n",
            "Actual     \n",
            "0        72\n",
            "1        75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ3YoP6I0axi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd561f71-16c9-472e-e919-cb139ce97eab"
      },
      "source": [
        "print(METRICS)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        72\n",
            "           1       0.51      1.00      0.68        75\n",
            "\n",
            "    accuracy                           0.51       147\n",
            "   macro avg       0.26      0.50      0.34       147\n",
            "weighted avg       0.26      0.51      0.34       147\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH"
      },
      "source": [
        "#pred_test"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QISvYcJBgWbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b8f103-b18c-47f4-993b-320709f8382e"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[2] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  prediction_02 = model.predict(result)\n",
        "  Rows, Cols = prediction_02.shape\n",
        "  Prediction =[]\n",
        "  for i in range(Rows):\n",
        "    if(prediction_02[0,0] > prediction_02[0,1]):\n",
        "      Prediction.append(0)\n",
        "    else:\n",
        "      Prediction.append(1)\n",
        "  loc_grao =[];k=0\n",
        "  for i in Prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0   111.0   39.139114   35.777046  ...    0.000000    0.000000    0.000000\n",
            "1   181.0   64.611183   70.103752  ...    8.125424    7.489546    8.058760\n",
            "2   142.0  159.149979  148.153336  ...  102.377907  103.613174  105.808380\n",
            "3   137.0  143.328781  141.488724  ...  144.816925  141.923798  138.413239\n",
            "4   182.0   34.893494   27.840239  ...   65.124260   80.319527  126.071022\n",
            "5   179.0   99.614624  100.183823  ...  112.516174  132.455139  133.112106\n",
            "6   139.0    0.000000    0.000000  ...   41.692921   41.147972   40.521713\n",
            "7   152.0  178.719528  177.253464  ...  133.371185  132.650970  133.094864\n",
            "8   185.0   96.681129  132.600784  ...  142.305817  147.257141  144.821838\n",
            "9   161.0   83.606804   74.506622  ...   58.155014   57.255203   54.892254\n",
            "10  165.0  145.567719  146.000992  ...  141.905365  139.257034  139.172775\n",
            "11  126.0   99.790123   99.172844  ...   52.296299   28.703703    5.938272\n",
            "12  161.0   75.652176   74.446129  ...   57.068054   57.793957   53.914932\n",
            "13  124.0   94.542137   88.524445  ...   56.249733   54.115501   55.869926\n",
            "14  120.0   83.994446   83.994446  ...   87.364449   71.400002   76.309998\n",
            "15  200.0  146.876801  149.571198  ...  116.251587  107.946808  108.013206\n",
            "16  165.0  133.573547  133.608170  ...  111.676071  116.173935  124.666115\n",
            "17  190.0    0.000000    0.000000  ...  129.959763  134.409073  131.125977\n",
            "18  107.0  137.118774  141.535416  ...  148.489655  145.491135  143.215469\n",
            "19  197.0  158.098068  158.052032  ...    6.830297    6.603752    6.704760\n",
            "20  114.0   62.750690   62.908894  ...   60.884583   59.915363   60.724838\n",
            "21  189.0  129.887527  144.880676  ...    7.085048    7.529492    7.200274\n",
            "22  196.0  130.448975  127.061218  ...  147.836731  147.244888  149.244888\n",
            "23  121.0  144.783203  141.146988  ...  145.750504  124.499344  126.497032\n",
            "24  198.0  129.358109  132.031311  ...    7.446485    6.310886    7.472196\n",
            "25  181.0  111.135437  120.768478  ...  131.802246  134.398270  132.861511\n",
            "26  197.0  145.590210  141.660797  ...   65.164421  108.645889  122.922005\n",
            "27  110.0  129.949753  117.354050  ...  100.758347  100.089249   98.759003\n",
            "28  114.0   64.961227   65.560173  ...  100.769470  104.003693  104.917824\n",
            "29  182.0    0.644970    1.177515  ...  113.449715  116.573975  119.260361\n",
            "30  193.0   79.948158   75.678726  ...  139.289474  138.306641  132.797180\n",
            "31  194.0   90.605270   97.088211  ...    6.072377    5.835794    5.283771\n",
            "32  119.0  115.224915  120.269897  ...    0.726644    0.778547    0.723183\n",
            "33  127.0  129.293320  124.487694  ...  162.587830  164.205963  162.656082\n",
            "34  161.0  121.820419   39.907372  ...  106.546326  110.659737  114.606804\n",
            "35  199.0   88.160950   88.877205  ...   63.018555   52.261330    5.296406\n",
            "36  130.0   57.275028   53.071953  ...  141.545105  135.213486  127.862007\n",
            "37  153.0  164.082535  163.959335  ...   91.553680   91.856468   91.103081\n",
            "38  146.0  135.440979  124.886658  ...   55.470821   50.981422   41.978607\n",
            "39  104.0  122.326935  126.965988  ...  158.831375  156.905350  154.254456\n",
            "40  176.0  125.808365  123.927689  ...  155.011887  157.271698  158.744308\n",
            "41  182.0   94.390541   85.952675  ...  141.029587  143.775146  145.550308\n",
            "42  196.0  126.510201  127.959183  ...  128.673462  126.102036  120.734688\n",
            "43  185.0  129.304031  129.779297  ...   74.910614   74.166138   75.320198\n",
            "44  129.0   83.660057   84.534760  ...  110.698929  109.662872  110.028603\n",
            "45  179.0   80.511505   76.957176  ...    7.554976    6.959865    7.178334\n",
            "46  114.0  110.157585   78.672203  ...  104.132965  105.857185  108.116348\n",
            "47  158.0   97.849533  102.441437  ...  100.887039  124.571060  136.335205\n",
            "48  104.0  128.251480  124.883148  ...   61.272194   66.500000   71.184921\n",
            "49  126.0  124.320992  127.432098  ...  169.098770  193.345673  213.123459\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "e1347d7c-6df3-435f-f746-ceab74fd5b8b"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marquesgabi_paper_fev_2021'...\n",
            "remote: Enumerating objects: 692, done.\u001b[K\n",
            "remote: Counting objects: 100% (453/453), done.\u001b[K\n",
            "remote: Compressing objects: 100% (451/451), done.\u001b[K\n",
            "remote: Total 692 (delta 285), reused 0 (delta 0), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (692/692), 5.65 MiB | 13.51 MiB/s, done.\n",
            "Resolving deltas: 100% (422/422), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "427390a9-4a63-462b-95a8-476b1971631f"
      },
      "source": [
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "\n",
        "%cd Doutorado\n",
        "\n",
        "PSD_imageJ = 'Amostra7.csv' \n",
        "PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 458, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 458 (delta 98), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (458/458), 166.03 MiB | 23.36 MiB/s, done.\n",
            "Resolving deltas: 100% (221/221), done.\n",
            "Checking out files: 100% (90/90), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "   Unnamed: 0   Area\n",
            "0           1  1.387\n",
            "1           2  1.626\n",
            "2           3  1.336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tEPjIBnv_xM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d52507-2a08-4ce3-a76f-545ff67059e9"
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfagXc-Mv3oa"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekBHQOT_6CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a56ee407-27e6-4c24-f8ee-8bd9487deef2"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111.0</td>\n",
              "      <td>39.139114</td>\n",
              "      <td>35.777046</td>\n",
              "      <td>34.969563</td>\n",
              "      <td>31.241135</td>\n",
              "      <td>28.902523</td>\n",
              "      <td>28.072720</td>\n",
              "      <td>25.939939</td>\n",
              "      <td>20.325462</td>\n",
              "      <td>42.173687</td>\n",
              "      <td>95.541428</td>\n",
              "      <td>127.498009</td>\n",
              "      <td>133.011688</td>\n",
              "      <td>124.186516</td>\n",
              "      <td>113.438354</td>\n",
              "      <td>111.186424</td>\n",
              "      <td>112.927200</td>\n",
              "      <td>112.789948</td>\n",
              "      <td>113.845230</td>\n",
              "      <td>116.288612</td>\n",
              "      <td>116.469116</td>\n",
              "      <td>115.610985</td>\n",
              "      <td>110.651321</td>\n",
              "      <td>97.152580</td>\n",
              "      <td>83.539726</td>\n",
              "      <td>85.084084</td>\n",
              "      <td>84.607338</td>\n",
              "      <td>82.277412</td>\n",
              "      <td>80.693123</td>\n",
              "      <td>47.732246</td>\n",
              "      <td>44.228310</td>\n",
              "      <td>34.752861</td>\n",
              "      <td>30.267998</td>\n",
              "      <td>27.090820</td>\n",
              "      <td>26.933039</td>\n",
              "      <td>20.677055</td>\n",
              "      <td>19.302168</td>\n",
              "      <td>62.780128</td>\n",
              "      <td>103.158340</td>\n",
              "      <td>115.743607</td>\n",
              "      <td>...</td>\n",
              "      <td>31.057219</td>\n",
              "      <td>15.418228</td>\n",
              "      <td>2.361415</td>\n",
              "      <td>2.694668</td>\n",
              "      <td>1.510348</td>\n",
              "      <td>1.449476</td>\n",
              "      <td>0.990991</td>\n",
              "      <td>0.205340</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368233</td>\n",
              "      <td>0.379434</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.928577</td>\n",
              "      <td>1.144144</td>\n",
              "      <td>1.710170</td>\n",
              "      <td>2.688581</td>\n",
              "      <td>1.604578</td>\n",
              "      <td>1.520493</td>\n",
              "      <td>2.127262</td>\n",
              "      <td>1.878013</td>\n",
              "      <td>1.252252</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.973216</td>\n",
              "      <td>0.504505</td>\n",
              "      <td>0.104537</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>181.0</td>\n",
              "      <td>64.611183</td>\n",
              "      <td>70.103752</td>\n",
              "      <td>91.097931</td>\n",
              "      <td>108.381950</td>\n",
              "      <td>115.860672</td>\n",
              "      <td>117.034187</td>\n",
              "      <td>107.872879</td>\n",
              "      <td>104.763741</td>\n",
              "      <td>106.575241</td>\n",
              "      <td>107.299995</td>\n",
              "      <td>104.803528</td>\n",
              "      <td>103.313156</td>\n",
              "      <td>106.252319</td>\n",
              "      <td>113.190453</td>\n",
              "      <td>122.381989</td>\n",
              "      <td>133.801666</td>\n",
              "      <td>148.853531</td>\n",
              "      <td>156.481628</td>\n",
              "      <td>158.514191</td>\n",
              "      <td>160.457169</td>\n",
              "      <td>148.662247</td>\n",
              "      <td>124.059845</td>\n",
              "      <td>104.241844</td>\n",
              "      <td>96.861427</td>\n",
              "      <td>90.854767</td>\n",
              "      <td>77.062462</td>\n",
              "      <td>71.725288</td>\n",
              "      <td>67.748604</td>\n",
              "      <td>68.823151</td>\n",
              "      <td>63.900650</td>\n",
              "      <td>104.141609</td>\n",
              "      <td>126.701180</td>\n",
              "      <td>125.180351</td>\n",
              "      <td>123.899368</td>\n",
              "      <td>118.144478</td>\n",
              "      <td>108.938591</td>\n",
              "      <td>106.880112</td>\n",
              "      <td>106.651787</td>\n",
              "      <td>105.039040</td>\n",
              "      <td>...</td>\n",
              "      <td>0.306798</td>\n",
              "      <td>0.274870</td>\n",
              "      <td>0.312231</td>\n",
              "      <td>0.346967</td>\n",
              "      <td>0.229663</td>\n",
              "      <td>0.191630</td>\n",
              "      <td>0.259089</td>\n",
              "      <td>0.395653</td>\n",
              "      <td>0.416074</td>\n",
              "      <td>0.298251</td>\n",
              "      <td>0.425597</td>\n",
              "      <td>0.429016</td>\n",
              "      <td>8.535667</td>\n",
              "      <td>6.537438</td>\n",
              "      <td>7.978420</td>\n",
              "      <td>7.465493</td>\n",
              "      <td>7.734105</td>\n",
              "      <td>7.934832</td>\n",
              "      <td>7.896371</td>\n",
              "      <td>7.737402</td>\n",
              "      <td>7.251092</td>\n",
              "      <td>7.553647</td>\n",
              "      <td>7.557920</td>\n",
              "      <td>7.827997</td>\n",
              "      <td>7.864748</td>\n",
              "      <td>7.998078</td>\n",
              "      <td>8.616007</td>\n",
              "      <td>7.858765</td>\n",
              "      <td>7.756204</td>\n",
              "      <td>8.124874</td>\n",
              "      <td>8.101189</td>\n",
              "      <td>7.728000</td>\n",
              "      <td>7.938463</td>\n",
              "      <td>7.808980</td>\n",
              "      <td>7.076586</td>\n",
              "      <td>7.842556</td>\n",
              "      <td>7.570008</td>\n",
              "      <td>8.125424</td>\n",
              "      <td>7.489546</td>\n",
              "      <td>8.058760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>142.0</td>\n",
              "      <td>159.149979</td>\n",
              "      <td>148.153336</td>\n",
              "      <td>119.222572</td>\n",
              "      <td>85.171791</td>\n",
              "      <td>89.834557</td>\n",
              "      <td>102.524101</td>\n",
              "      <td>106.470345</td>\n",
              "      <td>108.921844</td>\n",
              "      <td>111.158707</td>\n",
              "      <td>112.365997</td>\n",
              "      <td>115.557823</td>\n",
              "      <td>117.473328</td>\n",
              "      <td>115.376907</td>\n",
              "      <td>115.055550</td>\n",
              "      <td>121.093643</td>\n",
              "      <td>132.005356</td>\n",
              "      <td>147.896439</td>\n",
              "      <td>154.822845</td>\n",
              "      <td>130.740128</td>\n",
              "      <td>127.963699</td>\n",
              "      <td>127.111885</td>\n",
              "      <td>121.867691</td>\n",
              "      <td>117.165848</td>\n",
              "      <td>113.555046</td>\n",
              "      <td>111.993454</td>\n",
              "      <td>110.481056</td>\n",
              "      <td>107.501289</td>\n",
              "      <td>103.672684</td>\n",
              "      <td>159.926010</td>\n",
              "      <td>154.293396</td>\n",
              "      <td>140.522324</td>\n",
              "      <td>112.456856</td>\n",
              "      <td>107.682205</td>\n",
              "      <td>112.384453</td>\n",
              "      <td>113.415794</td>\n",
              "      <td>114.342987</td>\n",
              "      <td>117.290413</td>\n",
              "      <td>120.091064</td>\n",
              "      <td>120.925026</td>\n",
              "      <td>...</td>\n",
              "      <td>127.639359</td>\n",
              "      <td>123.096207</td>\n",
              "      <td>116.448914</td>\n",
              "      <td>113.212250</td>\n",
              "      <td>106.395561</td>\n",
              "      <td>101.833366</td>\n",
              "      <td>99.927193</td>\n",
              "      <td>100.855980</td>\n",
              "      <td>102.337433</td>\n",
              "      <td>103.208298</td>\n",
              "      <td>105.419159</td>\n",
              "      <td>109.880592</td>\n",
              "      <td>152.138062</td>\n",
              "      <td>146.487213</td>\n",
              "      <td>142.609009</td>\n",
              "      <td>140.225754</td>\n",
              "      <td>139.951614</td>\n",
              "      <td>137.777420</td>\n",
              "      <td>141.731812</td>\n",
              "      <td>148.103943</td>\n",
              "      <td>155.255127</td>\n",
              "      <td>158.551300</td>\n",
              "      <td>149.034317</td>\n",
              "      <td>124.633217</td>\n",
              "      <td>119.476295</td>\n",
              "      <td>119.024803</td>\n",
              "      <td>119.664154</td>\n",
              "      <td>123.366592</td>\n",
              "      <td>126.541557</td>\n",
              "      <td>124.058327</td>\n",
              "      <td>117.693520</td>\n",
              "      <td>113.539581</td>\n",
              "      <td>107.348946</td>\n",
              "      <td>101.805206</td>\n",
              "      <td>99.661377</td>\n",
              "      <td>99.332481</td>\n",
              "      <td>100.984932</td>\n",
              "      <td>102.377907</td>\n",
              "      <td>103.613174</td>\n",
              "      <td>105.808380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>137.0</td>\n",
              "      <td>143.328781</td>\n",
              "      <td>141.488724</td>\n",
              "      <td>145.284729</td>\n",
              "      <td>150.819275</td>\n",
              "      <td>153.772766</td>\n",
              "      <td>158.294357</td>\n",
              "      <td>160.300430</td>\n",
              "      <td>160.583344</td>\n",
              "      <td>165.866959</td>\n",
              "      <td>170.467743</td>\n",
              "      <td>163.890442</td>\n",
              "      <td>94.249138</td>\n",
              "      <td>79.242363</td>\n",
              "      <td>72.557083</td>\n",
              "      <td>75.949959</td>\n",
              "      <td>80.732857</td>\n",
              "      <td>86.125679</td>\n",
              "      <td>110.439819</td>\n",
              "      <td>133.223770</td>\n",
              "      <td>137.868042</td>\n",
              "      <td>138.710205</td>\n",
              "      <td>136.883057</td>\n",
              "      <td>132.596725</td>\n",
              "      <td>127.895676</td>\n",
              "      <td>128.467163</td>\n",
              "      <td>127.266968</td>\n",
              "      <td>127.784210</td>\n",
              "      <td>126.764771</td>\n",
              "      <td>135.089142</td>\n",
              "      <td>136.179871</td>\n",
              "      <td>143.785324</td>\n",
              "      <td>147.929520</td>\n",
              "      <td>155.417175</td>\n",
              "      <td>163.004486</td>\n",
              "      <td>162.746918</td>\n",
              "      <td>160.860291</td>\n",
              "      <td>166.854858</td>\n",
              "      <td>171.376801</td>\n",
              "      <td>163.480942</td>\n",
              "      <td>...</td>\n",
              "      <td>144.650223</td>\n",
              "      <td>146.899033</td>\n",
              "      <td>149.801376</td>\n",
              "      <td>152.468964</td>\n",
              "      <td>155.057755</td>\n",
              "      <td>153.420273</td>\n",
              "      <td>150.561508</td>\n",
              "      <td>148.615845</td>\n",
              "      <td>147.023651</td>\n",
              "      <td>143.221863</td>\n",
              "      <td>138.927902</td>\n",
              "      <td>135.946289</td>\n",
              "      <td>175.447968</td>\n",
              "      <td>180.413605</td>\n",
              "      <td>182.691299</td>\n",
              "      <td>183.029938</td>\n",
              "      <td>170.151031</td>\n",
              "      <td>125.751129</td>\n",
              "      <td>123.149132</td>\n",
              "      <td>123.688095</td>\n",
              "      <td>123.134422</td>\n",
              "      <td>121.415527</td>\n",
              "      <td>123.561829</td>\n",
              "      <td>127.440025</td>\n",
              "      <td>131.973465</td>\n",
              "      <td>135.291168</td>\n",
              "      <td>138.049713</td>\n",
              "      <td>142.178635</td>\n",
              "      <td>145.094879</td>\n",
              "      <td>147.015289</td>\n",
              "      <td>149.574188</td>\n",
              "      <td>151.419998</td>\n",
              "      <td>150.910583</td>\n",
              "      <td>151.027481</td>\n",
              "      <td>149.799179</td>\n",
              "      <td>149.104736</td>\n",
              "      <td>147.525879</td>\n",
              "      <td>144.816925</td>\n",
              "      <td>141.923798</td>\n",
              "      <td>138.413239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>182.0</td>\n",
              "      <td>34.893494</td>\n",
              "      <td>27.840239</td>\n",
              "      <td>22.124262</td>\n",
              "      <td>18.798819</td>\n",
              "      <td>11.473374</td>\n",
              "      <td>7.082841</td>\n",
              "      <td>70.810654</td>\n",
              "      <td>136.467468</td>\n",
              "      <td>145.284027</td>\n",
              "      <td>155.366867</td>\n",
              "      <td>182.573975</td>\n",
              "      <td>153.082855</td>\n",
              "      <td>131.680481</td>\n",
              "      <td>186.461548</td>\n",
              "      <td>201.958603</td>\n",
              "      <td>59.828407</td>\n",
              "      <td>88.502960</td>\n",
              "      <td>92.668640</td>\n",
              "      <td>91.497055</td>\n",
              "      <td>93.840240</td>\n",
              "      <td>97.804741</td>\n",
              "      <td>98.573975</td>\n",
              "      <td>92.615402</td>\n",
              "      <td>35.621304</td>\n",
              "      <td>4.011835</td>\n",
              "      <td>2.946746</td>\n",
              "      <td>4.781066</td>\n",
              "      <td>53.443790</td>\n",
              "      <td>69.745567</td>\n",
              "      <td>73.295860</td>\n",
              "      <td>82.964508</td>\n",
              "      <td>89.272202</td>\n",
              "      <td>99.473373</td>\n",
              "      <td>94.917168</td>\n",
              "      <td>127.402374</td>\n",
              "      <td>138.479279</td>\n",
              "      <td>144.017761</td>\n",
              "      <td>151.686401</td>\n",
              "      <td>169.177521</td>\n",
              "      <td>...</td>\n",
              "      <td>141.260361</td>\n",
              "      <td>65.035507</td>\n",
              "      <td>65.686394</td>\n",
              "      <td>68.112434</td>\n",
              "      <td>65.491127</td>\n",
              "      <td>62.946751</td>\n",
              "      <td>61.147930</td>\n",
              "      <td>61.041424</td>\n",
              "      <td>61.621307</td>\n",
              "      <td>62.118347</td>\n",
              "      <td>104.816574</td>\n",
              "      <td>137.195267</td>\n",
              "      <td>172.325470</td>\n",
              "      <td>139.698227</td>\n",
              "      <td>140.071014</td>\n",
              "      <td>136.650894</td>\n",
              "      <td>132.372803</td>\n",
              "      <td>128.065094</td>\n",
              "      <td>124.810661</td>\n",
              "      <td>120.467468</td>\n",
              "      <td>120.431969</td>\n",
              "      <td>120.420135</td>\n",
              "      <td>118.278107</td>\n",
              "      <td>123.260361</td>\n",
              "      <td>125.508881</td>\n",
              "      <td>132.905334</td>\n",
              "      <td>138.183456</td>\n",
              "      <td>146.147949</td>\n",
              "      <td>146.384628</td>\n",
              "      <td>71.958588</td>\n",
              "      <td>61.710068</td>\n",
              "      <td>66.313614</td>\n",
              "      <td>62.603558</td>\n",
              "      <td>60.911251</td>\n",
              "      <td>59.420124</td>\n",
              "      <td>60.473381</td>\n",
              "      <td>62.449707</td>\n",
              "      <td>65.124260</td>\n",
              "      <td>80.319527</td>\n",
              "      <td>126.071022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "0  111.0   39.139114   35.777046  ...    0.000000    0.000000    0.000000\n",
              "1  181.0   64.611183   70.103752  ...    8.125424    7.489546    8.058760\n",
              "2  142.0  159.149979  148.153336  ...  102.377907  103.613174  105.808380\n",
              "3  137.0  143.328781  141.488724  ...  144.816925  141.923798  138.413239\n",
              "4  182.0   34.893494   27.840239  ...   65.124260   80.319527  126.071022\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q09DRGPtM75"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "\n",
        "# Area = np.array(PSD_new.iloc[:,1])\n",
        "Area = PSD_new['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aUb2_-jsY1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758b6a73-8b4a-4e3e-f703-680934df9796"
      },
      "source": [
        "PSD_new.iloc[:,1].values"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.387, 1.626, 1.336, 0.64 , 2.211, 1.12 , 0.974, 1.237, 1.29 ,\n",
              "       3.755, 2.778, 1.256, 1.386, 1.302, 1.071, 1.497, 1.518, 1.244,\n",
              "       1.532, 1.325, 1.519, 1.895, 1.22 , 1.241, 1.301, 1.429, 0.667,\n",
              "       2.157, 1.052, 2.082, 1.517, 1.281, 0.784, 1.067, 2.764, 1.215,\n",
              "       0.943, 2.182, 1.486, 1.569, 2.667, 0.709, 1.006, 1.6  , 1.408,\n",
              "       3.16 , 2.465, 2.284, 1.273, 1.256, 3.021, 1.701, 1.955, 5.248,\n",
              "       1.627, 1.367, 1.592, 2.718, 1.658, 1.128, 2.192, 1.508, 2.547,\n",
              "       1.945, 1.606, 3.482, 1.756, 1.457, 1.864, 1.821, 1.314, 1.715,\n",
              "       1.015, 1.345, 1.265, 1.844, 1.396, 1.785, 1.694, 1.413, 1.368,\n",
              "       2.21 , 1.034, 1.367, 1.943, 1.008, 1.279, 1.579, 1.444, 1.879,\n",
              "       1.466, 2.154, 1.794, 3.149, 1.883, 1.692, 1.163, 1.297, 2.949,\n",
              "       1.09 , 1.444, 1.524])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J705kDqsE8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f93b3a4-61a4-4102-b983-7023c82ae2d5"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK1GBUHWiIr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f95bb7ac-75ee-409c-b22e-6ac99a2e5765"
      },
      "source": [
        "Freq = [12.8, 23.2, 29.2, 18.4, 12.0, 0.8]\n",
        "Freq2 = [16.4, 22.2, 29.6, 20.8, 8., 0.2]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434, 0.]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "444567c0-bc64-4781-de41-42a3edd6c85d"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f929ca5d550>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "ce3857f9-0aa4-48fb-edc2-2d7ed948fe39"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.03921569, 0.25490196, 0.6372549 , 0.80392157,\n",
              "         0.89215686, 0.97058824, 0.99019608, 0.99019608, 1.        ],\n",
              "        [0.1       , 0.24      , 0.42      , 0.68      , 0.96      ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.71139016, 0.89874604, 1.08610192, 1.2734578 , 1.46081368,\n",
              "        1.64816956, 1.83552544, 2.02288132, 2.2102372 , 2.39759308,\n",
              "        2.58494896]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xENlBUUxfTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "59da9da4-a94f-43ee-b8ef-c53436eca245"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r_squared = 0.921862636972828\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KukfpGTTKlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "47a72502-bcb3-4621-f38a-f3a8e292ec79"
      },
      "source": [
        "df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.921863</td>\n",
              "      <td>0.997085</td>\n",
              "      <td>0.510204</td>\n",
              "      <td>0.003307</td>\n",
              "      <td>7.567057</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2  ...  loss test                                 Details\n",
              "0  20  20  ...   7.567057  3 layers of Convolution: 64, 128, 256 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHa1j4HT9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "c529bbd9-d9a9-42eb-8868-c1ea18d897db"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.71139016 0.89874604 1.08610192 1.2734578  1.46081368 1.64816956\n",
            " 1.83552544 2.02288132 2.2102372  2.39759308 2.58494896]\n",
            "[[ 0.          3.92156863 21.56862745 38.23529412 16.66666667  8.82352941\n",
            "   7.84313725  1.96078431  0.          0.98039216]\n",
            " [10.         14.         18.         26.         28.          4.\n",
            "   0.          0.          0.          0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da285bff-37e2-4389-eaf3-0d855586cedf"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "26f6bd95-4355-4795-b3a9-620b3e13be63"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f92a45a6bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVRUlEQVR4nO3df5BddZnn8fdDaOhZyUIgTUwRQgdIgaRYAjZBBmrMBGEzsCNQhQo1RYUtqCAOlCmnZo1QJcF1C9DMgFrsOGFgzSAoFJpV1JklBaEsVMAOBAj0DJAQMVRImvBD2ZVgyLN/3JPYNP3jdve9fftr3q+qW33O95xz79OnTz459/z4nshMJEnl2afVBUiSRscAl6RCGeCSVCgDXJIKZYBLUqH2Hc8Pmzp1anZ2do7nR0pS8dauXftqZnb0bx/XAO/s7KS7u3s8P1KSihcRvxqove5DKBExKSKeiIgfVeOzIuLRiHghIu6OiP0aVawkaXgjOQb+WaCnz/iNwE2ZeTTwOnBpIwuTJA2trgCPiBnAOcA/VeMBLADurWZZCZzXjAIlSQOr9xj4zcB/AyZX44cAb2Tmzmp8M3DYQAtGxGJgMcDMmTNHX6mk4v3+979n8+bNvP32260uZUJqb29nxowZtLW11TX/sAEeEf8F2JaZayNi/kgLyswVwAqArq4uO16R9mKbN29m8uTJdHZ2Uvsir90yk+3bt7N582ZmzZpV1zL17IGfBnw8Is4G2oH/CHwNOCgi9q32wmcAL4+ybkl7ibffftvwHkREcMghh9Db21v3MsMeA8/ML2TmjMzsBC4EHszMvwLWABdUsy0CfjDykiXtbQzvwY103YzlTszPA5+LiBeoHRO/bQzvJUkaoRHdyJOZDwEPVcMbgXmNL0nS3qJz6Y8b+n6bbjhn2HkOOOAA3nrrrYZ+7mjMnz+f5cuX09XVNer3GNc7MVWW0fzjqucfkKTGsDMrSXulhx56iI9+9KOce+65HHnkkSxdupQ777yTefPmcfzxx7NhwwYA7rvvPk455RROPPFEPvaxj7F161YAent7OfPMM5kzZw6XXXYZRxxxBK+++ioA3/72t5k3bx5z587l8ssv5913323K72CAS9prPfnkk3zzm9+kp6eHO+64g+eee47HHnuMyy67jG984xsAnH766TzyyCM88cQTXHjhhXzlK18B4LrrrmPBggU888wzXHDBBbz00ksA9PT0cPfdd/Ozn/2MdevWMWnSJO68886m1O8hFEl7rZNPPpnp06cDcNRRR3HWWWcBcPzxx7NmzRqgdu36pz71KbZs2cI777yz5xrthx9+mFWrVgGwcOFCpkyZAsADDzzA2rVrOfnkkwH43e9+x6GHHtqU+g1wSXut/ffff8/wPvvss2d8n332YefO2o3mV111FZ/73Of4+Mc/zkMPPcSyZcuGfM/MZNGiRVx//fVNq3s3D6FI0hDefPNNDjus1lPIypUr97Sfdtpp3HPPPQDcf//9vP766wCcccYZ3HvvvWzbtg2A1157jV/9asDeYMfMPXBJLVPCVUvLli3jE5/4BFOmTGHBggW8+OKLAFx77bVcdNFF3HHHHZx66ql88IMfZPLkyUydOpUvf/nLnHXWWezatYu2tjZuueUWjjjiiPe8786dO9/zDWA0InP8uifp6upKH+hQDi8jVKP19PTwoQ99qNVlNMSOHTuYNGkS++67L7/4xS+44oorWLduXd3LHn300axfv54DDzzwPdMGWkcRsTYz33fBuHvgkjQKL730Ep/85CfZtWsX++23H7feemtdy3V3d3PxxRfzmc985n3hPVIGuCSNwuzZs3niiSdGvFxXVxc9PT3Dz1gHT2JKUqEMcEkqlAEuSYUywCWpUJ7ElNQ6y8Z2Fcb73+/NYWd55ZVXWLJkCb/85S856KCDmDZtGjfffDPHHHMMX//617nqqqsAuPLKK+nq6uKSSy7hkksuYfXq1WzcuJH999+fV199la6uLjZt2tTY+kfIPXBJe43M5Pzzz2f+/Pls2LCBtWvXcv3117N161YOPfRQvva1r/HOO+8MuOykSZO4/fbbx7nioRngkvYaa9asoa2tjU9/+tN72k444QQOP/xwOjo6OOOMM95zu3xfS5Ys4aabbtrTR8pEYIBL2musX7+eD3/4w4NO//znP8/y5csH7L975syZnH766dxxxx3NLHFEhg3wiGiPiMci4smIeCYirqvavxURL0bEuuo1t/nlSlLzHHnkkZxyyincddddA07/whe+wFe/+lV27do1zpUNrJ498B3Agsw8AZgLLIyIj1TT/jYz51av+joBkKQWmTNnDmvXrh1ynquvvpobb7yRgfqJmj17NnPnzt3TC2GrDRvgWbP7CaBt1Wv8esCSpAZZsGABO3bsYMWKFXvannrqKX7961/vGT/22GM57rjjuO+++wZ8j2uuuYbly5c3vdZ61HUZYURMAtYCRwO3ZOajEXEF8D8i4ovAA8DSzNwxwLKLgcVQO4YkSXvUcdlfI0UEq1atYsmSJdx44420t7fT2dnJzTff/J75rrnmGk488cQB32POnDmcdNJJPP744+NR8pBG1J1sRBwErAKuArYDrwD7ASuADZn5paGWtzvZstidrBrtj6k72WYZSXeyI7oKJTPfANYACzNzS3V4ZQfwv4B5Y6hZkjRC9VyF0lHteRMRfwKcCfxbREyv2gI4D1jfzEIlSe9VzzHw6cDK6jj4PsA9mfmjiHgwIjqAANYBnx7qTSQJandD1vb71N9In5A2bIBn5lPA+47mZ+aCEX2SpL1ee3s727dv55BDDjHE+8lMtm/fTnt7e93L2JmVpHEzY8YMNm/eTG9vb6tLmZDa29uZMWNG3fMb4JLGTVtbG7NmzWp1GX807AtFkgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqEMcEkqlAEuSYUywCWpUAa4JBXKAJekQtXzTMz2iHgsIp6MiGci4rqqfVZEPBoRL0TE3RGxX/PLlSTtVs8e+A5gQWaeAMwFFkbER4AbgZsy82jgdeDS5pUpSepv2ADPmreq0bbqlcAC4N6qfSW1J9NLksZJXcfAI2JSRKwDtgGrgQ3AG5m5s5plM3BYc0qUJA2krgDPzHczcy4wA5gHHFvvB0TE4ojojohuH2QqSY0zoqtQMvMNYA1wKnBQROx+KPIM4OVBllmRmV2Z2dXR0TGmYiVJf1DPVSgdEXFQNfwnwJlAD7Ugv6CabRHwg2YVKUl6v32Hn4XpwMqImEQt8O/JzB9FxLPAdyPiy8ATwG1NrFOS1M+wAZ6ZTwEnDtC+kdrxcElSC3gnpiQVygCXpEIZ4JJUKANckgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqEMcEkqlAEuSYUywCWpUAa4JBXKAJekQtXzUOPDI2JNRDwbEc9ExGer9mUR8XJErKteZze/XEnSbvU81Hgn8DeZ+XhETAbWRsTqatpNmbm8eeVJkgZTz0ONtwBbquHfRkQPcFizC5MkDW1Ex8AjopPaE+ofrZqujIinIuL2iJgyyDKLI6I7Irp7e3vHVKwk6Q/qDvCIOAD4HrAkM38D/ANwFDCX2h763w20XGauyMyuzOzq6OhoQMmSJKgzwCOijVp435mZ3wfIzK2Z+W5m7gJuBeY1r0xJUn/1XIUSwG1AT2b+fZ/26X1mOx9Y3/jyJEmDqecqlNOAi4GnI2Jd1XY1cFFEzAUS2ARc3pQKJUkDqucqlIeBGGDSTxpfjiSpXt6JKUmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgplgEtSoQxwSSqUAS5JhTLAJalQ9fSFohbqXPrjES+z6YZzmlCJpInGPXBJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUqHqeiXl4RKyJiGcj4pmI+GzVfnBErI6I56ufU5pfriRpt3r2wHcCf5OZxwEfAf46Io4DlgIPZOZs4IFqXJI0ToYN8MzckpmPV8O/BXqAw4BzgZXVbCuB85pVpCTp/UZ0DDwiOoETgUeBaZm5pZr0CjCtoZVJkoZUd4BHxAHA94AlmfmbvtMyM4EcZLnFEdEdEd29vb1jKlaS9Ad1BXhEtFEL7zsz8/tV89aImF5Nnw5sG2jZzFyRmV2Z2dXR0dGImiVJ1HcVSgC3AT2Z+fd9Jv0QWFQNLwJ+0PjyJEmDqac3wtOAi4GnI2Jd1XY1cANwT0RcCvwK+GRzSpQkDWTYAM/Mh4EYZPIZjS1HklQv78SUpEIZ4JJUKANckgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCgDXJIKVU9nVtK461z64xEvs+mGc5pQiTRxuQcuSYUywCWpUAa4JBXKAJekQhngklQoA1ySClXPQ41vj4htEbG+T9uyiHg5ItZVr7ObW6Ykqb969sC/BSwcoP2mzJxbvX7S2LIkScMZNsAz86fAa+NQiyRpBMZyDPzKiHiqOsQyZbCZImJxRHRHRHdvb+8YPk6S1NdoA/wfgKOAucAW4O8GmzEzV2RmV2Z2dXR0jPLjJEn9jSrAM3NrZr6bmbuAW4F5jS1LkjScUQV4REzvM3o+sH6weSVJzTFsb4QR8R1gPjA1IjYD1wLzI2IukMAm4PIm1ihJGsCwAZ6ZFw3QfFsTapHGZtmBI5z/zebUIY0T78SUpEIZ4JJUKANckgplgEtSoQxwSSqUDzVWY3kliDRu3AOXpEIZ4JJUKANckgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqGGDfCIuD0itkXE+j5tB0fE6oh4vvo5pbllSpL6q2cP/FvAwn5tS4EHMnM28EA1LkkaR8MGeGb+FHitX/O5wMpqeCVwXoPrkiQNY7THwKdl5pZq+BVg2mAzRsTiiOiOiO7e3t5Rfpwkqb8xn8TMzARyiOkrMrMrM7s6OjrG+nGSpMpoA3xrREwHqH5ua1xJkqR6jDbAfwgsqoYXAT9oTDmSpHrVcxnhd4BfAMdExOaIuBS4ATgzIp4HPlaNS5LG0bAPNc7MiwaZdEaDa1Gj+GDhMelc+uMRL7PphnOaUIk0NO/ElKRCGeCSVCgDXJIKZYBLUqGGPYkpaXyN9CSqJ1D3Xu6BS1KhDHBJKpQBLkmFMsAlqVAGuCQVyqtQmsXb2SU1mXvgklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVBjuowwIjYBvwXeBXZmZlcjipIkDa8R14H/eWa+2oD3kSSNgIdQJKlQY90DT+D+iEjgHzNzRf8ZImIxsBhg5syZY/y4EfJuSEl/xMa6B356Zp4E/AXw1xHxZ/1nyMwVmdmVmV0dHR1j/DhJ0m5jCvDMfLn6uQ1YBcxrRFGSpOGNOsAj4gMRMXn3MHAWsL5RhUmShjaWY+DTgFURsft97srMf21IVZKkYY06wDNzI3BCA2uRJI2A/YHXYaRPCQfY1N6EQiSpD68Dl6RCGeCSVCgDXJIKZYBLUqEMcEkqlAEuSYUywCWpUAa4JBXKAJekQnknptQIfyR9z4/0ruNNN5zTpEpUD/fAJalQBrgkFcoAl6RCGeCSVChPYkra65V68tY9cEkqlAEuSYUaU4BHxMKI+PeIeCEiljaqKEnS8MbyVPpJwC3AXwDHARdFxHGNKkySNLSx7IHPA17IzI2Z+Q7wXeDcxpQlSRpOZOboFoy4AFiYmZdV4xcDp2Tmlf3mWwwsrkaPAf599OXuMRV4tQHv02wl1FlCjVBGnSXUCGXUWUKNMH51HpGZHf0bm34ZYWauAFY08j0jojszuxr5ns1QQp0l1Ahl1FlCjVBGnSXUCK2vcyyHUF4GDu8zPqNqkySNg7EE+C+B2RExKyL2Ay4EftiYsiRJwxn1IZTM3BkRVwL/B5gE3J6ZzzSssqE19JBME5VQZwk1Qhl1llAjlFFnCTVCi+sc9UlMSVJreSemJBXKAJekQk24AB/u9vyIuCki1lWv5yLijT7T3u0zrWknVCPi9ojYFhHrB5keEfH16nd4KiJO6jNtUUQ8X70WtbDGv6pqezoifh4RJ/SZtqlqXxcR3c2qsc4650fEm33+rl/sM21cunKoo8a/7VPf+mo7PLiaNi7rMiIOj4g1EfFsRDwTEZ8dYJ6JsF3WU2dLt806a2z5dglAZk6YF7WToRuAI4H9gCeB44aY/ypqJ093j781TnX+GXASsH6Q6WcD/wIE8BHg0ar9YGBj9XNKNTylRTX+6e7PptYdwqN9pm0Cpk6QdTkf+NFYt5Vm1thv3r8EHhzvdQlMB06qhicDz/VfHxNku6ynzpZum3XW2PLtMjMn3B74SG/Pvwj4zrhU1kdm/hR4bYhZzgX+OWseAQ6KiOnAfwZWZ+Zrmfk6sBpY2IoaM/PnVQ0Aj1C7jn/c1bEuBzNuXTmMsMZWbZNbMvPxavi3QA9wWL/ZJsJ2OWydrd4261yXgxnXLkYmWoAfBvy6z/hmBllxEXEEMAt4sE9ze0R0R8QjEXFe88oc1mC/R92/3zi7lNqe2W4J3B8Ra6PWFUKrnRoRT0bEv0TEnKptwq3LiPgP1ILve32ax31dRkQncCLwaL9JE2q7HKLOvlq6bQ5TY8u3y5KfyHMhcG9mvtun7YjMfDkijgQejIinM3NDi+orQkT8ObV/JKf3aT69Wo+HAqsj4t+qvdBWeJza3/WtiDgb+N/A7BbVMpy/BH6WmX331sd1XUbEAdT+A1mSmb9p1ueMVT11tnrbHKbGCbFdTrQ98JHcnn8h/b6qZubL1c+NwEPU/udshcF+jwnV/UBE/Cfgn4BzM3P77vY+63EbsIra18KWyMzfZOZb1fBPgLaImMoEW5eVobbJpq/LiGijFjh3Zub3B5hlQmyXddTZ8m1zuBonzHbZzJMBI31R+0awkdqhkd0nAOYMMN+x1E5mRJ+2KcD+1fBU4HmaePIA6GTwE2/n8N6TRY9V7QcDL1a1TqmGD25RjTOBF4A/7df+AWByn+GfU+t1spl/96Hq/ODuvzO1f6wvVeu1rm1lPGqsph9I7Tj5B1qxLqt18s/AzUPM0/Ltss46W7pt1lnjhNguJ9QhlBzk9vyI+BLQnZm7Lw28EPhuVmuv8iHgHyNiF7VvFjdk5rPNqDMivkPtLPTUiNgMXAu0Vb/DN4GfUDvj/wLw/4D/Wk17LSL+O7V+ZAC+lO/9uj2eNX4ROAT4nxEBsDNrvapNA1ZVbfsCd2XmvzajxjrrvAC4IiJ2Ar8DLqz+7uPWlUMdNQKcD9yfmf+3z6LjuS5PAy4Gno6IdVXb1dTCcMJsl3XW2epts54aW75dgrfSS1KxJtoxcElSnQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVKj/D5xtdakGn6TnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27cc85bc-0656-4f17-c31c-eb6aee13757f"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.3289030245084366,\n",
              "  1.4388493665910183,\n",
              "  1.3042423209535017,\n",
              "  0.9027033336764101,\n",
              "  1.6778356991700483,\n",
              "  1.1941642642883694,\n",
              "  1.113613629842976,\n",
              "  1.254988970803089,\n",
              "  1.2815923738491737,\n",
              "  2.186553107171316,\n",
              "  1.8807071689325485,\n",
              "  1.2645903954195463,\n",
              "  1.3284238815238665,\n",
              "  1.2875394701698204,\n",
              "  1.1677497815933682,\n",
              "  1.3805939296073044,\n",
              "  1.3902437300372827,\n",
              "  1.2585348599266302,\n",
              "  1.3966398900698307,\n",
              "  1.2988619621707653,\n",
              "  1.3907015741893414,\n",
              "  1.5533154661153457,\n",
              "  1.2463355264843006,\n",
              "  1.2570164179581493,\n",
              "  1.2870449283923413,\n",
              "  1.3488733481786004,\n",
              "  0.9215480325725586,\n",
              "  1.6572198701420842,\n",
              "  1.157345238492556,\n",
              "  1.6281537802488464,\n",
              "  1.3897857350553149,\n",
              "  1.2771138777750963,\n",
              "  0.9991095050455518,\n",
              "  1.165567069812981,\n",
              "  1.875962180228586,\n",
              "  1.2437789380968078,\n",
              "  1.0957485526731296,\n",
              "  1.6667959343039342,\n",
              "  1.3755122549350303,\n",
              "  1.413404699896484,\n",
              "  1.8427506249649406,\n",
              "  0.9501193805081709,\n",
              "  1.1317592420667806,\n",
              "  1.4272992929222168,\n",
              "  1.3389254195014408,\n",
              "  2.0058506827187097,\n",
              "  1.7715912276177528,\n",
              "  1.7053090981329784,\n",
              "  1.273119766733618,\n",
              "  1.2645903954195463,\n",
              "  1.9612385537320356,\n",
              "  1.4716590860639265,\n",
              "  1.5777145844408116,\n",
              "  2.584948960960377,\n",
              "  1.4392917491892008,\n",
              "  1.319287102056625,\n",
              "  1.4237265731938766,\n",
              "  1.8602862904913782,\n",
              "  1.4529388029682806,\n",
              "  1.1984215478959244,\n",
              "  1.6706109906436855,\n",
              "  1.3856569681781365,\n",
              "  1.8008167925806498,\n",
              "  1.5736743355948497,\n",
              "  1.4299729748651446,\n",
              "  2.1055688292639205,\n",
              "  1.4952620641730152,\n",
              "  1.3620242349823046,\n",
              "  1.540557857201846,\n",
              "  1.5226848692236787,\n",
              "  1.293459223084363,\n",
              "  1.4777028859756633,\n",
              "  1.1368105109938904,\n",
              "  1.3086279790944384,\n",
              "  1.269113085619237,\n",
              "  1.5322707725763225,\n",
              "  1.3332075624036517,\n",
              "  1.507558485549488,\n",
              "  1.4686278591874,\n",
              "  1.341300666036808,\n",
              "  1.319769562157615,\n",
              "  1.6774562271083886,\n",
              "  1.1474012764748687,\n",
              "  1.319287102056625,\n",
              "  1.5728650404343092,\n",
              "  1.1328836926591555,\n",
              "  1.2761165219980004,\n",
              "  1.417901703622935,\n",
              "  1.355934328276106,\n",
              "  1.546744033302657,\n",
              "  1.3662244224803437,\n",
              "  1.6560670213972442,\n",
              "  1.5113542745679724,\n",
              "  2.0023564433863985,\n",
              "  1.5483895061438226,\n",
              "  1.467760644550703,\n",
              "  1.2168720518308382,\n",
              "  1.2850648580991957,\n",
              "  1.937726352564777,\n",
              "  1.1780624362746346,\n",
              "  1.355934328276106,\n",
              "  1.3929885377045959],\n",
              " [0.7619769059790192,\n",
              "  1.4287778577193873,\n",
              "  1.3307233041216784,\n",
              "  1.1406613160316459,\n",
              "  1.391051351387613,\n",
              "  1.5817446144503136,\n",
              "  1.2097642545549692,\n",
              "  1.2258235723674462,\n",
              "  1.5250904059920267,\n",
              "  1.300347498957053,\n",
              "  1.3699247827188596,\n",
              "  1.128574674289959,\n",
              "  1.2886499823938515,\n",
              "  0.995512755932789,\n",
              "  1.1504384611960339,\n",
              "  1.7181486997946478,\n",
              "  1.5513972518323593,\n",
              "  1.5640634600635148,\n",
              "  0.7113901595641053,\n",
              "  1.5056984407876912,\n",
              "  0.891416816026254,\n",
              "  1.6064229726296286,\n",
              "  1.5520122841008464,\n",
              "  1.0732161515115186,\n",
              "  1.4672390990298814,\n",
              "  1.4376799865731829,\n",
              "  1.6425230822008792,\n",
              "  0.9336942716226224,\n",
              "  1.094073676139681,\n",
              "  1.4411542638079289,\n",
              "  1.4873678020978742,\n",
              "  1.548056308107394,\n",
              "  1.0073537741008887,\n",
              "  0.9755200105125168,\n",
              "  1.3310383893152864,\n",
              "  1.767224546391867,\n",
              "  1.1197394706529056,\n",
              "  1.4129917729991484,\n",
              "  1.093352612019035,\n",
              "  0.9593679482706046,\n",
              "  1.4320667901022832,\n",
              "  1.4545191952448477,\n",
              "  1.606485337401383,\n",
              "  1.5934754005445195,\n",
              "  1.0022630146026297,\n",
              "  1.4777405824778564,\n",
              "  0.8713178794405928,\n",
              "  1.3501557426909685,\n",
              "  0.8646864689648678,\n",
              "  1.088130739593666]]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "60cf0e83-c94b-4019-a177-966239bab4ad"
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4,1.6, 1.8,2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f92a0ec8990>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6feb1b28-ec3e-4f8c-c0e4-130690fcfb29"
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAP4UlEQVR4nO3df4xlZX3H8fenC3RtQUCZki3Ldqi/SVMWOiItxiDWyo+maEIa0SI1NGtbMdiaFiRpxbYmmFSxjS3NKpRtY/0RxUL91RLEEqOuHXRZFrbWFdFCV3b8gaJNbBa+/eOejesws/fMzL0z8wzvV3Iz5zznued+n8zms2fOPc85qSokSe35iZUuQJK0OAa4JDXKAJekRhngktQoA1ySGnXYcn7YcccdV5OTk8v5kZLUvDvvvPObVTUxu31ZA3xycpLp6enl/EhJal6Sr83V7ikUSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIa1TvAk6xL8sUkH+nWT0qyPcmeJO9PcsT4ypQkzbaQI/DLgd0Hrb8VuLaqng58B7h0lIVJkg6t10zMJBuB84G3AH+YJMDZwCu6LtuAq4HrxlCjGjF55UdHvs/7rzl/5PuU1oq+R+DvAP4YeKxbfyrwcFXt79YfAE6Y641JtiSZTjI9MzOzpGIlST8yNMCT/Dqwr6ruXMwHVNXWqpqqqqmJicfdi0WStEh9TqGcCfxGkvOA9cCTgb8CjklyWHcUvhF4cHxlSpJmG3oEXlVvrKqNVTUJvBz4ZFW9ErgduLDrdglw89iqlCQ9zlKuA7+CwReaexicE79+NCVJkvpY0P3Aq+pTwKe65fuA00dfkiSpD2diSlKjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIa1eehxuuTfD7JXUnuSfLmrv3GJF9NsqN7bR5/uZKkA/o8keeHwNlV9f0khwOfTvLxbtsfVdUHx1eeJGk+QwO8qgr4frd6ePeqcRYlSRqu1znwJOuS7AD2AbdW1fZu01uS7ExybZKfnOe9W5JMJ5memZkZUdmSpF4BXlWPVtVmYCNwepJfAN4IPBt4LvAUBk+pn+u9W6tqqqqmJiYmRlS2JGlBV6FU1cPA7cA5VbW3Bn4I/D0+oV6SllWfq1AmkhzTLT8JeDHwn0k2dG0BXgrsGmehkqQf1+cqlA3AtiTrGAT+B6rqI0k+mWQCCLAD+N0x1ilJmqXPVSg7gVPnaD97LBVJknrpcwQuaZSuPnoM+/zu6PepVc+p9JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRvV5Jub6JJ9PcleSe5K8uWs/Kcn2JHuSvD/JEeMvV5J0QJ8j8B8CZ1fVKcBm4JwkZwBvBa6tqqcD3wEuHV+ZkqTZhgZ4DXy/Wz28exVwNvDBrn0bgyfTS5KWSa9z4EnWJdkB7ANuBb4CPFxV+7suDwAnzPPeLUmmk0zPzMyMomZJEj0DvKoerarNwEbgdODZfT+gqrZW1VRVTU1MTCyyTEnSbAu6CqWqHgZuB34ZOCbJgafabwQeHHFtkqRD6HMVykSSY7rlJwEvBnYzCPILu26XADePq0hJ0uMdNrwLG4BtSdYxCPwPVNVHktwLvC/JXwBfBK4fY52SpFmGBnhV7QROnaP9PgbnwyVJK8CZmJLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktSoPs/EPDHJ7UnuTXJPksu79quTPJhkR/c6b/zlSpIO6PNMzP3AG6rqC0mOAu5Mcmu37dqq+svxlSdJmk+fZ2LuBfZ2y48k2Q2cMO7CJEmHtqBz4EkmGTzgeHvXdFmSnUluSHLsPO/ZkmQ6yfTMzMySipUk/UjvAE9yJPAh4PVV9T3gOuBpwGYGR+hvm+t9VbW1qqaqampiYmIEJUuSoGeAJzmcQXi/p6puAqiqh6rq0ap6DHgXcPr4ypQkzdbnKpQA1wO7q+rtB7VvOKjby4Bdoy9PkjSfPlehnAlcDNydZEfXdhVwUZLNQAH3A68ZS4WSpDn1uQrl00Dm2PSx0ZcjSerLmZiS1CgDXJIa1eccuPSENXnlR0e+z/vXj3yXeoLyCFySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNarPMzFPTHJ7knuT3JPk8q79KUluTfLl7uex4y9XknRAnyPw/cAbqupk4AzgtUlOBq4EbquqZwC3deuSpGUyNMCram9VfaFbfgTYDZwAXABs67ptA146riIlSY+3oCfyJJkETgW2A8dX1d5u0zeA4+d5zxZgC8CmTZsWW6f6uvroMezzu6Pfp6Ql6/0lZpIjgQ8Br6+q7x28raoKqLneV1Vbq2qqqqYmJiaWVKwk6Ud6BXiSwxmE93uq6qau+aEkG7rtG4B94ylRkjSXPlehBLge2F1Vbz9o0y3AJd3yJcDNoy9PkjSfPufAzwQuBu5OsqNruwq4BvhAkkuBrwG/OZ4SJUlzGRrgVfVpIPNsftFoy5Ek9eVMTElqlAEuSY0ywCWpUQa4JDVqQTMxpWXnzFJpXh6BS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjerzSLUbkuxLsuugtquTPJhkR/c6b7xlSpJm63MEfiNwzhzt11bV5u71sdGWJUkaZmiAV9UdwLeXoRZJ0gIs5Rz4ZUl2dqdYjh1ZRZKkXhYb4NcBTwM2A3uBt83XMcmWJNNJpmdmZhb5cZKk2RYV4FX1UFU9WlWPAe8CTj9E361VNVVVUxMTE4utU5I0y6ICPMmGg1ZfBuyar68kaTyGPlItyXuBs4DjkjwAvAk4K8lmoID7gdeMsUZJ0hyGBnhVXTRH8/VjqEWStABP7Ica+8BcSQ1zKr0kNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRj2xp9KvsMkrPzryfd6/fuS7lLRKeQQuSY0ywCWpUQa4JDXKAJekRhngktSooQGe5IYk+5LsOqjtKUluTfLl7uex4y1TkjRbnyPwG4FzZrVdCdxWVc8AbuvWJUnLaGiAV9UdwLdnNV8AbOuWtwEvHXFdkqQhFjuR5/iq2tstfwM4fr6OSbYAWwA2bdq0yI+TtGr5bNkVs+QvMauqgDrE9q1VNVVVUxMTE0v9OElSZ7EB/lCSDQDdz32jK0mS1MdiA/wW4JJu+RLg5tGUI0nqq89lhO8FPgs8K8kDSS4FrgFenOTLwK9265KkZTT0S8yqumieTS8acS2SpAXwdrLSE4i3MF5bnEovSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNciampKaNZXbpNeePfJ/j4BG4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJatSSLiNMcj/wCPAosL+qpkZRlCRpuFFcB/7CqvrmCPYjSVoAT6FIUqOWGuAF/FuSO5NsmatDki1JppNMz8zMLPHjJEkHLDXAn19VpwHnAq9N8oLZHapqa1VNVdXUxMTEEj9OknTAkgK8qh7sfu4DPgycPoqiJEnDLTrAk/x0kqMOLAO/BuwaVWGSpENbylUoxwMfTnJgP/9UVZ8YSVWSpKEWHeBVdR9wyghrkSQtQDP3Ax/LPX/Xj3yXkrRsvA5ckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktSoJQV4knOSfCnJniRXjqooSdJwS3mo8Trgb4BzgZOBi5KcPKrCJEmHtpQj8NOBPVV1X1X9H/A+4ILRlCVJGiZVtbg3JhcC51TV73TrFwPPq6rLZvXbAmzpVp8FfKnH7o8DvrmowlantTYeWHtjWmvjgbU3prU2Hug/pp+rqonZjWN/qHFVbQW2LuQ9SaarampMJS27tTYeWHtjWmvjgbU3prU2Hlj6mJZyCuVB4MSD1jd2bZKkZbCUAP8P4BlJTkpyBPBy4JbRlCVJGmbRp1Cqan+Sy4B/BdYBN1TVPSOqa0GnXBqw1sYDa29Ma208sPbGtNbGA0sc06K/xJQkrSxnYkpSowxwSWrUigb4sKn4STYluT3JF5PsTHLeStTZV5IbkuxLsmue7Uny1914dyY5bblrXIge43llN467k3wmySnLXeNCDRvTQf2em2R/N99h1eozniRnJdmR5J4k/76c9S1Uj39zRyf5lyR3deN59XLXuFBJTuxy7N6u5svn6LO4bKiqFXkx+OLzK8DPA0cAdwEnz+qzFfi9bvlk4P6VqrfnmF4AnAbsmmf7ecDHgQBnANtXuuYljudXgGO75XNX+3j6jKnrsw74JPAx4MKVrnmJv6NjgHuBTd36z6x0zUscz1XAW7vlCeDbwBErXfeQMW0ATuuWjwL+a46sW1Q2rOQReJ+p+AU8uVs+GvifZaxvwarqDgb/oOZzAfAPNfA54JgkG5anuoUbNp6q+kxVfadb/RyDuQCrWo/fEcDrgA8B+8Zf0dL0GM8rgJuq6utd/1U9ph7jKeCoJAGO7PruX47aFquq9lbVF7rlR4DdwAmzui0qG1YywE8A/vug9Qd4/KCuBn4ryQMMjoZetzyljU2fMbfqUgZHEE1LcgLwMuC6la5lRJ4JHJvkU0nuTPKqlS5oid4JPIfBwdzdwOVV9djKltRfkkngVGD7rE2LyobV/iXmRcCNVbWRwZ8Y/5hktdf8hJPkhQwC/IqVrmUE3gFc0VIoDHEY8EvA+cBLgD9J8syVLWlJXgLsAH4W2Ay8M8mTD/2W1SHJkQz+snt9VX1vFPsc+71QDqHPVPxLgXMAquqzSdYzuPnLqv4z8BDW3O0Hkvwi8G7g3Kr61krXMwJTwPsGf6FzHHBekv1V9c8rW9aiPQB8q6p+APwgyR3AKQzOw7bo1cA1NThxvCfJV4FnA59f2bIOLcnhDML7PVV10xxdFpUNK3k022cq/teBFwEkeQ6wHphZ1ipH6xbgVd03zmcA362qvStd1GIl2QTcBFxcVa0Gwo+pqpOqarKqJoEPAr/fcHgD3Aw8P8lhSX4KeB6Dc7CtOjgTjmdwh9P7VrSiIbrz9dcDu6vq7fN0W1Q2rNgReM0zFT/JnwHTVXUL8AbgXUn+gMGXF7/d/c+7KiV5L3AWcFx33v5NwOEAVfV3DM7jnwfsAf6XwdHEqtVjPH8KPBX42+6IdX+t8rvF9RhTU4aNp6p2J/kEsBN4DHh3VR3yEsqV1OP38+fAjUnuZnDFxhVVtdpvMXsmcDFwd5IdXdtVwCZYWjY4lV6SGuUXgpLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNer/AYTh38ggUGPOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443a8d6f-31f5-40ca-b8cf-24faf9e08c10"
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.92156863, 11.76470588, 40.19607843, 23.52941176,  8.82352941,\n",
              "        6.8627451 ])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f77cd49-56b0-4209-f234-759e6dd5ec66"
      },
      "source": [
        "bins_list"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4b11b2f8-0800-4092-f812-fca8a73c421e"
      },
      "source": [
        "df"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "      <th>0.8</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.4</th>\n",
              "      <th>1.6</th>\n",
              "      <th>1.8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.921863</td>\n",
              "      <td>0.997085</td>\n",
              "      <td>0.510204</td>\n",
              "      <td>0.003307</td>\n",
              "      <td>7.567057</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2       R^2  acc train  acc test  ...   1.0   1.2   1.4   1.6  1.8\n",
              "0  20  20  0.921863   0.997085  0.510204  ...  20.0  18.0  34.0  10.0  0.0\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b333b63f-228f-43a9-b9f0-8b2d1df26a45"
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3375a2af-cbb7-4756-8d7b-1121e94ee3e6\", \"output.xlsx\", 5243)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}