{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_Amostra3_r_squared_set_09_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/PSD_histogram_CNN_B_Amostra3_r_squared_set_06_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZEvJvfoibE4",
        "outputId": "5fc5cc24-b0c5-4b1d-a227-4eeb00fcc7ed"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VcTdaNVh9EE",
        "outputId": "0d76a217-2fc7-4a9d-cfcd-cee503fb8314"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7SRrc8mH2N",
        "outputId": "90f70b48-9eb8-4c1e-fab7-d24d2b2b76d6"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "ea3364cb-4b57-4068-80cb-f4cb1d2998ce"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[4] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgqAnaFyCjp",
        "outputId": "00fe17d3-d06b-4007-90d5-91d5cd89e357"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN5MN5a_v4np",
        "outputId": "d80cf2bd-c1c9-4425-a923-78b49c544482"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     133  130.243774  128.387817  ...    0.307479    0.518005    1.465374\n",
            "1     102  103.302963   92.550957  ...  189.091888  188.342560  186.466370\n",
            "2     118  119.457054  116.201088  ...  134.674805  136.027283  137.058029\n",
            "3     124   44.984386   47.443287  ...    1.000000    1.000000    1.000000\n",
            "4     134  117.215195  116.873466  ...  138.024948  136.704834  137.680557\n",
            "5     107  176.333054  147.251892  ...   81.771416   82.066551   88.379593\n",
            "6     119  142.979233  152.446365  ...  108.930794  126.197235  137.871964\n",
            "7     145  107.998383  107.314240  ...  158.094086  158.433716  156.161301\n",
            "8     136  180.668686  164.006058  ...  237.807968  226.825272  209.068329\n",
            "9     197   94.658157   80.931648  ...  151.816757  154.131287  160.797165\n",
            "10    155  148.806915  148.386185  ...  153.454361  159.595154  158.721542\n",
            "11    185  164.642517  159.442108  ...  133.324814  128.978607  135.920197\n",
            "12    176  176.843506  225.145645  ...  193.392044  193.994324  188.921478\n",
            "13    175  163.427200  168.863998  ...  175.943985  178.918396  181.823990\n",
            "14    140  157.559998  196.839996  ...  148.399994  149.800003  148.039993\n",
            "15    114  171.655273  173.474915  ...  167.611893  171.466614  174.499542\n",
            "16    199  133.116486  176.502655  ...    1.506932    0.245802    1.310169\n",
            "17    188    0.640109    0.555002  ...  156.896332  205.942505  201.810776\n",
            "18    139  143.584229  140.262863  ...  153.028244  147.107086  120.186630\n",
            "19    159  230.179169  222.843704  ...    0.321427    1.383213    1.000000\n",
            "20    110  152.157013  152.044632  ...  177.136200  162.833054  148.951401\n",
            "21    150  138.961426  117.758583  ...    1.000000    1.000000    1.000000\n",
            "22    111  108.820305   95.931740  ...  148.999756  144.458237  126.850746\n",
            "23    165   63.976089   63.550014  ...    0.574252    1.710670    0.884812\n",
            "24    191  191.443573  187.441528  ...    0.301033    0.921713    0.593213\n",
            "25    107    0.806795    1.330160  ...   90.532280   84.264214   84.837715\n",
            "26    108  149.456787  154.116592  ...  158.847733  166.611801  165.259262\n",
            "27    165  169.081909  165.048920  ...   78.764809  113.178772  127.333992\n",
            "28    186  188.862885  191.129288  ...  137.966125  168.673035  176.179794\n",
            "29    162    0.917543    0.135040  ...    0.104405    0.985216    1.684195\n",
            "30    164  105.433670  101.704941  ...  156.775711  152.096375  151.363480\n",
            "31    143  137.870071  126.853981  ...  158.225784  158.644394  158.919113\n",
            "32    146   96.789635  107.402138  ...    0.543629    0.379246    1.420341\n",
            "33    179   65.491127   66.244095  ...  150.497726  134.618149  127.411324\n",
            "34    199  170.086090  183.786255  ...    1.200348    0.619580    0.584733\n",
            "35    147    0.854875    1.807256  ...   94.283447   84.512474   75.251701\n",
            "36    192  146.741318  117.545128  ...    1.396267    0.167535    1.312934\n",
            "37    144  149.283966  139.310181  ...  172.137360  177.165894  176.429031\n",
            "38    129   94.791122   96.735588  ...    0.937804    1.302325    1.207500\n",
            "39    144  109.583336  109.253853  ...  134.330246  147.750015  167.076385\n",
            "40    133  204.191147  203.969543  ...  159.609421  147.365646  128.717453\n",
            "41    193  108.207191   96.078667  ...  172.221756  171.166611  171.741211\n",
            "42    149  159.843033  155.254318  ...  238.478729  242.682419  246.817902\n",
            "43    192  155.647552  133.950943  ...    1.396267    0.167535    1.312934\n",
            "44    147   91.938782  111.929710  ...    1.321995    1.512472    0.464853\n",
            "45    153  139.923920  132.668259  ...    0.654406    0.314537    1.399504\n",
            "46    190  103.214058   95.662819  ...    1.386149    0.193352    1.333518\n",
            "47    168  117.888893  148.500000  ...  232.222229  246.916672  252.972229\n",
            "48    139  144.333572  145.759888  ...    0.421873    0.450650    1.443455\n",
            "49    172  187.427811  181.083282  ...  136.350464  128.246094  110.409958\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xzpQ1Pz0fX5L",
        "outputId": "0a7b72e5-f281-4159-dd96-9959c3ca54ec"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "04d8548f-f619-4bcc-beab-4d65d42ef742"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "2114e73b-4cd5-4d05-f5b5-113ee29ee3b6"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 134ms/step - loss: 0.5748 - accuracy: 0.6968 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.4075 - accuracy: 0.8163 - val_loss: 0.6930 - val_accuracy: 0.4898\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.2835 - accuracy: 0.8805 - val_loss: 0.6930 - val_accuracy: 0.4898\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.1598 - accuracy: 0.9417 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.1090 - accuracy: 0.9592 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.1134 - accuracy: 0.9446 - val_loss: 0.6925 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.0647 - accuracy: 0.9854 - val_loss: 0.6925 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.6926 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0346 - accuracy: 0.9913 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0342 - accuracy: 0.9825 - val_loss: 0.6924 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.6997 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.7043 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.7066 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.7166 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.7070 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7351 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.7596 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0136 - accuracy: 0.9913 - val_loss: 0.8404 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0135 - accuracy: 0.9913 - val_loss: 0.8028 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 1.0166 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0233 - accuracy: 0.9854 - val_loss: 1.1278 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0174 - accuracy: 0.9913 - val_loss: 1.5772 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0162 - accuracy: 0.9913 - val_loss: 2.5463 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.7372 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0392 - accuracy: 0.9796 - val_loss: 1.6694 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0543 - accuracy: 0.9825 - val_loss: 2.5771 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0621 - accuracy: 0.9883 - val_loss: 1.7681 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0358 - accuracy: 0.9913 - val_loss: 0.7621 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0249 - accuracy: 0.9883 - val_loss: 1.8731 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0134 - accuracy: 0.9942 - val_loss: 3.0010 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.4351 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1550 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3787 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2828 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2474 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1621 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 5.6066e-04 - accuracy: 1.0000 - val_loss: 1.1736 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 6.2736e-04 - accuracy: 1.0000 - val_loss: 1.1632 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 4.3753e-04 - accuracy: 1.0000 - val_loss: 1.1957 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1919 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 4.0851e-04 - accuracy: 1.0000 - val_loss: 1.1632 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 5.9375e-04 - accuracy: 1.0000 - val_loss: 1.1250 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4293 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 4.7690e-04 - accuracy: 1.0000 - val_loss: 1.7491 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 3.0802e-04 - accuracy: 1.0000 - val_loss: 1.9152 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9828 - val_accuracy: 0.5102\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1723 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.4170e-04 - accuracy: 1.0000 - val_loss: 2.4620 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 6.3775e-04 - accuracy: 1.0000 - val_loss: 2.4615 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 6.0532e-04 - accuracy: 1.0000 - val_loss: 2.1984 - val_accuracy: 0.5102\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 5.5372e-04 - accuracy: 1.0000 - val_loss: 2.0167 - val_accuracy: 0.5170\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 5.3169e-04 - accuracy: 1.0000 - val_loss: 1.8690 - val_accuracy: 0.5170\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 2.6833e-04 - accuracy: 1.0000 - val_loss: 1.6133 - val_accuracy: 0.5374\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.7018e-04 - accuracy: 1.0000 - val_loss: 1.4239 - val_accuracy: 0.5850\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 2.5044e-04 - accuracy: 1.0000 - val_loss: 1.3829 - val_accuracy: 0.6122\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 2.8591e-04 - accuracy: 1.0000 - val_loss: 1.2182 - val_accuracy: 0.6463\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.8038e-04 - accuracy: 1.0000 - val_loss: 1.5122 - val_accuracy: 0.5782\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 1.8966e-04 - accuracy: 1.0000 - val_loss: 1.6125 - val_accuracy: 0.5850\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 1.0260e-04 - accuracy: 1.0000 - val_loss: 1.4992 - val_accuracy: 0.6190\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 1.6987e-04 - accuracy: 1.0000 - val_loss: 1.2747 - val_accuracy: 0.7075\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 1.8348e-04 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.7483\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.5220e-04 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7823\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 1.6278e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8027\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 1.0528e-04 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.8435\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 2.8015e-04 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.8776\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.3786e-04 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9184\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.9628e-04 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9388\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.5582e-04 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9524\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 1.7993e-04 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9524\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 4.5057e-04 - accuracy: 1.0000 - val_loss: 2.6540 - val_accuracy: 0.5714\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 2.3417e-04 - accuracy: 1.0000 - val_loss: 3.7597 - val_accuracy: 0.5238\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 2.0688e-04 - accuracy: 1.0000 - val_loss: 4.2582 - val_accuracy: 0.5170\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 6.4151e-04 - accuracy: 1.0000 - val_loss: 5.5404 - val_accuracy: 0.5170\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 2.1575e-04 - accuracy: 1.0000 - val_loss: 4.9955 - val_accuracy: 0.5102\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 7.7585e-04 - accuracy: 1.0000 - val_loss: 5.2625 - val_accuracy: 0.5102\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 3.9243e-04 - accuracy: 1.0000 - val_loss: 5.3556 - val_accuracy: 0.5102\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 1.5880e-04 - accuracy: 1.0000 - val_loss: 5.5387 - val_accuracy: 0.5102\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 7.2601e-04 - accuracy: 1.0000 - val_loss: 2.6171 - val_accuracy: 0.5374\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 4.9763e-04 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.6735\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.1201e-04 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.7347\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 5.4632e-05 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.7959\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 3.1113e-04 - accuracy: 1.0000 - val_loss: 0.8672 - val_accuracy: 0.7211\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 3.0893e-04 - accuracy: 1.0000 - val_loss: 2.0798 - val_accuracy: 0.5442\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 9.8053e-05 - accuracy: 1.0000 - val_loss: 2.4772 - val_accuracy: 0.5238\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.6648e-04 - accuracy: 1.0000 - val_loss: 2.0253 - val_accuracy: 0.5442\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.7747e-04 - accuracy: 1.0000 - val_loss: 1.5228 - val_accuracy: 0.5918\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 1.0788e-04 - accuracy: 1.0000 - val_loss: 1.4336 - val_accuracy: 0.6327\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 5.9511e-05 - accuracy: 1.0000 - val_loss: 1.2393 - val_accuracy: 0.6735\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 4.6798e-05 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.7415\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 9.6024e-05 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.7755\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.3968e-04 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.8027\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.4003e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.8571\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 1.6004e-04 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9116\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.9839e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9524\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 6.2347e-05 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9592\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.0309e-04 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9592\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 6.0697e-05 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9592\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 1.4895e-04 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9592\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.7465e-04 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9728\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 4.8194e-05 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9728\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 2.2414e-04 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9660\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 4.6948e-05 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9184\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 7.8981e-05 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9252\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 5.1612e-05 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9184\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 3.9603e-05 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9116\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.3836e-04 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9728\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 5.7973e-05 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9660\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 3.3715e-05 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9728\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 7.7954e-05 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9728\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 3.9474e-05 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9728\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 6.0473e-05 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9796\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 2s 135ms/step - loss: 5.6103e-05 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9796\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.4762e-04 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9796\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.0990e-05 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9660\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 3.9318e-05 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9592\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 8.3757e-05 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9728\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.0782e-05 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9728\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 3.2671e-05 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9728\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 6.3663e-05 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9796\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.5231e-05 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9796\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 6.4641e-05 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9796\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 6.2540e-05 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9728\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 2.3947e-05 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9728\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 6.6439e-05 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9728\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.0018e-05 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9592\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.3262e-05 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9524\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.5582e-04 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9524\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 6.1155e-05 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9592\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.6557e-05 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9592\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 7.3517e-05 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9728\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.0953e-05 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9728\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 5.1323e-05 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9728\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 6.9384e-05 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9728\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 5.1792e-05 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9728\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 2.4969e-05 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9660\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 8.1609e-05 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9592\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.9497e-05 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9592\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.1512e-05 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9592\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 9.4759e-06 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9660\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.8606e-05 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9660\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.9381e-05 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9728\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 3.3572e-05 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9728\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.5161e-05 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9796\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 3.9813e-05 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9660\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 6.2972e-04 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9320\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 7.4782e-05 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9252\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 4.6853e-05 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9048\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.6547e-04 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.8912\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 3.7314e-05 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9048\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.5337e-04 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9728\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 2.0361e-04 - accuracy: 1.0000 - val_loss: 2.1302 - val_accuracy: 0.6190\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 5.0775e-05 - accuracy: 1.0000 - val_loss: 2.5487 - val_accuracy: 0.5986\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.4858e-05 - accuracy: 1.0000 - val_loss: 2.0945 - val_accuracy: 0.6599\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 2.3118e-05 - accuracy: 1.0000 - val_loss: 1.5993 - val_accuracy: 0.7211\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 2.6482e-05 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.7687\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.1711e-04 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8912\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 9.7536e-05 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9252\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.1850e-05 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9456\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 8.2900e-06 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9660\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.7264e-05 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9728\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 2.9821e-05 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9728\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 7.6347e-06 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9864\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 1.0868e-05 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9728\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 2.8809e-05 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9592\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 7.6408e-06 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9592\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 9.6342e-06 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9524\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 4.2614e-05 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9524\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.6786e-05 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9592\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.5425e-05 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9592\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.0939e-04 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9592\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 9.1463e-06 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9524\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 3.3551e-05 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9524\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.2086e-05 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9524\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 7.2837e-05 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9524\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 2.8000e-05 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9592\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 4.5887e-06 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9592\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.5479e-05 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9592\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.4858e-05 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9660\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.6518e-05 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9592\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.1395e-05 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9660\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 7.0432e-06 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9592\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.9204e-05 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9592\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 3.3473e-05 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9592\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.3296e-04 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9660\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 1.3269e-04 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9456\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 5.5968e-05 - accuracy: 1.0000 - val_loss: 1.4214 - val_accuracy: 0.6735\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.1046e-05 - accuracy: 1.0000 - val_loss: 1.9880 - val_accuracy: 0.6054\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 2.3637e-05 - accuracy: 1.0000 - val_loss: 1.8709 - val_accuracy: 0.6122\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 2.4731e-05 - accuracy: 1.0000 - val_loss: 1.4845 - val_accuracy: 0.6735\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.7973e-05 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.7687\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 3.1831e-05 - accuracy: 1.0000 - val_loss: 0.8796 - val_accuracy: 0.7959\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.2785e-05 - accuracy: 1.0000 - val_loss: 0.8267 - val_accuracy: 0.8095\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 5.7984e-06 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDVY6HbxMOlH",
        "outputId": "12df9f24-e6bd-48e8-95b4-2c732d2ab3af"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   0   1\n",
            "Actual         \n",
            "0        47  25\n",
            "1         1  74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFNNrlWV9tH",
        "outputId": "26b00a3e-05f5-4e51-c442-68f5b4f6e86e"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv5I61yhPQmk",
        "outputId": "e7d17688-2bb9-4a2b-b873-1ac1440da1af"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[4] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  #prediction = model.predict_classes(result)\n",
        "  prediction= np.argmax(model.predict(result), axis=-1)\n",
        "  loc_grao =[];k=0\n",
        "  for i in prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0   122.0  123.761337  133.587204  ...  134.521896  132.229507  134.617035\n",
            "1   173.0  173.956955  158.307724  ...   49.259109   17.691870    1.848441\n",
            "2   104.0  114.942314  118.853561  ...    0.807692    0.926036    1.000000\n",
            "3   192.0  100.387589   97.979164  ...    1.396267    0.167535    1.312934\n",
            "5   180.0  178.968414  173.285431  ...  108.594574  125.621742  143.518036\n",
            "6   122.0  180.621063  174.442078  ...  191.528610  190.470840  175.730164\n",
            "7   125.0  135.317444  142.897217  ...    1.000000    1.000000    1.000000\n",
            "8   119.0  210.754333  198.802780  ...   69.730103   74.899658   76.394463\n",
            "9   127.0  140.090515  153.397980  ...  153.931610  164.372498  163.173538\n",
            "10  161.0  171.277893  179.678650  ...  172.650299  160.139893  158.657852\n",
            "12  192.0  189.003876  189.090698  ...    1.396267    0.167535    1.312934\n",
            "13  148.0  196.720978  239.984665  ...  197.441223  205.723892  207.667664\n",
            "14  127.0  213.890015  224.986786  ...  192.535187  129.691803  122.242355\n",
            "15  113.0  154.310349  146.764587  ...    0.335735    0.300337    1.061399\n",
            "16  153.0  223.414215  233.383118  ...    1.146995    1.046649    1.000000\n",
            "17  187.0  113.864174  117.685890  ...  233.441818  234.210602  229.729019\n",
            "18  189.0  155.606308  171.170105  ...    8.104253   18.928671   37.008232\n",
            "19  191.0  158.596283  158.900024  ...    1.191470    0.208081    1.314685\n",
            "21  136.0   93.289795   94.285477  ...  138.853806  139.409164  127.686859\n",
            "22  163.0  162.269455  180.901535  ...    0.810079    0.231962    1.373066\n",
            "24  112.0  165.937500  164.750000  ...    0.187500    0.000000    0.062500\n",
            "25  146.0  139.396683  137.501785  ...  150.795273  128.748169  136.250885\n",
            "26  164.0  102.255203  127.591324  ...  148.073761  134.810822  138.170731\n",
            "27  162.0  127.569580  167.894531  ...  195.999237  115.216278  128.685577\n",
            "28  165.0  148.080444  145.692047  ...    5.702847    2.967824    1.537521\n",
            "29  172.0  220.832336  205.830719  ...    0.448350    0.680909    1.757166\n",
            "30  100.0   59.956799   62.011200  ...  119.687996  122.988800  128.923187\n",
            "31  186.0  177.071442  175.326752  ...  188.799530  196.356583  188.354034\n",
            "32  119.0   53.301044   57.903118  ...   79.861595   80.044983   80.480972\n",
            "33  145.0  119.628578  114.392815  ...  125.469055  129.626678  133.315903\n",
            "34  108.0  137.817566  135.227707  ...    0.733882    0.009602    0.835391\n",
            "35  184.0  188.498108  181.470215  ...  157.614349  163.565689  174.858673\n",
            "36  158.0  194.459854  190.323654  ...   68.609993   57.578594   48.066654\n",
            "37  173.0  136.174866  166.840988  ...   35.206188   34.648102   58.836342\n",
            "38  187.0  128.947952  120.312416  ...    0.178730    1.321885    0.573222\n",
            "39  132.0  227.836563  231.039490  ...  112.216713  119.352631  118.868690\n",
            "41  159.0  189.000565  177.628540  ...  174.749695  199.674637  249.299042\n",
            "42  195.0  201.638397  194.884521  ...  159.575714  149.339691  155.018387\n",
            "43  192.0   27.104164    9.057292  ...  165.096786  190.974808  198.699646\n",
            "44  199.0  113.605156  126.924713  ...  114.555077   85.055443   61.355240\n",
            "45  156.0   50.227486   44.474033  ...    0.698882    0.288626    1.391190\n",
            "46  187.0  159.545822  165.901520  ...  194.584045  197.232895  196.024948\n",
            "47  124.0  165.826233  166.733612  ...  107.659721   93.348587  103.057228\n",
            "48  141.0  153.658279  154.640228  ...  125.609077  119.719887  125.840698\n",
            "49  101.0   85.334480  102.642776  ...  154.517120  154.846390  156.325851\n",
            "\n",
            "[45 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "8fa4273d-86fe-4827-87ad-e746dc867a16"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marquesgabi_paper_fev_2021'...\n",
            "remote: Enumerating objects: 687, done.\u001b[K\n",
            "remote: Counting objects: 100% (448/448), done.\u001b[K\n",
            "remote: Compressing objects: 100% (446/446), done.\u001b[K\n",
            "remote: Total 687 (delta 282), reused 0 (delta 0), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (687/687), 5.59 MiB | 11.76 MiB/s, done.\n",
            "Resolving deltas: 100% (419/419), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "450510a8-5c9f-4449-b98e-f2d3572c96b4"
      },
      "source": [
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "\n",
        "%cd Doutorado\n",
        "\n",
        "PSD_imageJ = 'Amostra7.csv' \n",
        "PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 411, done.\u001b[K\n",
            "remote: Counting objects: 100% (161/161), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 411 (delta 68), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (411/411), 202.74 MiB | 28.96 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n",
            "Checking out files: 100% (81/81), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "   Unnamed: 0   Area\n",
            "0           1  1.387\n",
            "1           2  1.626\n",
            "2           3  1.336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tEPjIBnv_xM",
        "outputId": "380b980c-43df-4a31-e91b-5b0de8f82e94"
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfagXc-Mv3oa"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "PekBHQOT_6CP",
        "outputId": "354833ba-278f-497e-b649-368be23ecf59"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122.0</td>\n",
              "      <td>123.761337</td>\n",
              "      <td>133.587204</td>\n",
              "      <td>145.525650</td>\n",
              "      <td>150.594193</td>\n",
              "      <td>160.037628</td>\n",
              "      <td>167.253403</td>\n",
              "      <td>180.070679</td>\n",
              "      <td>180.992996</td>\n",
              "      <td>154.723175</td>\n",
              "      <td>119.033318</td>\n",
              "      <td>111.113403</td>\n",
              "      <td>135.715393</td>\n",
              "      <td>159.384033</td>\n",
              "      <td>175.114746</td>\n",
              "      <td>180.853806</td>\n",
              "      <td>244.945160</td>\n",
              "      <td>251.220062</td>\n",
              "      <td>250.746017</td>\n",
              "      <td>250.511673</td>\n",
              "      <td>251.196411</td>\n",
              "      <td>249.206116</td>\n",
              "      <td>252.827728</td>\n",
              "      <td>252.327316</td>\n",
              "      <td>250.924454</td>\n",
              "      <td>250.203690</td>\n",
              "      <td>180.922318</td>\n",
              "      <td>80.906471</td>\n",
              "      <td>104.241600</td>\n",
              "      <td>127.052399</td>\n",
              "      <td>135.980637</td>\n",
              "      <td>147.029007</td>\n",
              "      <td>151.417084</td>\n",
              "      <td>152.744415</td>\n",
              "      <td>168.608429</td>\n",
              "      <td>192.720490</td>\n",
              "      <td>193.442886</td>\n",
              "      <td>133.366562</td>\n",
              "      <td>100.463036</td>\n",
              "      <td>120.091103</td>\n",
              "      <td>...</td>\n",
              "      <td>181.268463</td>\n",
              "      <td>176.181671</td>\n",
              "      <td>225.145111</td>\n",
              "      <td>224.320602</td>\n",
              "      <td>163.116638</td>\n",
              "      <td>145.199402</td>\n",
              "      <td>146.775314</td>\n",
              "      <td>148.472183</td>\n",
              "      <td>144.038162</td>\n",
              "      <td>137.767807</td>\n",
              "      <td>134.840622</td>\n",
              "      <td>134.955658</td>\n",
              "      <td>204.158020</td>\n",
              "      <td>191.400146</td>\n",
              "      <td>180.446365</td>\n",
              "      <td>184.284058</td>\n",
              "      <td>180.024994</td>\n",
              "      <td>178.986572</td>\n",
              "      <td>177.927170</td>\n",
              "      <td>179.324097</td>\n",
              "      <td>195.251526</td>\n",
              "      <td>231.184357</td>\n",
              "      <td>250.255844</td>\n",
              "      <td>253.561386</td>\n",
              "      <td>253.347458</td>\n",
              "      <td>253.044327</td>\n",
              "      <td>252.976059</td>\n",
              "      <td>251.905396</td>\n",
              "      <td>249.531830</td>\n",
              "      <td>248.345062</td>\n",
              "      <td>247.293457</td>\n",
              "      <td>220.944641</td>\n",
              "      <td>140.032516</td>\n",
              "      <td>141.499329</td>\n",
              "      <td>144.135712</td>\n",
              "      <td>144.716736</td>\n",
              "      <td>143.601181</td>\n",
              "      <td>134.521896</td>\n",
              "      <td>132.229507</td>\n",
              "      <td>134.617035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>173.0</td>\n",
              "      <td>173.956955</td>\n",
              "      <td>158.307724</td>\n",
              "      <td>161.155136</td>\n",
              "      <td>177.080765</td>\n",
              "      <td>182.047012</td>\n",
              "      <td>175.783463</td>\n",
              "      <td>165.713074</td>\n",
              "      <td>165.123611</td>\n",
              "      <td>156.673859</td>\n",
              "      <td>100.228539</td>\n",
              "      <td>102.221581</td>\n",
              "      <td>102.233612</td>\n",
              "      <td>107.074463</td>\n",
              "      <td>109.283905</td>\n",
              "      <td>112.319084</td>\n",
              "      <td>119.523926</td>\n",
              "      <td>121.724182</td>\n",
              "      <td>115.532394</td>\n",
              "      <td>99.607765</td>\n",
              "      <td>55.670250</td>\n",
              "      <td>48.002209</td>\n",
              "      <td>48.530186</td>\n",
              "      <td>50.683079</td>\n",
              "      <td>53.791172</td>\n",
              "      <td>60.754784</td>\n",
              "      <td>64.112068</td>\n",
              "      <td>41.493099</td>\n",
              "      <td>2.377393</td>\n",
              "      <td>169.637482</td>\n",
              "      <td>167.927231</td>\n",
              "      <td>163.854782</td>\n",
              "      <td>169.189590</td>\n",
              "      <td>180.493393</td>\n",
              "      <td>173.438492</td>\n",
              "      <td>168.597031</td>\n",
              "      <td>168.385941</td>\n",
              "      <td>142.896454</td>\n",
              "      <td>101.331688</td>\n",
              "      <td>103.650497</td>\n",
              "      <td>...</td>\n",
              "      <td>147.558655</td>\n",
              "      <td>131.433151</td>\n",
              "      <td>128.831238</td>\n",
              "      <td>128.745377</td>\n",
              "      <td>122.721008</td>\n",
              "      <td>118.013397</td>\n",
              "      <td>107.038452</td>\n",
              "      <td>86.787598</td>\n",
              "      <td>58.540409</td>\n",
              "      <td>30.922852</td>\n",
              "      <td>11.031641</td>\n",
              "      <td>3.710381</td>\n",
              "      <td>147.206619</td>\n",
              "      <td>82.714050</td>\n",
              "      <td>106.617393</td>\n",
              "      <td>161.965851</td>\n",
              "      <td>179.160126</td>\n",
              "      <td>179.648605</td>\n",
              "      <td>176.660736</td>\n",
              "      <td>178.176025</td>\n",
              "      <td>174.841888</td>\n",
              "      <td>167.096619</td>\n",
              "      <td>166.491928</td>\n",
              "      <td>174.204590</td>\n",
              "      <td>178.141174</td>\n",
              "      <td>166.563553</td>\n",
              "      <td>166.950867</td>\n",
              "      <td>170.862076</td>\n",
              "      <td>151.972168</td>\n",
              "      <td>128.541779</td>\n",
              "      <td>124.599228</td>\n",
              "      <td>118.513145</td>\n",
              "      <td>115.468506</td>\n",
              "      <td>100.486580</td>\n",
              "      <td>80.927383</td>\n",
              "      <td>70.797012</td>\n",
              "      <td>68.680878</td>\n",
              "      <td>49.259109</td>\n",
              "      <td>17.691870</td>\n",
              "      <td>1.848441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104.0</td>\n",
              "      <td>114.942314</td>\n",
              "      <td>118.853561</td>\n",
              "      <td>119.502968</td>\n",
              "      <td>117.417175</td>\n",
              "      <td>119.837288</td>\n",
              "      <td>125.755928</td>\n",
              "      <td>138.146469</td>\n",
              "      <td>142.393509</td>\n",
              "      <td>138.170135</td>\n",
              "      <td>131.149414</td>\n",
              "      <td>123.420128</td>\n",
              "      <td>117.406807</td>\n",
              "      <td>112.128716</td>\n",
              "      <td>109.326935</td>\n",
              "      <td>104.041435</td>\n",
              "      <td>104.769241</td>\n",
              "      <td>108.792915</td>\n",
              "      <td>112.825455</td>\n",
              "      <td>117.244095</td>\n",
              "      <td>114.238174</td>\n",
              "      <td>114.923088</td>\n",
              "      <td>125.545868</td>\n",
              "      <td>132.862442</td>\n",
              "      <td>133.150909</td>\n",
              "      <td>131.375748</td>\n",
              "      <td>132.744095</td>\n",
              "      <td>117.378716</td>\n",
              "      <td>73.704155</td>\n",
              "      <td>114.452667</td>\n",
              "      <td>116.720428</td>\n",
              "      <td>120.323975</td>\n",
              "      <td>123.476349</td>\n",
              "      <td>125.479294</td>\n",
              "      <td>129.513336</td>\n",
              "      <td>137.961563</td>\n",
              "      <td>144.591736</td>\n",
              "      <td>140.085800</td>\n",
              "      <td>132.337296</td>\n",
              "      <td>123.497047</td>\n",
              "      <td>...</td>\n",
              "      <td>0.868343</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.069527</td>\n",
              "      <td>0.415680</td>\n",
              "      <td>0.031065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.569527</td>\n",
              "      <td>0.995562</td>\n",
              "      <td>0.390533</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.254438</td>\n",
              "      <td>0.977811</td>\n",
              "      <td>1.036982</td>\n",
              "      <td>1.066568</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.948225</td>\n",
              "      <td>0.056213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044379</td>\n",
              "      <td>0.451183</td>\n",
              "      <td>0.865385</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.881657</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.110947</td>\n",
              "      <td>0.457101</td>\n",
              "      <td>0.072485</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.610947</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.955621</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.926036</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>192.0</td>\n",
              "      <td>100.387589</td>\n",
              "      <td>97.979164</td>\n",
              "      <td>112.197899</td>\n",
              "      <td>141.857193</td>\n",
              "      <td>146.177078</td>\n",
              "      <td>149.804688</td>\n",
              "      <td>148.243484</td>\n",
              "      <td>136.307709</td>\n",
              "      <td>120.652763</td>\n",
              "      <td>111.440094</td>\n",
              "      <td>107.704849</td>\n",
              "      <td>121.004761</td>\n",
              "      <td>133.996078</td>\n",
              "      <td>137.410156</td>\n",
              "      <td>101.041656</td>\n",
              "      <td>79.719177</td>\n",
              "      <td>85.087677</td>\n",
              "      <td>76.445305</td>\n",
              "      <td>67.940536</td>\n",
              "      <td>55.736111</td>\n",
              "      <td>12.687933</td>\n",
              "      <td>1.869358</td>\n",
              "      <td>1.321615</td>\n",
              "      <td>0.220920</td>\n",
              "      <td>1.176215</td>\n",
              "      <td>1.396267</td>\n",
              "      <td>0.167535</td>\n",
              "      <td>1.312934</td>\n",
              "      <td>97.647125</td>\n",
              "      <td>98.133247</td>\n",
              "      <td>127.645393</td>\n",
              "      <td>150.139313</td>\n",
              "      <td>153.353714</td>\n",
              "      <td>153.862823</td>\n",
              "      <td>145.995209</td>\n",
              "      <td>131.822906</td>\n",
              "      <td>130.025604</td>\n",
              "      <td>128.740448</td>\n",
              "      <td>122.233932</td>\n",
              "      <td>...</td>\n",
              "      <td>94.901901</td>\n",
              "      <td>72.884979</td>\n",
              "      <td>51.791229</td>\n",
              "      <td>17.323784</td>\n",
              "      <td>0.992621</td>\n",
              "      <td>2.551649</td>\n",
              "      <td>1.335069</td>\n",
              "      <td>0.220920</td>\n",
              "      <td>1.176215</td>\n",
              "      <td>1.396267</td>\n",
              "      <td>0.167535</td>\n",
              "      <td>1.312934</td>\n",
              "      <td>117.112404</td>\n",
              "      <td>183.265610</td>\n",
              "      <td>188.404938</td>\n",
              "      <td>167.625412</td>\n",
              "      <td>162.347214</td>\n",
              "      <td>165.499115</td>\n",
              "      <td>163.681412</td>\n",
              "      <td>174.163635</td>\n",
              "      <td>179.729172</td>\n",
              "      <td>179.817261</td>\n",
              "      <td>181.516495</td>\n",
              "      <td>192.932297</td>\n",
              "      <td>160.766037</td>\n",
              "      <td>63.738277</td>\n",
              "      <td>76.068138</td>\n",
              "      <td>132.889740</td>\n",
              "      <td>137.521255</td>\n",
              "      <td>132.654068</td>\n",
              "      <td>98.030380</td>\n",
              "      <td>48.088974</td>\n",
              "      <td>3.383246</td>\n",
              "      <td>2.185764</td>\n",
              "      <td>1.621962</td>\n",
              "      <td>0.220920</td>\n",
              "      <td>1.176215</td>\n",
              "      <td>1.396267</td>\n",
              "      <td>0.167535</td>\n",
              "      <td>1.312934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>180.0</td>\n",
              "      <td>178.968414</td>\n",
              "      <td>173.285431</td>\n",
              "      <td>170.742737</td>\n",
              "      <td>164.271118</td>\n",
              "      <td>157.539276</td>\n",
              "      <td>157.488907</td>\n",
              "      <td>157.170380</td>\n",
              "      <td>152.509155</td>\n",
              "      <td>152.193100</td>\n",
              "      <td>151.270142</td>\n",
              "      <td>151.800507</td>\n",
              "      <td>139.550140</td>\n",
              "      <td>128.777298</td>\n",
              "      <td>141.423218</td>\n",
              "      <td>153.621735</td>\n",
              "      <td>154.040512</td>\n",
              "      <td>155.779770</td>\n",
              "      <td>158.034073</td>\n",
              "      <td>157.106186</td>\n",
              "      <td>144.485931</td>\n",
              "      <td>145.059265</td>\n",
              "      <td>148.198044</td>\n",
              "      <td>150.239517</td>\n",
              "      <td>143.113602</td>\n",
              "      <td>100.759018</td>\n",
              "      <td>82.243469</td>\n",
              "      <td>89.198021</td>\n",
              "      <td>98.939758</td>\n",
              "      <td>177.912628</td>\n",
              "      <td>174.516541</td>\n",
              "      <td>173.559525</td>\n",
              "      <td>167.493835</td>\n",
              "      <td>154.325928</td>\n",
              "      <td>149.755066</td>\n",
              "      <td>149.886917</td>\n",
              "      <td>147.951126</td>\n",
              "      <td>153.322495</td>\n",
              "      <td>160.729385</td>\n",
              "      <td>155.107178</td>\n",
              "      <td>...</td>\n",
              "      <td>145.679031</td>\n",
              "      <td>115.626183</td>\n",
              "      <td>106.520508</td>\n",
              "      <td>108.860252</td>\n",
              "      <td>114.280495</td>\n",
              "      <td>120.055313</td>\n",
              "      <td>128.667664</td>\n",
              "      <td>110.772354</td>\n",
              "      <td>137.966431</td>\n",
              "      <td>176.949646</td>\n",
              "      <td>196.846436</td>\n",
              "      <td>195.552597</td>\n",
              "      <td>167.969894</td>\n",
              "      <td>168.371872</td>\n",
              "      <td>176.228653</td>\n",
              "      <td>179.459274</td>\n",
              "      <td>172.649902</td>\n",
              "      <td>150.554596</td>\n",
              "      <td>153.015808</td>\n",
              "      <td>165.596069</td>\n",
              "      <td>171.074570</td>\n",
              "      <td>178.218292</td>\n",
              "      <td>187.280014</td>\n",
              "      <td>191.316544</td>\n",
              "      <td>193.305695</td>\n",
              "      <td>193.365433</td>\n",
              "      <td>185.692856</td>\n",
              "      <td>160.290878</td>\n",
              "      <td>128.304703</td>\n",
              "      <td>118.023705</td>\n",
              "      <td>118.144691</td>\n",
              "      <td>113.889404</td>\n",
              "      <td>124.038025</td>\n",
              "      <td>130.209885</td>\n",
              "      <td>123.439018</td>\n",
              "      <td>110.596054</td>\n",
              "      <td>98.501236</td>\n",
              "      <td>108.594574</td>\n",
              "      <td>125.621742</td>\n",
              "      <td>143.518036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "0  122.0  123.761337  133.587204  ...  134.521896  132.229507  134.617035\n",
              "1  173.0  173.956955  158.307724  ...   49.259109   17.691870    1.848441\n",
              "2  104.0  114.942314  118.853561  ...    0.807692    0.926036    1.000000\n",
              "3  192.0  100.387589   97.979164  ...    1.396267    0.167535    1.312934\n",
              "5  180.0  178.968414  173.285431  ...  108.594574  125.621742  143.518036\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VaZPe_AxNBK9",
        "outputId": "736b540b-a1c2-4fba-ddf3-fa19aba812f0"
      },
      "source": [
        "PSD_new.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2.211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Area\n",
              "0           1  1.387\n",
              "1           2  1.626\n",
              "2           3  1.336\n",
              "3           4  0.640\n",
              "4           5  2.211"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "\n",
        "# Area = np.array(PSD_new.iloc[:,1])\n",
        "Area = PSD_new['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aUb2_-jsY1Z",
        "outputId": "2607c782-314c-47b1-f174-a578626862ce"
      },
      "source": [
        "PSD_new.iloc[:,1].values"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.387, 1.626, 1.336, 0.64 , 2.211, 1.12 , 0.974, 1.237, 1.29 ,\n",
              "       3.755, 2.778, 1.256, 1.386, 1.302, 1.071, 1.497, 1.518, 1.244,\n",
              "       1.532, 1.325, 1.519, 1.895, 1.22 , 1.241, 1.301, 1.429, 0.667,\n",
              "       2.157, 1.052, 2.082, 1.517, 1.281, 0.784, 1.067, 2.764, 1.215,\n",
              "       0.943, 2.182, 1.486, 1.569, 2.667, 0.709, 1.006, 1.6  , 1.408,\n",
              "       3.16 , 2.465, 2.284, 1.273, 1.256, 3.021, 1.701, 1.955, 5.248,\n",
              "       1.627, 1.367, 1.592, 2.718, 1.658, 1.128, 2.192, 1.508, 2.547,\n",
              "       1.945, 1.606, 3.482, 1.756, 1.457, 1.864, 1.821, 1.314, 1.715,\n",
              "       1.015, 1.345, 1.265, 1.844, 1.396, 1.785, 1.694, 1.413, 1.368,\n",
              "       2.21 , 1.034, 1.367, 1.943, 1.008, 1.279, 1.579, 1.444, 1.879,\n",
              "       1.466, 2.154, 1.794, 3.149, 1.883, 1.692, 1.163, 1.297, 2.949,\n",
              "       1.09 , 1.444, 1.524])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J705kDqsE8f",
        "outputId": "a99082b9-c944-4ebc-b5c5-52d2422e133d"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mK1GBUHWiIr4",
        "outputId": "e8f61972-38c5-46cb-b3ce-270c37c0d212"
      },
      "source": [
        "Freq = [10.52631579, 24.21052632, 36.84210526, 14.73684211,  7.36842105, 0.]\n",
        "Freq2 = [12.90153, 28.11527, 27.66761, 20.21617, 10.34227, 0.]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434, 0.]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "69d5aec3-8306-4193-ee5d-bf4b0381cd03"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9868065450>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUe0lEQVR4nO3df5BdZZ3n8feX0NKzkoJAmhgJ0PxIgTBsGuwEGagxE4TJyI5AFa5QU1aYkg3qgKacnSJC1RBnrQI0M6AWM05Ys2RiUCkkq6gzSwpDWaiAHQgQyAy/jBgqJE1AlF0JBr77xz0NnaY7fbv7/ujHvF9Vt/rc5zzn3m+fPv3p0+c859zITCRJ5dmv3QVIksbHAJekQhngklQoA1ySCmWAS1Kh9m/lm02fPj27u7tb+ZaSVLwNGza8kJldQ9tbGuDd3d309fW18i0lqXgR8Yvh2j2EIkmFMsAlqVAGuCQVqqXHwCXt2373u9+xdetWXn311XaXMil1dnYya9YsOjo66upvgEtqma1btzJ16lS6u7uJiHaXM6lkJjt37mTr1q0cffTRdS3jIRRJLfPqq69y6KGHGt7DiAgOPfTQMf13YoBLainDe2RjXTcGuCQVymPgktqme+n3G/p6W647d9Q+Bx54IK+88kpD33c85s+fz/Lly+nt7R33axjgGtF4frnq+QWS1BgeQpG0T7rnnnt4//vfz3nnnccxxxzD0qVLWbNmDfPmzePkk0/m6aefBuDOO+/ktNNO45RTTuEDH/gA27dvB6C/v5+zzz6bk046iUsvvZSjjjqKF154AYCvf/3rzJs3j56eHi677DJef/31pnwPBrikfdbDDz/MV7/6VTZv3szq1at54okneOCBB7j00kv5yle+AsCZZ57Jfffdx0MPPcRFF13EF77wBQA+97nPsWDBAh577DEuvPBCnn32WQA2b97Mt771LX784x+zceNGpkyZwpo1a5pSv4dQJO2z5s6dy8yZMwE49thjOeeccwA4+eSTWb9+PVAbu/6Rj3yEbdu28dprr705Rvvee+9l7dq1ACxcuJBp06YBcPfdd7Nhwwbmzp0LwG9/+1sOO+ywptQ/aoBHRCfwI+CAqv/tmXlNRNwCvB94uep6SWZubEqVktQEBxxwwJvT++2335vP99tvP3bv3g3AFVdcwWc+8xk+9KEPcc8997Bs2bK9vmZmsmjRIq699tqm1T2gnkMou4AFmTkH6AEWRsT7qnl/k5k91cPwlvR75+WXX+bwww8HYNWqVW+2n3HGGdx2220A3HXXXbz00ksAnHXWWdx+++3s2LEDgBdffJFf/GLYu8FO2Kh74JmZwMCYm47qkU2pRtI+pYRRS8uWLePDH/4w06ZNY8GCBfz85z8H4JprruHiiy9m9erVnH766bzrXe9i6tSpTJ8+nc9//vOcc845vPHGG3R0dHDTTTdx1FFH7fG6u3fv3uM/gPGIWj6P0iliCrABOA64KTOvrA6hnE5tD/1uYGlm7hpm2cXAYoAjjzzyvc36S6TGcxihGm3z5s285z3vaXcZDbFr1y6mTJnC/vvvz09/+lM+8YlPsHFjfQcidu3axXHHHcemTZs46KCD9pg33DqKiA2Z+bYB43WNQsnM1zOzB5gFzIuIPwQ+C5wAzAUOAa4cYdkVmdmbmb1dXW/7RCBJKtKzzz7L3LlzmTNnDp/61Ke4+eab61qur6+Pnp4ePvnJT74tvMdqTKNQMvNXEbEeWJiZy6vmXRHxv4D/PqFKJKkgs2fP5qGHHhrzcr29vWzevLkhNYy6Bx4RXRFxcDX9B8DZwL9HxMyqLYDzgU0NqUiSVJd69sBnAquq4+D7Abdl5vci4ocR0QUEsBH4eBPrlCQNUc8olEeAU4ZpX9CUiiRJdfFSekkqlJfSS2qfZRMbhfH213t51C7PP/88S5Ys4Wc/+xkHH3wwM2bM4MYbb+T444/ny1/+MldccQUAl19+Ob29vVxyySVccsklrFu3jmeeeYYDDjiAF154gd7eXrZs2dLY+sfIPXBJ+4zM5IILLmD+/Pk8/fTTbNiwgWuvvZbt27dz2GGH8aUvfYnXXntt2GWnTJnCypUrW1zx3hngkvYZ69evp6Ojg49//K0xF3PmzOGII46gq6uLs846a4/L5QdbsmQJN9xww5v3SJkMDHBJ+4xNmzbx3ve+d8T5V155JcuXLx/2/t1HHnkkZ555JqtXr25miWNigEtS5ZhjjuG0007j1ltvHXb+Zz/7Wb74xS/yxhtvtLiy4RngkvYZJ510Ehs2bNhrn6uuuorrr7+e4e4TNXv2bHp6et68C2G7GeCS9hkLFixg165drFix4s22Rx55hF/+8pdvPj/hhBM48cQTufPOO4d9jauvvprly5cPO6/VHEYoqX3qGPbXSBHB2rVrWbJkCddffz2dnZ10d3dz44037tHv6quv5pRT3nb9IlDbiz/11FN58MEHW1HyXhngkvYp7373u4c9BLJp01u3c5ozZ84ex7lvueWWPfrecccdTatvLDyEIkmFMsAlqVAGuKSWqudTwPZVY103Brikluns7GTnzp2G+DAyk507d9LZ2Vn3Mp7ElNQys2bNYuvWrfT397e7lEmps7OTWbNm1d3fAJfUMh0dHRx99NHtLuP3hodQJKlQBrgkFcoAl6RC1fOp9J0R8UBEPBwRj0XE56r2oyPi/oh4KiK+FRHvaH65kqQB9eyB7wIWZOYcoAdYGBHvA64HbsjM44CXgI81r0xJ0lCjBnjWvFI97ageCSwAbq/aVwHnN6VCSdKw6joGHhFTImIjsANYBzwN/CozBz5baCtweHNKlCQNp64Az8zXM7MHmAXMA06o9w0iYnFE9EVEn4P3JalxxjQKJTN/BawHTgcOjoiBC4FmAc+NsMyKzOzNzN6urq4JFStJeks9o1C6IuLgavoPgLOBzdSC/MKq2yLgO80qUpL0dvVcSj8TWBURU6gF/m2Z+b2IeBz4ZkR8HngI+FoT65QkDTFqgGfmI8DbPlsoM5+hdjxcktQGXokpSYUywCWpUAa4JBXKAJekQhngklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgpVz/3ApTIsO2iM/V9uTh1Sixjgk1z30u+PeZkt153bhEokTTYeQpGkQhngklQoA1ySCmWAS1KhRg3wiDgiItZHxOMR8VhEfLpqXxYRz0XExurxweaXK0kaUM8olN3AX2fmgxExFdgQEeuqeTdk5vLmlSdJGsmoAZ6Z24Bt1fRvImIzcHizC5Mk7d2YjoFHRDdwCnB/1XR5RDwSESsjYtoIyyyOiL6I6Ovv759QsZKkt9Qd4BFxIPBtYElm/hr4J+BYoIfaHvrfD7dcZq7IzN7M7O3q6mpAyZIkqDPAI6KDWnivycw7ADJze2a+nplvADcD85pXpiRpqFGPgUdEAF8DNmfmPwxqn1kdHwe4ANjUnBJVFO9HIrVMPaNQzgA+CjwaERurtquAiyOiB0hgC3BZUyqUJA2rnlEo9wIxzKwfNL4cSVK9vBJTkgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqHquReKxsObOklqMvfAJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqEMcEkqlAEuSYUaNcAj4oiIWB8Rj0fEYxHx6ar9kIhYFxFPVl+nNb9cSdKAevbAdwN/nZknAu8D/ioiTgSWAndn5mzg7uq5JKlFRg3wzNyWmQ9W078BNgOHA+cBq6puq4Dzm1WkJOntxnQMPCK6gVOA+4EZmbmtmvU8MKOhlUmS9qruAI+IA4FvA0sy89eD52VmAjnCcosjoi8i+vr7+ydUrCTpLXUFeER0UAvvNZl5R9W8PSJmVvNnAjuGWzYzV2Rmb2b2dnV1NaJmSRL1jUIJ4GvA5sz8h0GzvgssqqYXAd9pfHmSpJHUcz/wM4CPAo9GxMaq7SrgOuC2iPgY8AvgvzanREnScEYN8My8F4gRZp/V2HIkSfXySkxJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqEMcEkqlAEuSYUywCWpUAa4JBVq1A81joiVwH8BdmTmH1Zty4D/BvRX3a7KzB80q0iN0bKDxtj/5ebUIamp6tkDvwVYOEz7DZnZUz0Mb0lqsVEDPDN/BLzYglokSWMwkWPgl0fEIxGxMiKmjdQpIhZHRF9E9PX394/UTZI0RuMN8H8CjgV6gG3A34/UMTNXZGZvZvZ2dXWN8+0kSUONehJzOJm5fWA6Im4GvtewiiSge+n3x7zMls4mFCJNYuPaA4+ImYOeXgBsakw5kqR61TOM8BvAfGB6RGwFrgHmR0QPkMAW4LIm1ihJGsaoAZ6ZFw/T/LUm1CJJGgOvxJSkQhngklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFWpcn4lZjGUHjbH/y82pQ5KawD1wSSqUAS5JhTLAJalQowZ4RKyMiB0RsWlQ2yERsS4inqy+TmtumZKkoerZA78FWDikbSlwd2bOBu6unkuSWmjUAM/MHwEvDmk+D1hVTa8Czm9wXZKkUYz3GPiMzNxWTT8PzBipY0Qsjoi+iOjr7+8f59tJkoaa8EnMzEwg9zJ/RWb2ZmZvV1fXRN9OklQZb4Bvj4iZANXXHY0rSZJUj/EG+HeBRdX0IuA7jSlHklSveoYRfgP4KXB8RGyNiI8B1wFnR8STwAeq55KkFhr1XiiZefEIs85qcC2SpDHwSkxJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUqN/vj1STxqF76ffHvMyW685tQiXS3rkHLkmFMsAlqVAGuCQVygCXpEIZ4JJUKEehSJPMWEfBOAJm3+UeuCQVygCXpEIZ4JJUKANckgplgEtSoQxwSSrUhIYRRsQW4DfA68DuzOxtRFGSpNE1Yhz4n2TmCw14HUnSGHgIRZIKNdEAT+CuiNgQEYuH6xARiyOiLyL6+vv7J/h2kqQBEw3wMzPzVODPgL+KiD8e2iEzV2Rmb2b2dnV1TfDtJEkDJhTgmflc9XUHsBaY14iiJEmjG3eAR8Q7I2LqwDRwDrCpUYVJkvZuIqNQZgBrI2LgdW7NzH9rSFWSpFGNO8Az8xlgTgNrkSSNgcMIJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqH8VPo6jPVTwgG2dDahEEkaxD1wSSqUAS5JhTLAJalQBrgkFcoAl6RCFTMKxZEgUvON9fdsy3XnNqkS1cM9cEkqlAEuSYUywCWpUAa4JBWqmJOYktQspZ68dQ9ckgplgEtSoSYU4BGxMCL+IyKeioiljSpKkjS6cQd4REwBbgL+DDgRuDgiTmxUYZKkvZvIHvg84KnMfCYzXwO+CZzXmLIkSaOJzBzfghEXAgsz89Lq+UeB0zLz8iH9FgOLq6fHA/8xjrebDrwwrkJbyzobyzobyzobq5V1HpWZXUMbmz6MMDNXACsm8hoR0ZeZvQ0qqWmss7Gss7Gss7EmQ50TOYTyHHDEoOezqjZJUgtMJMB/BsyOiKMj4h3ARcB3G1OWJGk04z6Ekpm7I+Jy4P8AU4CVmflYwyrb04QOwbSQdTaWdTaWdTZW2+sc90lMSVJ7eSWmJBXKAJekQrU1wEe7FD8iboiIjdXjiYj41aB5rw+a19STpxGxMiJ2RMSmEeZHRHy5+j4eiYhTB81bFBFPVo9Fba7zL6r6Ho2In0TEnEHztlTtGyOir811zo+Ilwf9fP920LyW3b6hjjr/ZlCNm6pt8pBqXivX5xERsT4iHo+IxyLi08P0afs2Wmedbd9G66xzUmyjZGZbHtROfD4NHAO8A3gYOHEv/a+gdqJ04PkrLaz1j4FTgU0jzP8g8K9AAO8D7q/aDwGeqb5Oq6antbHOPxp4f2q3QLh/0LwtwPRJsj7nA9+b6DbT7DqH9P1z4IdtWp8zgVOr6anAE0PXy2TYRuuss+3baJ11TopttJ174GO9FP9i4BstqWyIzPwR8OJeupwH/EvW3AccHBEzgT8F1mXmi5n5ErAOWNiuOjPzJ1UdAPdRG7vfcnWsz5G09PYNY6yzndvntsx8sJr+DbAZOHxIt7Zvo/XUORm20TrX50hauo22M8APB3456PlWRlhJEXEUcDTww0HNnRHRFxH3RcT5zSuzLiN9L3V/j23wMWp7ZAMSuCsiNkTt9gftdnpEPBwR/xoRJ1Vtk3J9RsR/ohZ63x7U3Jb1GRHdwCnA/UNmTaptdC91Dtb2bXSUOtu+jZbyiTwXAbdn5uuD2o7KzOci4hjghxHxaGY+3ab6ihIRf0Ltl+PMQc1nVuvzMGBdRPx7tQfaDg9S+/m+EhEfBP43MLtNtdTjz4EfZ+bgvfWWr8+IOJDaH5ElmfnrZr7XRNRT52TYRkepc1Jso+3cAx/LpfgXMeTf08x8rvr6DHAPtb+S7TLS9zLpbjcQEf8Z+J/AeZm5c6B90PrcAayl9q9gW2TmrzPzlWr6B0BHRExnEq7Pyt62z5asz4jooBY2azLzjmG6TIpttI46J8U2Olqdk2YbbfYJgZEe1Pb+n6F2aGTgYP9Jw/Q7gdrJixjUNg04oJqeDjxJE08UVO/Tzcgn3c5lzxNED1TthwA/r+qdVk0f0sY6jwSeAv5oSPs7gamDpn9C7U6T7arzXQM/b2q/pM9W67aubaZVdVbzD6J2nPyd7Vqf1br5F+DGvfRp+zZaZ51t30brrHNSbKNtO4SSI1yKHxF/B/Rl5sDQwIuAb2a1pirvAf45It6g9l/EdZn5eLNqjYhvUDvrPD0itgLXAB3V9/FV4AfUzvI/Bfw/4C+reS9GxP+gdt8YgL/LPf/NbnWdfwscCvxjRADsztrd1GYAa6u2/YFbM/Pf2ljnhcAnImI38Fvgourn38rbN9RTJ8AFwF2Z+X8HLdrS9QmcAXwUeDQiNlZtV1ELw8m0jdZT52TYRuupc3Jso3vmoiSpFF6JKUmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgplgEtSof4/UIgxE9h+CpMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "132cc44f-eb53-4211-aad9-2e3b05346924"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.01960784, 0.04901961, 0.31372549, 0.67647059, 0.82352941,\n",
              "         0.90196078, 0.97058824, 0.99019608, 0.99019608, 1.        ],\n",
              "        [0.11111111, 0.33333333, 0.48888889, 0.73333333, 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.7397148 , 0.92423821, 1.10876163, 1.29328505, 1.47780846,\n",
              "        1.66233188, 1.8468553 , 2.03137871, 2.21590213, 2.40042554,\n",
              "        2.58494896]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xENlBUUxfTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b8143d4d-fe06-4ec6-cd37-0636a995f41b"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r_squared = 0.8836165728061469\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KukfpGTTKlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "fe2d3165-c9b6-41db-ec82-324f9d35b906"
      },
      "source": [
        "df"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.883617</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.823129</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.694839</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2  ...  loss test                                 Details\n",
              "0  20  20  ...   0.694839  3 layers of Convolution: 64, 128, 256 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHa1j4HT9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "32ebdee6-36ee-4242-cfca-ec99e18715fe"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.7397148  0.92423821 1.10876163 1.29328505 1.47780846 1.66233188\n",
            " 1.8468553  2.03137871 2.21590213 2.40042554 2.58494896]\n",
            "[[ 1.96078431  2.94117647 26.47058824 36.2745098  14.70588235  7.84313725\n",
            "   6.8627451   1.96078431  0.          0.98039216]\n",
            " [11.11111111 22.22222222 15.55555556 24.44444444 26.66666667  0.\n",
            "   0.          0.          0.          0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f692e6-4047-4f85-ba16-ef4a2b9cfcaa"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200.0000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "55c6ca1a-e415-4adf-d196-19b19fb8c523"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f986bb3bc10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8754d1-530b-443c-c3ab-088ace4fb90e"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.3289030245084366,\n",
              "  1.4388493665910183,\n",
              "  1.3042423209535017,\n",
              "  0.9027033336764101,\n",
              "  1.6778356991700483,\n",
              "  1.1941642642883694,\n",
              "  1.113613629842976,\n",
              "  1.254988970803089,\n",
              "  1.2815923738491737,\n",
              "  2.186553107171316,\n",
              "  1.8807071689325485,\n",
              "  1.2645903954195463,\n",
              "  1.3284238815238665,\n",
              "  1.2875394701698204,\n",
              "  1.1677497815933682,\n",
              "  1.3805939296073044,\n",
              "  1.3902437300372827,\n",
              "  1.2585348599266302,\n",
              "  1.3966398900698307,\n",
              "  1.2988619621707653,\n",
              "  1.3907015741893414,\n",
              "  1.5533154661153457,\n",
              "  1.2463355264843006,\n",
              "  1.2570164179581493,\n",
              "  1.2870449283923413,\n",
              "  1.3488733481786004,\n",
              "  0.9215480325725586,\n",
              "  1.6572198701420842,\n",
              "  1.157345238492556,\n",
              "  1.6281537802488464,\n",
              "  1.3897857350553149,\n",
              "  1.2771138777750963,\n",
              "  0.9991095050455518,\n",
              "  1.165567069812981,\n",
              "  1.875962180228586,\n",
              "  1.2437789380968078,\n",
              "  1.0957485526731296,\n",
              "  1.6667959343039342,\n",
              "  1.3755122549350303,\n",
              "  1.413404699896484,\n",
              "  1.8427506249649406,\n",
              "  0.9501193805081709,\n",
              "  1.1317592420667806,\n",
              "  1.4272992929222168,\n",
              "  1.3389254195014408,\n",
              "  2.0058506827187097,\n",
              "  1.7715912276177528,\n",
              "  1.7053090981329784,\n",
              "  1.273119766733618,\n",
              "  1.2645903954195463,\n",
              "  1.9612385537320356,\n",
              "  1.4716590860639265,\n",
              "  1.5777145844408116,\n",
              "  2.584948960960377,\n",
              "  1.4392917491892008,\n",
              "  1.319287102056625,\n",
              "  1.4237265731938766,\n",
              "  1.8602862904913782,\n",
              "  1.4529388029682806,\n",
              "  1.1984215478959244,\n",
              "  1.6706109906436855,\n",
              "  1.3856569681781365,\n",
              "  1.8008167925806498,\n",
              "  1.5736743355948497,\n",
              "  1.4299729748651446,\n",
              "  2.1055688292639205,\n",
              "  1.4952620641730152,\n",
              "  1.3620242349823046,\n",
              "  1.540557857201846,\n",
              "  1.5226848692236787,\n",
              "  1.293459223084363,\n",
              "  1.4777028859756633,\n",
              "  1.1368105109938904,\n",
              "  1.3086279790944384,\n",
              "  1.269113085619237,\n",
              "  1.5322707725763225,\n",
              "  1.3332075624036517,\n",
              "  1.507558485549488,\n",
              "  1.4686278591874,\n",
              "  1.341300666036808,\n",
              "  1.319769562157615,\n",
              "  1.6774562271083886,\n",
              "  1.1474012764748687,\n",
              "  1.319287102056625,\n",
              "  1.5728650404343092,\n",
              "  1.1328836926591555,\n",
              "  1.2761165219980004,\n",
              "  1.417901703622935,\n",
              "  1.355934328276106,\n",
              "  1.546744033302657,\n",
              "  1.3662244224803437,\n",
              "  1.6560670213972442,\n",
              "  1.5113542745679724,\n",
              "  2.0023564433863985,\n",
              "  1.5483895061438226,\n",
              "  1.467760644550703,\n",
              "  1.2168720518308382,\n",
              "  1.2850648580991957,\n",
              "  1.937726352564777,\n",
              "  1.1780624362746346,\n",
              "  1.355934328276106,\n",
              "  1.3929885377045959],\n",
              " [1.083424093767878,\n",
              "  1.454489407522323,\n",
              "  0.8145162691765964,\n",
              "  1.5622546801115815,\n",
              "  1.4231024569674144,\n",
              "  1.0645335579493107,\n",
              "  1.0050558644674685,\n",
              "  1.0182444016774048,\n",
              "  1.005640612657181,\n",
              "  1.4102143644705405,\n",
              "  1.5484087229904584,\n",
              "  1.3029099436665117,\n",
              "  1.0953339517097753,\n",
              "  0.8299070906329501,\n",
              "  1.2756651349072816,\n",
              "  1.6317030765288614,\n",
              "  1.5058501320026694,\n",
              "  1.6080339224824232,\n",
              "  1.1211475417022465,\n",
              "  1.3184643465511814,\n",
              "  0.7783143007204917,\n",
              "  1.2492746440747993,\n",
              "  1.4528056436639867,\n",
              "  1.3412121944629911,\n",
              "  1.3967510313163582,\n",
              "  1.4400940115837697,\n",
              "  0.7397147984262246,\n",
              "  1.5851797189880141,\n",
              "  1.0619883744065528,\n",
              "  1.260361162723066,\n",
              "  1.0495563775632433,\n",
              "  1.4927508264552123,\n",
              "  1.2912647460283173,\n",
              "  1.3889008610997782,\n",
              "  1.508085579162582,\n",
              "  1.0549260097380215,\n",
              "  1.329399453057621,\n",
              "  1.6574205273162836,\n",
              "  1.5203385640171556,\n",
              "  1.6498770301139871,\n",
              "  1.2915376687421394,\n",
              "  1.5547727855425988,\n",
              "  1.0511047904186566,\n",
              "  1.1506501881987266,\n",
              "  0.8218110556836966]]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "5f8d53eb-09e9-47ff-d8fd-eea1e751ba0f"
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4,1.6, 1.8,2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f986801bd10>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "14e3e1d0-91ed-4e00-a1dc-53017095100f"
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18df97b0-32df-478b-96ea-1faf9a13425b"
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.92156863, 11.76470588, 40.19607843, 23.52941176,  8.82352941,\n",
              "        6.8627451 ])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a53e2f0-32d3-4d9c-9999-b615ad92b8bf"
      },
      "source": [
        "bins_list"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "3f06547f-4829-4411-da45-b22917749a5a"
      },
      "source": [
        "df"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "      <th>0.8</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.4</th>\n",
              "      <th>1.6</th>\n",
              "      <th>1.8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.883617</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.823129</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.694839</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>24.444444</td>\n",
              "      <td>28.888889</td>\n",
              "      <td>8.888889</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2       R^2  acc train  ...        1.2        1.4       1.6  1.8\n",
              "0  20  20  0.883617        1.0  ...  24.444444  28.888889  8.888889  0.0\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "519f3c64-9ace-4caa-bb0d-bf6d963d4188"
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f783c8bc-4f11-4a19-a6b7-40113b3ceff6\", \"output.xlsx\", 5254)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}