{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_r_squared_jun_23_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/ANN_%20better_resolution/PSD_histogram_CNN_B_r_squared_jun_23_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e9ec79-ac5c-4897-f644-835bb4cf88dd"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c08f117-7796-4114-9375-815b1909d699"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_fev_2020'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 73 (delta 37), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020/marquesgabi_fev_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc7f50a-1035-4575-e77d-dfca26b4019f"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 369, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 369 (delta 43), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (369/369), 165.41 MiB | 25.67 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqIYzUcnrdMp",
        "outputId": "a6a0398c-187b-4e3e-902e-6120b136686d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[4] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7013912-2e27-4d16-eea7-b10bc145fc35"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 22.80 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN5MN5a_v4np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1142fe41-c275-4ff1-a433-ece842d33bcd"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     151  199.719193  146.160919  ...  149.228317  136.957245  139.731964\n",
            "1     115  179.223053  179.125656  ...  104.448685   99.339050  122.354996\n",
            "2     133  121.722992  118.277016  ...  155.318542  157.385040  157.517990\n",
            "3     160  124.976250  126.253120  ...    0.760000    0.255625    1.380625\n",
            "4     190    0.316454    0.948698  ...  126.066589  147.544495  177.043655\n",
            "5     200   72.693596   70.962799  ...    1.542400    0.824800    0.442400\n",
            "6     199  185.081680  155.313675  ...    1.487134    0.208328    1.288250\n",
            "7     126  115.111115  113.185181  ...  163.962967  166.432098  170.111115\n",
            "8     181  137.957947  138.529373  ...   74.995247   80.142487   85.243500\n",
            "9     172  142.768524  141.323441  ...  192.124954  191.282318  193.135757\n",
            "10    138   92.088211   92.076447  ...    0.878807    1.849821    1.038227\n",
            "11    187  237.937408  247.486877  ...  172.297974  123.670273  118.436211\n",
            "12    182  119.159767  127.976349  ...    1.000000    1.000000    1.000000\n",
            "13    128  105.986328   63.514648  ...  155.025391  153.255859  162.853516\n",
            "14    187  127.343643  122.665100  ...  113.890762  121.823441  118.044037\n",
            "15    148  252.201630  245.397385  ...  137.278320  135.797668  136.013168\n",
            "16    181  211.813339  191.455276  ...   98.327164   90.070854   77.796745\n",
            "17    157  142.335281  144.898956  ...    0.732646    0.299525    1.407806\n",
            "18    101  252.722778  252.789642  ...  160.854233  170.306931  174.184784\n",
            "19    113  114.655960  122.114182  ...  136.828720  136.588379  138.735291\n",
            "20    161  108.831757  121.187157  ...    0.776938    0.247637    1.378072\n",
            "21    148  139.180435   58.288540  ...    0.765522    0.170928    1.224982\n",
            "22    168  184.805557  209.083328  ...  203.138885  229.305557  205.694443\n",
            "23    148  154.060638  155.487228  ...  164.883865  138.159256  192.719513\n",
            "24    154   89.760330  115.694221  ...    1.702479    1.504132    2.000000\n",
            "25    105  127.382240  151.755569  ...    0.888889    1.000000    1.000000\n",
            "26    120  200.101135  188.863358  ...  191.498901  202.428894  204.105560\n",
            "27    161  138.680527  129.478271  ...  133.432892  138.035919  134.455582\n",
            "28    172  134.760956   90.467827  ...    0.584640    0.491617    1.677664\n",
            "29    160   61.848751   67.898125  ...    0.848125    1.743750    0.680625\n",
            "30    151  133.324203  122.629402  ...  208.688934  213.577393  214.242798\n",
            "31    142  200.695496  192.909744  ...    0.475501    0.419163    1.433248\n",
            "32    134  155.935410  152.869232  ...  234.974609  249.505249  250.193115\n",
            "33    149  111.118103  103.202873  ...    0.592361    0.350750    1.411153\n",
            "34    103  142.098206  140.799500  ...  155.847107  162.571487  170.014603\n",
            "35    168  227.972229  241.750000  ...  151.138885  142.638885  137.388885\n",
            "36    115  118.311371  131.148117  ...  149.596573  141.128983   83.537910\n",
            "37    186   65.935608  118.488274  ...  209.129517  205.792023  187.680328\n",
            "38    177  169.511810  159.603226  ...  178.886383  189.493195  207.322250\n",
            "39    103  186.115173  173.757370  ...  122.200867  126.102188  137.493439\n",
            "40    106  217.956589  218.375214  ...  157.805649  155.519409  150.038452\n",
            "41    139  150.060028  163.433655  ...  186.613312  181.027206  124.257385\n",
            "42    123  249.565018  247.927765  ...  181.521332  185.947983  188.312042\n",
            "43    111  142.699463  133.556519  ...  191.197708  187.418243  186.802368\n",
            "44    191  110.450958  123.510628  ...    0.912091    0.340862    1.607878\n",
            "45    100  142.926392  143.110397  ...    0.916800    1.153600    0.840000\n",
            "46    104  164.974869  165.874283  ...  204.568069  204.946762  198.834351\n",
            "47    147  147.816330  153.149658  ...  171.863953  164.761917  167.619049\n",
            "48    194  142.590485  199.835236  ...  109.570717  119.940796  136.257278\n",
            "49    172  133.542465  134.653870  ...  182.658737  152.510010  139.275299\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpQ1Pz0fX5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3551c639-404f-4436-c485-058422291fe5"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "5fabec8c-4b0a-46ca-a5ab-cad3528351cb"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 22.71 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 32, 64, 128 '\n",
        "N1 = 200\n",
        "N2 = 10\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=32, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "f8e7f4fe-c656-4a5c-9b2f-482d0a34ba51"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 3s 125ms/step - loss: 0.5920 - accuracy: 0.6467 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.2754 - accuracy: 0.8995 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.1614 - accuracy: 0.9413 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.1342 - accuracy: 0.9544 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0973 - accuracy: 0.9510 - val_loss: 0.6935 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0664 - accuracy: 0.9667 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0901 - accuracy: 0.9722 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0476 - accuracy: 0.9716 - val_loss: 0.6956 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0475 - accuracy: 0.9798 - val_loss: 0.6956 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0539 - accuracy: 0.9861 - val_loss: 0.6959 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0276 - accuracy: 0.9914 - val_loss: 0.7009 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0187 - accuracy: 0.9978 - val_loss: 0.7054 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.7056 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.7163 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.7176 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.7328 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 9.9445e-04 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.4185e-04 - accuracy: 1.0000 - val_loss: 0.7706 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 5.0717e-04 - accuracy: 1.0000 - val_loss: 0.7763 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7926 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 7.1227e-04 - accuracy: 1.0000 - val_loss: 0.8201 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 9.6573e-04 - accuracy: 1.0000 - val_loss: 0.8411 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.8895e-04 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 7.8505e-04 - accuracy: 1.0000 - val_loss: 0.8863 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 4.3844e-04 - accuracy: 1.0000 - val_loss: 0.9187 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 7.2714e-04 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.1226e-04 - accuracy: 1.0000 - val_loss: 1.0080 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.2020e-04 - accuracy: 1.0000 - val_loss: 1.0219 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.2296e-04 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.4096e-04 - accuracy: 1.0000 - val_loss: 1.1044 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.0684e-04 - accuracy: 1.0000 - val_loss: 1.1896 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.9042e-04 - accuracy: 1.0000 - val_loss: 1.2590 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.9055e-04 - accuracy: 1.0000 - val_loss: 1.3852 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.9608e-04 - accuracy: 1.0000 - val_loss: 1.4775 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.9444e-04 - accuracy: 1.0000 - val_loss: 1.5488 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.1663e-04 - accuracy: 1.0000 - val_loss: 1.6169 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.9884e-04 - accuracy: 1.0000 - val_loss: 1.6969 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.2630e-04 - accuracy: 1.0000 - val_loss: 1.7982 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.7906e-04 - accuracy: 1.0000 - val_loss: 1.8878 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 9.2361e-05 - accuracy: 1.0000 - val_loss: 1.9509 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 9.8958e-05 - accuracy: 1.0000 - val_loss: 2.0100 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.8738e-05 - accuracy: 1.0000 - val_loss: 2.0820 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.7945e-04 - accuracy: 1.0000 - val_loss: 2.2878 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.8756e-04 - accuracy: 1.0000 - val_loss: 0.9124 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.5113e-04 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.5238\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 7.8198e-05 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.5238\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.0748e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.5782\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.8518e-05 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.6871\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.6497e-05 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.7823\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 3.4333e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.8503\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 7.7316e-05 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.8367\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.6451e-05 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.8095\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.3077e-05 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.7959\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 9.2585e-05 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.7959\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 7.6609e-05 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.8776\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.8541e-04 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9524\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 6.7057e-05 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.8844\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.0905e-04 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.8435\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.1312e-05 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8844\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.2069e-04 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9456\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.1510e-05 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9660\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.5201e-04 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9320\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 8.7096e-05 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.8980\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.7474e-05 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9252\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 5.1169e-05 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9388\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.7731e-04 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9524\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 7.8569e-05 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9524\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.1485e-04 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9388\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.5461e-04 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9524\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 4.3135e-05 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9592\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 7.5476e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9456\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.9195e-04 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9048\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.4556e-05 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.8776\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 6.1461e-05 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.8980\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.2703e-04 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.8571\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 6.4579e-05 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8503\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 4.6990e-05 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 0.8503\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.6606e-05 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.8571\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 5.5523e-05 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8980\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.6088e-05 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.8980\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.1990e-05 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9116\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 4.4426e-05 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9184\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 4.7155e-05 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9388\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.8622e-05 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9796\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.6864e-05 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9796\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.1414e-05 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9796\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 4.2172e-05 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9728\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.0030e-05 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9728\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.4782e-05 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9660\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.5848e-05 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9524\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.0209e-05 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9524\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.8903e-05 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9524\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 8.1657e-05 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9660\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 2.6855e-05 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9660\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.8245e-05 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9660\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.8815e-05 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9728\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.5097e-05 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9728\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.7889e-05 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9660\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.0006e-05 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9660\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.6963e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9728\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 5.3301e-05 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9592\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.1292e-05 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9524\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.3297e-04 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9728\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 8.0016e-05 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9388\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.5337e-05 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9184\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.0308e-05 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9320\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.9925e-05 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9320\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 4.1370e-05 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.8912\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.8553e-05 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8571\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.3824e-04 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.8435\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.4080e-05 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.8367\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.6441e-05 - accuracy: 1.0000 - val_loss: 1.2413 - val_accuracy: 0.7687\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.6435e-05 - accuracy: 1.0000 - val_loss: 0.8456 - val_accuracy: 0.8367\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 2.6572e-05 - accuracy: 1.0000 - val_loss: 0.9837 - val_accuracy: 0.8095\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.5208e-05 - accuracy: 1.0000 - val_loss: 1.1000 - val_accuracy: 0.8027\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 1.5833e-05 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.8299\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.6369e-05 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.8776\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.5421e-05 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.8912\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.9337e-05 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9320\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.5063e-05 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9524\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 2.3318e-04 - accuracy: 1.0000 - val_loss: 9.3418 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.2832e-05 - accuracy: 1.0000 - val_loss: 13.5334 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.8241e-05 - accuracy: 1.0000 - val_loss: 13.5114 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.5192e-05 - accuracy: 1.0000 - val_loss: 12.0882 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.3679e-05 - accuracy: 1.0000 - val_loss: 10.8930 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 6.6855e-05 - accuracy: 1.0000 - val_loss: 9.4044 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 6.6352e-06 - accuracy: 1.0000 - val_loss: 7.3878 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.5108e-05 - accuracy: 1.0000 - val_loss: 6.3508 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.3934e-05 - accuracy: 1.0000 - val_loss: 5.4335 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.6976e-05 - accuracy: 1.0000 - val_loss: 4.4749 - val_accuracy: 0.5238\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 1.2622e-05 - accuracy: 1.0000 - val_loss: 3.5469 - val_accuracy: 0.5782\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.2814e-05 - accuracy: 1.0000 - val_loss: 2.2918 - val_accuracy: 0.6531\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 9.2435e-06 - accuracy: 1.0000 - val_loss: 1.4324 - val_accuracy: 0.7347\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 9.8233e-06 - accuracy: 1.0000 - val_loss: 0.9236 - val_accuracy: 0.7891\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.1109e-05 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8435\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.2051e-04 - accuracy: 1.0000 - val_loss: 0.8445 - val_accuracy: 0.7347\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.5905e-05 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.8435\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.2023e-05 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.8844\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 4.4361e-05 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9048\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 7.9571e-06 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9116\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.7793e-05 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9252\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.0313e-05 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9456\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.3185e-05 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9524\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.3587e-05 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9524\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.9469e-05 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9456\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.7390e-05 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9592\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.4106e-05 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9660\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.2790e-05 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9796\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.5895e-05 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9456\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 6.6406e-06 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9252\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.7252e-05 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.8980\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 3.5516e-06 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9184\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.2986e-05 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9728\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 6.7596e-06 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9660\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 5.1907e-06 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9660\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 8.4658e-06 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9592\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 6.9447e-06 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9592\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.5620e-05 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9592\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.1961e-05 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9524\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.2383e-05 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9592\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 7.1475e-06 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9728\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.3824e-05 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9728\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 8.3030e-06 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9660\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.3599e-05 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9388\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 6.6714e-06 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9048\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.0125e-05 - accuracy: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.8503\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.9315e-06 - accuracy: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.8435\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 8.7420e-06 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.8639\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.4454e-05 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9048\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 4.7977e-06 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9184\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.0368e-05 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9184\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.9105e-06 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9320\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.2972e-05 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9524\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.1565e-05 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9388\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.2527e-05 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9524\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.6748e-05 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9456\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.5317e-05 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9388\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.6601e-05 - accuracy: 1.0000 - val_loss: 1.1210 - val_accuracy: 0.7551\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 4.1077e-06 - accuracy: 1.0000 - val_loss: 2.4562 - val_accuracy: 0.6190\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.1715e-05 - accuracy: 1.0000 - val_loss: 1.2471 - val_accuracy: 0.7483\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 8.4228e-06 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.8299\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.4575e-06 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.8707\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.4442e-06 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9184\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.3555e-05 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9524\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 1.2434e-05 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.8095\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.4355e-05 - accuracy: 1.0000 - val_loss: 1.9271 - val_accuracy: 0.6871\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.6171e-06 - accuracy: 1.0000 - val_loss: 2.5939 - val_accuracy: 0.6190\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 6.8666e-06 - accuracy: 1.0000 - val_loss: 2.8204 - val_accuracy: 0.5986\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.2507e-06 - accuracy: 1.0000 - val_loss: 2.6739 - val_accuracy: 0.6190\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 3.5646e-06 - accuracy: 1.0000 - val_loss: 2.5397 - val_accuracy: 0.6463\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 9.4190e-06 - accuracy: 1.0000 - val_loss: 2.5551 - val_accuracy: 0.6735\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 4.3139e-06 - accuracy: 1.0000 - val_loss: 2.4101 - val_accuracy: 0.6871\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 5.4298e-06 - accuracy: 1.0000 - val_loss: 1.9810 - val_accuracy: 0.7075\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 8.0537e-06 - accuracy: 1.0000 - val_loss: 1.6995 - val_accuracy: 0.7347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpf0XlSARX78",
        "outputId": "da81c546-6b4c-4fb3-e534-56305ac7a324"
      },
      "source": [
        "pred_test= model.predict_classes(X_test)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predict   0   1\n",
            "Actual         \n",
            "0        33  39\n",
            "1         0  75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFNNrlWV9tH",
        "outputId": "2d7e6509-5024-4203-8453-19b9fd3a77d0"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QISvYcJBgWbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3e846e-5482-4bd8-cfe5-b61298354a4f"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[4] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  prediction = model.predict_classes(result)\n",
        "  loc_grao =[];k=0\n",
        "  for i in prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0   158.0   28.232012  121.817329  ...    0.727608    0.271912    1.385836\n",
            "1   174.0   90.534409   91.254990  ...    1.052187    0.163430    1.347734\n",
            "2   136.0  124.560555  131.627167  ...    8.750000   18.241348   53.448097\n",
            "3   184.0  129.102554  111.531662  ...    1.297259    0.159735    1.340737\n",
            "4   158.0   31.226887   77.234901  ...    0.727608    0.271912    1.385836\n",
            "5   192.0  178.493057  176.296432  ...  253.065948  253.609787  253.085480\n",
            "6   103.0  155.724945  161.071533  ...    1.000000    1.000000    1.000000\n",
            "7   195.0  121.574524  109.282089  ...    1.456621    0.220934    1.328416\n",
            "8   119.0  130.927338  135.522491  ...  161.107285  149.609009  141.941193\n",
            "9   127.0  165.476105  177.337585  ...  139.719818  140.990891  147.968384\n",
            "10  148.0  155.099350  144.219879  ...  135.805710  142.177505  107.492340\n",
            "11  106.0   90.534363   96.389816  ...  138.467789  142.205414  147.387344\n",
            "12  194.0  218.067368  223.949188  ...    1.422893    0.175683    1.309491\n",
            "13  175.0  154.510391  161.262390  ...  147.919983  111.113594  106.374397\n",
            "14  200.0  187.445190  174.129593  ...   92.559189   17.254002    7.856400\n",
            "15  193.0  139.129349  128.608368  ...    1.409649    0.171629    1.311203\n",
            "16  190.0    1.611191    0.348033  ...   74.919220   86.305710  108.643425\n",
            "17  104.0  121.044388  122.479294  ...    1.380178    0.726331    0.000000\n",
            "18  167.0  182.923462  181.845337  ...  157.712280  156.041382  152.100403\n",
            "19  186.0  179.380981  185.107880  ...  143.578461  147.644135  144.408142\n",
            "20  111.0  131.715607  130.000000  ...  113.768127  104.454826  104.024834\n",
            "21  167.0  129.188080  163.667557  ...  143.168701  145.269928  149.009979\n",
            "22  173.0  137.048935  133.616409  ...    1.025694    0.168499    1.349895\n",
            "23  154.0  116.165306  122.727272  ...    1.487603    0.396694    0.578512\n",
            "24  161.0  108.667305  110.916832  ...    0.984877    1.701323    1.705104\n",
            "25  146.0  156.014816  160.434799  ...  166.931503  169.052551  173.498383\n",
            "26  183.0  146.168213  163.323502  ...  139.897736  134.207779  121.466087\n",
            "27  164.0    0.883403    6.449138  ...  103.238548  115.136826  123.362885\n",
            "28  163.0  109.708649  134.851944  ...  168.159241  171.698639  162.544495\n",
            "29  113.0  133.473267  128.199387  ...  177.758148  187.072983  226.880173\n",
            "30  133.0  128.033234  126.337952  ...  150.767319  147.922440  144.875336\n",
            "31  150.0  126.997154  142.373871  ...   34.694221   51.318043   94.828438\n",
            "32  148.0   94.623093   60.760414  ...  188.680069  182.919662  176.484314\n",
            "33  130.0  110.182022  134.817291  ...    1.000000    1.000000    1.000000\n",
            "34  120.0   71.971115   72.590004  ...   12.668888    8.198889    9.304444\n",
            "35  169.0  136.274170  119.891426  ...  202.921478  205.814514  208.863373\n",
            "36  158.0  220.006409  225.108139  ...  186.111374  165.842667  153.777588\n",
            "37  196.0  203.693878  229.816315  ...  178.102036  159.183670  111.714287\n",
            "38  138.0  249.317780  250.020996  ...  149.114059  145.281036  133.798569\n",
            "39  161.0  231.253326  229.449905  ...    1.378072    0.291115    0.725898\n",
            "40  117.0    1.159763    2.171817  ...  138.066986  141.948135  142.589233\n",
            "41  151.0   87.069824  104.945183  ...  134.792725  152.471832  161.465820\n",
            "42  150.0  177.010513  178.169937  ...  134.078751  128.359467   88.920181\n",
            "43  140.0  149.520004  151.039993  ...  126.320000  123.639999  127.879997\n",
            "44  163.0  140.122772  132.637360  ...  187.487305  185.139679  181.877075\n",
            "46  119.0  205.294098  198.076141  ...  143.955017  105.159164   97.650528\n",
            "47  198.0  128.835602   90.511574  ...   77.788696   80.209061   84.464539\n",
            "48  110.0  141.721649  141.346786  ...  162.345123  160.603302  148.237015\n",
            "49  163.0  239.970612  229.496750  ...  215.205688  192.669708  179.844925\n",
            "\n",
            "[49 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "c6258fc1-16a5-4960-d2c6-d62b165cc5ed"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_paper_fev_2021'...\n",
            "remote: Enumerating objects: 671, done.\u001b[K\n",
            "remote: Counting objects: 100% (432/432), done.\u001b[K\n",
            "remote: Compressing objects: 100% (430/430), done.\u001b[K\n",
            "remote: Total 671 (delta 270), reused 0 (delta 0), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (671/671), 5.50 MiB | 2.86 MiB/s, done.\n",
            "Resolving deltas: 100% (407/407), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "2ac98595-6fee-4080-a101-27dcd4e6a471"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "%cd marquesgabi_out_2020\n",
        "PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "PSD_new = pd.read_csv(PSD_imageJ)\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_out_2020'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 146 (delta 75), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 1.00 MiB | 5.87 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020\n",
            "   Juntas   Area\n",
            "0       1  2.001\n",
            "1       2  0.820\n",
            "2       3  1.270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tEPjIBnv_xM",
        "outputId": "7585e2d8-4a3b-4d38-fe12-9e1f0c2ea32b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfagXc-Mv3oa"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "PekBHQOT_6CP",
        "outputId": "14572135-f767-4491-8185-b63bd0aa76d4"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>158.0</td>\n",
              "      <td>28.232012</td>\n",
              "      <td>121.817329</td>\n",
              "      <td>139.675064</td>\n",
              "      <td>146.120819</td>\n",
              "      <td>148.306992</td>\n",
              "      <td>147.905792</td>\n",
              "      <td>151.324936</td>\n",
              "      <td>152.295944</td>\n",
              "      <td>148.062653</td>\n",
              "      <td>129.607590</td>\n",
              "      <td>84.703415</td>\n",
              "      <td>70.042305</td>\n",
              "      <td>80.429100</td>\n",
              "      <td>82.243881</td>\n",
              "      <td>81.603592</td>\n",
              "      <td>87.127060</td>\n",
              "      <td>93.061203</td>\n",
              "      <td>71.080750</td>\n",
              "      <td>22.560328</td>\n",
              "      <td>0.924371</td>\n",
              "      <td>1.153020</td>\n",
              "      <td>1.317417</td>\n",
              "      <td>0.203493</td>\n",
              "      <td>0.858516</td>\n",
              "      <td>1.789937</td>\n",
              "      <td>0.747797</td>\n",
              "      <td>0.292101</td>\n",
              "      <td>1.406025</td>\n",
              "      <td>57.547188</td>\n",
              "      <td>131.463211</td>\n",
              "      <td>133.110077</td>\n",
              "      <td>137.784317</td>\n",
              "      <td>137.296280</td>\n",
              "      <td>147.643951</td>\n",
              "      <td>153.738007</td>\n",
              "      <td>161.010590</td>\n",
              "      <td>158.002411</td>\n",
              "      <td>154.461624</td>\n",
              "      <td>142.755325</td>\n",
              "      <td>...</td>\n",
              "      <td>161.776154</td>\n",
              "      <td>100.543983</td>\n",
              "      <td>31.520428</td>\n",
              "      <td>2.140843</td>\n",
              "      <td>0.997116</td>\n",
              "      <td>0.819260</td>\n",
              "      <td>0.417722</td>\n",
              "      <td>0.605512</td>\n",
              "      <td>1.385836</td>\n",
              "      <td>0.727608</td>\n",
              "      <td>0.271912</td>\n",
              "      <td>1.385836</td>\n",
              "      <td>132.490295</td>\n",
              "      <td>115.829834</td>\n",
              "      <td>117.912354</td>\n",
              "      <td>123.169205</td>\n",
              "      <td>119.728882</td>\n",
              "      <td>115.156868</td>\n",
              "      <td>115.815735</td>\n",
              "      <td>117.344337</td>\n",
              "      <td>118.057198</td>\n",
              "      <td>123.815254</td>\n",
              "      <td>130.477173</td>\n",
              "      <td>130.748901</td>\n",
              "      <td>140.625702</td>\n",
              "      <td>150.308762</td>\n",
              "      <td>162.332794</td>\n",
              "      <td>167.326889</td>\n",
              "      <td>113.665916</td>\n",
              "      <td>43.258293</td>\n",
              "      <td>45.099983</td>\n",
              "      <td>9.518827</td>\n",
              "      <td>1.615286</td>\n",
              "      <td>0.939433</td>\n",
              "      <td>0.199167</td>\n",
              "      <td>0.683704</td>\n",
              "      <td>1.385836</td>\n",
              "      <td>0.727608</td>\n",
              "      <td>0.271912</td>\n",
              "      <td>1.385836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>174.0</td>\n",
              "      <td>90.534409</td>\n",
              "      <td>91.254990</td>\n",
              "      <td>91.918739</td>\n",
              "      <td>90.531517</td>\n",
              "      <td>91.883476</td>\n",
              "      <td>89.884270</td>\n",
              "      <td>91.167397</td>\n",
              "      <td>91.032639</td>\n",
              "      <td>135.747269</td>\n",
              "      <td>218.951675</td>\n",
              "      <td>229.710297</td>\n",
              "      <td>243.563370</td>\n",
              "      <td>250.800262</td>\n",
              "      <td>249.257126</td>\n",
              "      <td>237.517807</td>\n",
              "      <td>149.055634</td>\n",
              "      <td>62.579342</td>\n",
              "      <td>83.527153</td>\n",
              "      <td>87.233337</td>\n",
              "      <td>21.510241</td>\n",
              "      <td>2.570088</td>\n",
              "      <td>2.637204</td>\n",
              "      <td>0.730083</td>\n",
              "      <td>0.376272</td>\n",
              "      <td>1.571674</td>\n",
              "      <td>1.060906</td>\n",
              "      <td>0.171357</td>\n",
              "      <td>1.353283</td>\n",
              "      <td>80.669983</td>\n",
              "      <td>92.918625</td>\n",
              "      <td>95.249443</td>\n",
              "      <td>92.882950</td>\n",
              "      <td>88.841599</td>\n",
              "      <td>87.782539</td>\n",
              "      <td>84.280365</td>\n",
              "      <td>80.776596</td>\n",
              "      <td>85.542480</td>\n",
              "      <td>202.621887</td>\n",
              "      <td>248.951935</td>\n",
              "      <td>...</td>\n",
              "      <td>0.289867</td>\n",
              "      <td>0.850311</td>\n",
              "      <td>1.685956</td>\n",
              "      <td>0.508257</td>\n",
              "      <td>0.600211</td>\n",
              "      <td>1.707095</td>\n",
              "      <td>0.737218</td>\n",
              "      <td>0.381821</td>\n",
              "      <td>1.577223</td>\n",
              "      <td>1.069626</td>\n",
              "      <td>0.179284</td>\n",
              "      <td>1.358832</td>\n",
              "      <td>0.192364</td>\n",
              "      <td>0.988770</td>\n",
              "      <td>1.600608</td>\n",
              "      <td>0.405205</td>\n",
              "      <td>0.682917</td>\n",
              "      <td>1.345885</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375875</td>\n",
              "      <td>0.042674</td>\n",
              "      <td>0.827454</td>\n",
              "      <td>1.255780</td>\n",
              "      <td>0.086273</td>\n",
              "      <td>1.221298</td>\n",
              "      <td>1.474171</td>\n",
              "      <td>0.278769</td>\n",
              "      <td>0.829700</td>\n",
              "      <td>1.673273</td>\n",
              "      <td>0.497159</td>\n",
              "      <td>0.589114</td>\n",
              "      <td>1.688070</td>\n",
              "      <td>0.722949</td>\n",
              "      <td>0.370723</td>\n",
              "      <td>1.566125</td>\n",
              "      <td>1.052187</td>\n",
              "      <td>0.163430</td>\n",
              "      <td>1.347734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>136.0</td>\n",
              "      <td>124.560555</td>\n",
              "      <td>131.627167</td>\n",
              "      <td>137.104675</td>\n",
              "      <td>152.467133</td>\n",
              "      <td>166.414352</td>\n",
              "      <td>178.687714</td>\n",
              "      <td>185.121979</td>\n",
              "      <td>203.269043</td>\n",
              "      <td>214.232712</td>\n",
              "      <td>214.366791</td>\n",
              "      <td>208.192047</td>\n",
              "      <td>201.141861</td>\n",
              "      <td>189.114197</td>\n",
              "      <td>183.314026</td>\n",
              "      <td>175.264709</td>\n",
              "      <td>167.779434</td>\n",
              "      <td>163.721451</td>\n",
              "      <td>169.032867</td>\n",
              "      <td>181.465393</td>\n",
              "      <td>184.796722</td>\n",
              "      <td>185.301041</td>\n",
              "      <td>184.463669</td>\n",
              "      <td>175.578720</td>\n",
              "      <td>131.026825</td>\n",
              "      <td>124.214539</td>\n",
              "      <td>126.602081</td>\n",
              "      <td>129.179932</td>\n",
              "      <td>133.179932</td>\n",
              "      <td>126.865059</td>\n",
              "      <td>132.371979</td>\n",
              "      <td>132.327866</td>\n",
              "      <td>154.598618</td>\n",
              "      <td>176.476654</td>\n",
              "      <td>182.518158</td>\n",
              "      <td>190.014725</td>\n",
              "      <td>195.701553</td>\n",
              "      <td>208.507782</td>\n",
              "      <td>208.304504</td>\n",
              "      <td>198.651398</td>\n",
              "      <td>...</td>\n",
              "      <td>65.132355</td>\n",
              "      <td>67.583046</td>\n",
              "      <td>68.692909</td>\n",
              "      <td>68.541519</td>\n",
              "      <td>69.921280</td>\n",
              "      <td>76.696373</td>\n",
              "      <td>87.696373</td>\n",
              "      <td>97.551903</td>\n",
              "      <td>70.287201</td>\n",
              "      <td>8.475779</td>\n",
              "      <td>24.070070</td>\n",
              "      <td>70.790649</td>\n",
              "      <td>131.178192</td>\n",
              "      <td>138.854675</td>\n",
              "      <td>135.314026</td>\n",
              "      <td>139.781143</td>\n",
              "      <td>133.823532</td>\n",
              "      <td>132.591705</td>\n",
              "      <td>136.066620</td>\n",
              "      <td>124.618515</td>\n",
              "      <td>78.480972</td>\n",
              "      <td>35.513840</td>\n",
              "      <td>29.832180</td>\n",
              "      <td>27.916956</td>\n",
              "      <td>61.094292</td>\n",
              "      <td>97.500862</td>\n",
              "      <td>81.911766</td>\n",
              "      <td>73.306229</td>\n",
              "      <td>71.598618</td>\n",
              "      <td>69.799309</td>\n",
              "      <td>73.740486</td>\n",
              "      <td>70.987892</td>\n",
              "      <td>69.776825</td>\n",
              "      <td>76.678200</td>\n",
              "      <td>86.326126</td>\n",
              "      <td>98.121117</td>\n",
              "      <td>72.234428</td>\n",
              "      <td>8.750000</td>\n",
              "      <td>18.241348</td>\n",
              "      <td>53.448097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>184.0</td>\n",
              "      <td>129.102554</td>\n",
              "      <td>111.531662</td>\n",
              "      <td>102.106796</td>\n",
              "      <td>113.722107</td>\n",
              "      <td>117.895554</td>\n",
              "      <td>124.288269</td>\n",
              "      <td>131.961243</td>\n",
              "      <td>126.043938</td>\n",
              "      <td>121.491478</td>\n",
              "      <td>104.678635</td>\n",
              "      <td>102.974945</td>\n",
              "      <td>113.829849</td>\n",
              "      <td>123.939018</td>\n",
              "      <td>125.893181</td>\n",
              "      <td>129.448486</td>\n",
              "      <td>129.310959</td>\n",
              "      <td>123.436188</td>\n",
              "      <td>117.551979</td>\n",
              "      <td>71.494324</td>\n",
              "      <td>34.326557</td>\n",
              "      <td>4.804348</td>\n",
              "      <td>3.607750</td>\n",
              "      <td>1.271739</td>\n",
              "      <td>0.151701</td>\n",
              "      <td>1.370983</td>\n",
              "      <td>1.284026</td>\n",
              "      <td>0.133270</td>\n",
              "      <td>1.327505</td>\n",
              "      <td>110.815201</td>\n",
              "      <td>58.756138</td>\n",
              "      <td>76.023621</td>\n",
              "      <td>108.926270</td>\n",
              "      <td>115.148865</td>\n",
              "      <td>121.314735</td>\n",
              "      <td>128.162552</td>\n",
              "      <td>131.998093</td>\n",
              "      <td>128.970215</td>\n",
              "      <td>121.431938</td>\n",
              "      <td>121.101593</td>\n",
              "      <td>...</td>\n",
              "      <td>49.508980</td>\n",
              "      <td>45.033077</td>\n",
              "      <td>24.534971</td>\n",
              "      <td>5.786861</td>\n",
              "      <td>2.827977</td>\n",
              "      <td>1.396503</td>\n",
              "      <td>1.244801</td>\n",
              "      <td>0.170132</td>\n",
              "      <td>1.380907</td>\n",
              "      <td>1.293951</td>\n",
              "      <td>0.153119</td>\n",
              "      <td>1.337429</td>\n",
              "      <td>178.250473</td>\n",
              "      <td>175.527863</td>\n",
              "      <td>168.433365</td>\n",
              "      <td>157.827026</td>\n",
              "      <td>148.733932</td>\n",
              "      <td>146.551025</td>\n",
              "      <td>146.446121</td>\n",
              "      <td>132.980148</td>\n",
              "      <td>109.321831</td>\n",
              "      <td>103.865311</td>\n",
              "      <td>97.106796</td>\n",
              "      <td>113.984390</td>\n",
              "      <td>125.837891</td>\n",
              "      <td>107.678627</td>\n",
              "      <td>71.286385</td>\n",
              "      <td>54.701794</td>\n",
              "      <td>46.760872</td>\n",
              "      <td>44.854435</td>\n",
              "      <td>47.551506</td>\n",
              "      <td>33.421074</td>\n",
              "      <td>3.429584</td>\n",
              "      <td>1.414461</td>\n",
              "      <td>1.217391</td>\n",
              "      <td>0.176276</td>\n",
              "      <td>1.384215</td>\n",
              "      <td>1.297259</td>\n",
              "      <td>0.159735</td>\n",
              "      <td>1.340737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>158.0</td>\n",
              "      <td>31.226887</td>\n",
              "      <td>77.234901</td>\n",
              "      <td>139.781601</td>\n",
              "      <td>145.684189</td>\n",
              "      <td>149.879013</td>\n",
              "      <td>149.437744</td>\n",
              "      <td>147.410660</td>\n",
              "      <td>131.114883</td>\n",
              "      <td>82.905945</td>\n",
              "      <td>48.627781</td>\n",
              "      <td>64.539658</td>\n",
              "      <td>74.658867</td>\n",
              "      <td>83.854347</td>\n",
              "      <td>84.554565</td>\n",
              "      <td>80.461945</td>\n",
              "      <td>87.678413</td>\n",
              "      <td>83.370773</td>\n",
              "      <td>41.462749</td>\n",
              "      <td>5.808524</td>\n",
              "      <td>1.974523</td>\n",
              "      <td>0.637879</td>\n",
              "      <td>1.224323</td>\n",
              "      <td>0.183304</td>\n",
              "      <td>0.829675</td>\n",
              "      <td>1.758212</td>\n",
              "      <td>0.727608</td>\n",
              "      <td>0.271912</td>\n",
              "      <td>1.385836</td>\n",
              "      <td>22.737221</td>\n",
              "      <td>112.406830</td>\n",
              "      <td>141.984787</td>\n",
              "      <td>146.355560</td>\n",
              "      <td>151.526505</td>\n",
              "      <td>150.171921</td>\n",
              "      <td>149.872131</td>\n",
              "      <td>147.834961</td>\n",
              "      <td>139.673141</td>\n",
              "      <td>106.468506</td>\n",
              "      <td>75.508415</td>\n",
              "      <td>...</td>\n",
              "      <td>166.280731</td>\n",
              "      <td>154.242920</td>\n",
              "      <td>80.467712</td>\n",
              "      <td>6.101426</td>\n",
              "      <td>1.036853</td>\n",
              "      <td>1.170165</td>\n",
              "      <td>2.156385</td>\n",
              "      <td>1.595898</td>\n",
              "      <td>1.282647</td>\n",
              "      <td>0.727608</td>\n",
              "      <td>0.271912</td>\n",
              "      <td>1.385836</td>\n",
              "      <td>128.796509</td>\n",
              "      <td>98.729851</td>\n",
              "      <td>119.918938</td>\n",
              "      <td>122.037170</td>\n",
              "      <td>121.365807</td>\n",
              "      <td>122.491913</td>\n",
              "      <td>124.421089</td>\n",
              "      <td>123.272552</td>\n",
              "      <td>125.569786</td>\n",
              "      <td>128.413544</td>\n",
              "      <td>131.487259</td>\n",
              "      <td>135.699722</td>\n",
              "      <td>142.766220</td>\n",
              "      <td>156.349625</td>\n",
              "      <td>170.922760</td>\n",
              "      <td>167.314041</td>\n",
              "      <td>160.920990</td>\n",
              "      <td>128.384552</td>\n",
              "      <td>38.803879</td>\n",
              "      <td>1.141964</td>\n",
              "      <td>1.107675</td>\n",
              "      <td>0.734658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.367569</td>\n",
              "      <td>1.385836</td>\n",
              "      <td>0.727608</td>\n",
              "      <td>0.271912</td>\n",
              "      <td>1.385836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...       781        782        783\n",
              "0  158.0   28.232012  121.817329  ...  0.727608   0.271912   1.385836\n",
              "1  174.0   90.534409   91.254990  ...  1.052187   0.163430   1.347734\n",
              "2  136.0  124.560555  131.627167  ...  8.750000  18.241348  53.448097\n",
              "3  184.0  129.102554  111.531662  ...  1.297259   0.159735   1.340737\n",
              "4  158.0   31.226887   77.234901  ...  0.727608   0.271912   1.385836\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "Area = np.array(PSD_new['Area'])\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J705kDqsE8f",
        "outputId": "6283ffc7-d240-4200-a413-dbcda4708c8e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mK1GBUHWiIr4",
        "outputId": "87f1c494-5da0-491f-a721-a983c2567380"
      },
      "source": [
        "Freq = [10.52631579, 24.21052632, 36.84210526, 14.73684211,  7.36842105, 0.]\n",
        "Freq2 = [12.90153, 28.11527, 27.66761, 20.21617, 10.34227, 0.]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434, 0.]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Vfk_fNXGDK5_",
        "outputId": "4b35ea34-8a23-4465-8974-fd8bbc530fa4"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe53fd0f850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "20c20b21-392a-485d-af9e-4a90943b55ef"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.07368421, 0.17894737, 0.41052632, 0.74736842, 0.88421053,\n",
              "         0.96842105, 0.97894737, 0.97894737, 0.98947368, 1.        ],\n",
              "        [0.06122449, 0.20408163, 0.36734694, 0.63265306, 0.81632653,\n",
              "         0.95918367, 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.7496056 , 0.90638896, 1.06317232, 1.21995568, 1.37673904,\n",
              "        1.5335224 , 1.69030576, 1.84708911, 2.00387247, 2.16065583,\n",
              "        2.31743919]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9xENlBUUxfTu",
        "outputId": "09704d23-94fc-481d-f742-43b56143b092"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r_squared = 0.9817900676482314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "-KukfpGTTKlj",
        "outputId": "8c3aae95-8d03-4c0d-937b-a7ea1f5a23b0"
      },
      "source": [
        "df"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.98179</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.699469</td>\n",
              "      <td>3 layers of Convolution: 32, 64, 128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    N1  N2  ...  loss test                                Details\n",
              "0  200  10  ...   1.699469  3 layers of Convolution: 32, 64, 128 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "ZZHa1j4HT9Dq",
        "outputId": "2067d357-c7fb-47e1-e5cc-81b29db6d732"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.7496056  0.90638896 1.06317232 1.21995568 1.37673904 1.5335224\n",
            " 1.69030576 1.84708911 2.00387247 2.16065583 2.31743919]\n",
            "[[ 7.36842105 10.52631579 23.15789474 33.68421053 13.68421053  8.42105263\n",
            "   1.05263158  0.          1.05263158  1.05263158]\n",
            " [ 6.12244898 14.28571429 16.32653061 26.53061224 18.36734694 14.28571429\n",
            "   4.08163265  0.          0.          0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8"
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4,1.6, 1.8,2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm"
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs"
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx"
      },
      "source": [
        "bins_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2"
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}