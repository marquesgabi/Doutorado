{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_Amostra7_r_squared+MC_set_13_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/PSD_histogram_CNN_B_Amostra7_r_squared%2BMC_set_13_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3078e0ee-0a65-44c3-9aaa-e0c694f73fac"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990dfbdc-806c-4bdc-934e-b26451a1cbd4"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f25035-ee59-4038-912e-186832ca3bf3"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "95b71ca8-f364-48c7-ac73-47c8e6a30c3d"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[2] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bbc664-66c8-4d8a-f001-ca4c5fa142aa"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN5MN5a_v4np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9724c3c0-c198-4dda-f293-ff6f8ed8bf21"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     155  157.151840  168.565384  ...  101.389145  104.182487  109.768074\n",
            "1     147   76.104301   75.555557  ...  145.161011  150.117920  145.664398\n",
            "2     196  143.551010  137.346939  ...  179.000000  191.775513  213.591827\n",
            "3     128  110.456055  113.413086  ...  122.321289  115.157227  102.740234\n",
            "4     191   68.874985   68.446869  ...  145.202148  150.997009  151.914703\n",
            "5     120   59.841110   61.547779  ...    0.000000    0.000000    0.000000\n",
            "6     146   46.518105   36.854755  ...    9.326328    9.242260    9.168699\n",
            "7     166    2.750472    7.824938  ...   48.941063   18.310638    0.544927\n",
            "8     138  145.937820  141.501770  ...   69.152908   79.417351   88.780922\n",
            "9     162   64.032616   67.066002  ...  104.375397  100.745766  100.325714\n",
            "10    119  123.114189  123.024223  ...  127.757790  129.577866  125.404846\n",
            "11    159  146.541519  128.317230  ...   99.776627   97.145714   79.591270\n",
            "12    159  141.884689  142.220901  ...   83.070999   89.450974  113.498672\n",
            "13    121  140.565674  141.399078  ...  111.193703  113.724396  119.413078\n",
            "14    181  152.629028  153.927383  ...  158.997742  156.687759  156.511795\n",
            "15    187  212.842087  205.896729  ...  137.036255  123.632156   88.147926\n",
            "16    136   69.777687   81.793259  ...  120.519035  122.688583  124.379761\n",
            "17    118   98.001137  100.429756  ...   62.717323   64.078995   69.663025\n",
            "18    143  134.527176  135.089920  ...   45.379383   54.648582   52.521641\n",
            "19    196  130.959183  132.938766  ...    7.632653    7.469388    7.755102\n",
            "20    198  137.157410  134.951538  ...  145.689102  147.660843  149.554321\n",
            "21    200  132.094803  127.893990  ...  140.495590  149.040802  164.345200\n",
            "22    109  103.660545  109.433296  ...  120.157814  120.884598  123.437584\n",
            "23    179  131.712845  131.992722  ...  136.009323  134.184875  130.854034\n",
            "24    164  108.781082  111.506241  ...    8.070791    8.317073    8.365854\n",
            "25    124   70.628502   61.913624  ...   11.568157   11.445368   11.445369\n",
            "26    132    0.000000    0.000000  ...  177.382935  178.684128  164.732788\n",
            "27    199   97.236908   94.793282  ...   83.832420  110.797928  109.776794\n",
            "28    101  129.388000  124.626114  ...  117.172142  119.495056  121.260757\n",
            "29    157   35.490162   53.577309  ...  134.263138  132.930664  135.871643\n",
            "30    141    0.000000    0.000000  ...   66.564560   71.430656   73.336502\n",
            "31    200    0.000000    0.000000  ...  171.537201  139.064392  138.263199\n",
            "32    186   91.730957   91.684937  ...   66.467339   69.953873   69.743904\n",
            "33    137   83.551918   84.411743  ...  132.037460  134.241196  135.987045\n",
            "34    118   89.209129   91.962357  ...  105.605576  105.736855  108.656136\n",
            "35    159  172.086151  181.096558  ...   82.786636   83.879189   84.217087\n",
            "36    152  188.612183  200.926575  ...  127.153046  119.177963  115.841415\n",
            "37    181  147.854065  155.181763  ...  140.902771  139.906601  143.852142\n",
            "38    199  127.876923  135.660461  ...    1.621701    0.993611    0.333729\n",
            "39    170   96.112251   95.135925  ...    5.822700    5.668236    4.877371\n",
            "40    101  101.718956  115.799736  ...  127.436440  125.616425  125.169205\n",
            "41    182   83.065094   81.704147  ...   71.804741   58.017757   46.763317\n",
            "42    195   81.883507   82.326942  ...    7.377646    6.753873    7.097015\n",
            "43    143   53.246368   50.765266  ...  105.111839  104.120834  102.242798\n",
            "44    154   47.661156   72.223145  ...    9.123968    8.570249    8.471075\n",
            "45    109    0.000000    0.000000  ...    0.256881    0.051847    0.000000\n",
            "46    189   69.058983  126.718781  ...  128.384094  122.389572  109.111107\n",
            "47    157  161.491867  162.464645  ...  155.612152  146.349228  134.684891\n",
            "48    144   80.308647   78.054794  ...  116.670532  121.530106  126.683640\n",
            "49    131  146.983322  146.758286  ...  138.430283  148.359573  150.818878\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpQ1Pz0fX5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c1cf88ec-d036-40bf-c95b-bb56e0d580bd"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "93765f8d-ec67-4434-f0dc-0cca533d5ac4"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "92fd3983-ba15-48b6-caf7-e262f96a0bdd"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.5561 - accuracy: 0.7347 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.2868 - accuracy: 0.8950 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.1629 - accuracy: 0.9359 - val_loss: 0.6935 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.1516 - accuracy: 0.9534 - val_loss: 0.6935 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0618 - accuracy: 0.9854 - val_loss: 0.6948 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0556 - accuracy: 0.9796 - val_loss: 0.6940 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0411 - accuracy: 0.9883 - val_loss: 0.6957 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0603 - accuracy: 0.9738 - val_loss: 0.6949 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0333 - accuracy: 0.9854 - val_loss: 0.6949 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0254 - accuracy: 0.9942 - val_loss: 0.6939 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0142 - accuracy: 0.9942 - val_loss: 0.6950 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.6933 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0046 - accuracy: 0.9971 - val_loss: 0.7117 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 0.6869 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.6830 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0036 - accuracy: 0.9971 - val_loss: 0.7255 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7393 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 0.7255 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.8004 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0056 - accuracy: 0.9971 - val_loss: 0.9457 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.7221 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0219 - accuracy: 0.9913 - val_loss: 1.2753 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 3.0670 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0068 - accuracy: 0.9971 - val_loss: 2.5298 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0085 - accuracy: 0.9942 - val_loss: 2.1727 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.3145 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4934 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6443 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 9.1211e-04 - accuracy: 1.0000 - val_loss: 2.4968 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 7.0613e-04 - accuracy: 1.0000 - val_loss: 2.4225 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6674 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.9980e-04 - accuracy: 1.0000 - val_loss: 2.8491 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.0520e-04 - accuracy: 1.0000 - val_loss: 2.7936 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 4.7346e-04 - accuracy: 1.0000 - val_loss: 2.7594 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.7711e-04 - accuracy: 1.0000 - val_loss: 2.7195 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.3442e-04 - accuracy: 1.0000 - val_loss: 2.6997 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 4.0137e-04 - accuracy: 1.0000 - val_loss: 2.6881 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.1198e-04 - accuracy: 1.0000 - val_loss: 2.7373 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 3.4084e-04 - accuracy: 1.0000 - val_loss: 2.8007 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 3.2788e-04 - accuracy: 1.0000 - val_loss: 2.8273 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 4.6070e-04 - accuracy: 1.0000 - val_loss: 2.9339 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 4.7260e-04 - accuracy: 1.0000 - val_loss: 3.2197 - val_accuracy: 0.5102\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 2.4293e-04 - accuracy: 1.0000 - val_loss: 3.6415 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.2456e-04 - accuracy: 1.0000 - val_loss: 3.5237 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.1921e-04 - accuracy: 1.0000 - val_loss: 3.4713 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 3.6118e-04 - accuracy: 1.0000 - val_loss: 3.3308 - val_accuracy: 0.5102\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 2.0621e-04 - accuracy: 1.0000 - val_loss: 2.8407 - val_accuracy: 0.5102\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.3848e-04 - accuracy: 1.0000 - val_loss: 2.6690 - val_accuracy: 0.5102\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.6635 - val_accuracy: 0.5102\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0022 - accuracy: 0.9971 - val_loss: 0.8368 - val_accuracy: 0.6190\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0625 - accuracy: 0.9825 - val_loss: 117.1845 - val_accuracy: 0.5102\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.1379 - accuracy: 0.9475 - val_loss: 184.5304 - val_accuracy: 0.5102\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0524 - accuracy: 0.9883 - val_loss: 148.3917 - val_accuracy: 0.5102\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0452 - accuracy: 0.9883 - val_loss: 105.1352 - val_accuracy: 0.5102\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 33.0823 - val_accuracy: 0.5102\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 52.2739 - val_accuracy: 0.5102\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 95.7957 - val_accuracy: 0.5102\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 79.5910 - val_accuracy: 0.5102\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 88.1277 - val_accuracy: 0.5102\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 87.0957 - val_accuracy: 0.5102\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 77.4077 - val_accuracy: 0.5102\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 62.2688 - val_accuracy: 0.5102\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 40.8651 - val_accuracy: 0.5102\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 54.0941 - val_accuracy: 0.5102\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 63.7414 - val_accuracy: 0.5102\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 45.5183 - val_accuracy: 0.5102\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 34.5834 - val_accuracy: 0.5102\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 41.1953 - val_accuracy: 0.5102\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.6602e-04 - accuracy: 1.0000 - val_loss: 50.6385 - val_accuracy: 0.5102\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 5.8148e-04 - accuracy: 1.0000 - val_loss: 49.2426 - val_accuracy: 0.5102\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 5.7901e-04 - accuracy: 1.0000 - val_loss: 44.9641 - val_accuracy: 0.5102\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 6.3664e-04 - accuracy: 1.0000 - val_loss: 41.2774 - val_accuracy: 0.5102\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 31.0692 - val_accuracy: 0.5102\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 29.8056 - val_accuracy: 0.5102\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 26.2920 - val_accuracy: 0.5102\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.4049e-04 - accuracy: 1.0000 - val_loss: 22.4245 - val_accuracy: 0.5102\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 2.8118e-04 - accuracy: 1.0000 - val_loss: 19.1516 - val_accuracy: 0.5102\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 1.9356e-04 - accuracy: 1.0000 - val_loss: 16.1125 - val_accuracy: 0.5102\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 1.2672e-04 - accuracy: 1.0000 - val_loss: 13.5262 - val_accuracy: 0.5102\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 5.4897e-04 - accuracy: 1.0000 - val_loss: 13.2962 - val_accuracy: 0.5102\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 2s 201ms/step - loss: 9.5906e-04 - accuracy: 1.0000 - val_loss: 13.6230 - val_accuracy: 0.5102\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 2.0082e-04 - accuracy: 1.0000 - val_loss: 9.3761 - val_accuracy: 0.5102\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 7.7236e-05 - accuracy: 1.0000 - val_loss: 7.7175 - val_accuracy: 0.5102\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.5296 - val_accuracy: 0.5102\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.7948e-04 - accuracy: 1.0000 - val_loss: 7.4385 - val_accuracy: 0.5102\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0043 - accuracy: 0.9971 - val_loss: 10.8086 - val_accuracy: 0.5102\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 15.4189 - val_accuracy: 0.5102\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 13.1625 - val_accuracy: 0.5102\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 11.6152 - val_accuracy: 0.5102\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 2.0690e-04 - accuracy: 1.0000 - val_loss: 18.3456 - val_accuracy: 0.5102\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 9.0757e-04 - accuracy: 1.0000 - val_loss: 16.6047 - val_accuracy: 0.5102\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0115 - accuracy: 0.9942 - val_loss: 8.3374 - val_accuracy: 0.5102\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.0260 - val_accuracy: 0.5102\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 4.9006e-04 - accuracy: 1.0000 - val_loss: 7.1260 - val_accuracy: 0.5102\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 11.0164 - val_accuracy: 0.5102\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 7.3952 - val_accuracy: 0.5102\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 13.0821 - val_accuracy: 0.5102\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 17.5726 - val_accuracy: 0.5102\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 1.8911e-04 - accuracy: 1.0000 - val_loss: 16.4749 - val_accuracy: 0.5102\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0035 - accuracy: 0.9971 - val_loss: 15.9359 - val_accuracy: 0.5102\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 4.2189e-04 - accuracy: 1.0000 - val_loss: 14.8483 - val_accuracy: 0.5102\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 4.5845e-04 - accuracy: 1.0000 - val_loss: 13.7191 - val_accuracy: 0.5102\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 2.4734e-04 - accuracy: 1.0000 - val_loss: 12.2325 - val_accuracy: 0.5102\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 4.2571e-04 - accuracy: 1.0000 - val_loss: 10.7843 - val_accuracy: 0.5102\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 2.1376e-04 - accuracy: 1.0000 - val_loss: 8.9576 - val_accuracy: 0.5102\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 5.7542e-05 - accuracy: 1.0000 - val_loss: 7.7090 - val_accuracy: 0.5102\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 1.6691e-04 - accuracy: 1.0000 - val_loss: 6.7059 - val_accuracy: 0.5102\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 3.0403e-04 - accuracy: 1.0000 - val_loss: 6.0410 - val_accuracy: 0.5102\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 7.7147e-05 - accuracy: 1.0000 - val_loss: 5.4889 - val_accuracy: 0.5102\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 8.7396e-05 - accuracy: 1.0000 - val_loss: 4.9400 - val_accuracy: 0.5102\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 5.5789e-05 - accuracy: 1.0000 - val_loss: 4.4533 - val_accuracy: 0.5102\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 2.1807e-04 - accuracy: 1.0000 - val_loss: 3.9051 - val_accuracy: 0.5102\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 2.2419e-05 - accuracy: 1.0000 - val_loss: 3.3964 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 2.8085e-05 - accuracy: 1.0000 - val_loss: 2.9829 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 7.4592e-05 - accuracy: 1.0000 - val_loss: 2.5023 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 5.4327e-05 - accuracy: 1.0000 - val_loss: 2.1073 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 5.9575e-05 - accuracy: 1.0000 - val_loss: 1.7365 - val_accuracy: 0.5306\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 1.0996e-04 - accuracy: 1.0000 - val_loss: 1.6307 - val_accuracy: 0.5578\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 1.9007e-05 - accuracy: 1.0000 - val_loss: 1.4412 - val_accuracy: 0.6122\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 2.0290e-05 - accuracy: 1.0000 - val_loss: 1.1856 - val_accuracy: 0.6599\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 1.1993e-04 - accuracy: 1.0000 - val_loss: 0.9067 - val_accuracy: 0.7007\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 1.1115e-04 - accuracy: 1.0000 - val_loss: 1.2794 - val_accuracy: 0.6667\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.3792e-05 - accuracy: 1.0000 - val_loss: 1.1840 - val_accuracy: 0.6803\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 8.3226e-05 - accuracy: 1.0000 - val_loss: 1.1697 - val_accuracy: 0.6803\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.6967e-04 - accuracy: 1.0000 - val_loss: 1.0181 - val_accuracy: 0.6803\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 4.1711e-05 - accuracy: 1.0000 - val_loss: 0.8417 - val_accuracy: 0.7143\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 2.6991e-05 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.7755\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 1.2104e-04 - accuracy: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.8639\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 2.1358e-05 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8980\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 2.0729e-05 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9048\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 1.8857e-05 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9184\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 1.0526e-05 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9252\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.3513e-04 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9524\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 5.0715e-05 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9592\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 2.4819e-05 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9592\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.3840e-05 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9592\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.1651e-04 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9320\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 2.8575e-04 - accuracy: 1.0000 - val_loss: 4.0787 - val_accuracy: 0.5102\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4.6416e-05 - accuracy: 1.0000 - val_loss: 5.4311 - val_accuracy: 0.5102\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 7.8647e-05 - accuracy: 1.0000 - val_loss: 5.3530 - val_accuracy: 0.5102\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 2.3729e-05 - accuracy: 1.0000 - val_loss: 4.7934 - val_accuracy: 0.5102\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 2.2519e-04 - accuracy: 1.0000 - val_loss: 4.0919 - val_accuracy: 0.5102\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 8.7654e-06 - accuracy: 1.0000 - val_loss: 4.5293 - val_accuracy: 0.5102\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 2.1387e-05 - accuracy: 1.0000 - val_loss: 4.2245 - val_accuracy: 0.5170\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 3.9638e-05 - accuracy: 1.0000 - val_loss: 3.7996 - val_accuracy: 0.5306\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.7527e-05 - accuracy: 1.0000 - val_loss: 3.1792 - val_accuracy: 0.5714\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.2571e-05 - accuracy: 1.0000 - val_loss: 2.6039 - val_accuracy: 0.5986\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4.7793e-05 - accuracy: 1.0000 - val_loss: 2.0700 - val_accuracy: 0.6395\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.3721e-05 - accuracy: 1.0000 - val_loss: 1.5158 - val_accuracy: 0.6871\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 5.0735e-05 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.8163\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 2.8007e-05 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9116\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 3.4076e-05 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9524\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.0520e-05 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9660\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.5390e-05 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9728\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.1012e-05 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9728\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 5.1635e-05 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9728\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 3.0531e-05 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9728\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 1.5516e-04 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9796\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 4.6665e-05 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9320\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 2.7357e-05 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9252\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 7.0989e-06 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9320\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 6.8639e-06 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9524\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 1.0322e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9456\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 1.1332e-05 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9592\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 1.7007e-05 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9728\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 8.6960e-06 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9728\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 2.2569e-05 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9728\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 5.1762e-05 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9728\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 3.1371e-05 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9796\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 6.1240e-05 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9796\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 2.5983e-05 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9796\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 6.5786e-06 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9796\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 5.6748e-05 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9796\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 9.3941e-06 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9796\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 4.9467e-05 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9796\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 8.0774e-05 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9796\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 3.0233e-05 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9796\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 3.1944e-05 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9796\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 2.1395e-05 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9796\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 1.2422e-05 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9796\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 1.3502e-05 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9796\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 1.1323e-04 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9796\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 2.9256e-06 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9796\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 6.0225e-05 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9796\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 9.9388e-06 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9796\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.5650e-05 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9796\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 2.4143e-05 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9796\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 6.2941e-05 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9728\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.0765e-05 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEE2dRY62O66"
      },
      "source": [
        "pred_test= model.predict(X_test)\n",
        "Rows, Cols = pred_test.shape\n",
        "Prediction =[]\n",
        "for i in range(Rows):\n",
        "  if(pred_test[0,0] > pred_test[0,1]):\n",
        "    Prediction.append(0)\n",
        "  else:\n",
        "    Prediction.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIPQG40CyIXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b84ab75-c353-4ad6-ca6b-fc59666d6310"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   0   1\n",
            "Actual         \n",
            "0        70   2\n",
            "1         2  73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ3YoP6I0axi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a169d06d-7f8d-497c-b105-236a112309e3"
      },
      "source": [
        "print(METRICS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        72\n",
            "           1       0.97      0.97      0.97        75\n",
            "\n",
            "    accuracy                           0.97       147\n",
            "   macro avg       0.97      0.97      0.97       147\n",
            "weighted avg       0.97      0.97      0.97       147\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH"
      },
      "source": [
        "#pred_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QISvYcJBgWbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8eadcf9-78a6-4722-8f6f-11f5595d9fb4"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[2] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  prediction_02 = model.predict(result)\n",
        "  Rows, Cols = prediction_02.shape\n",
        "  Prediction =[]\n",
        "  for i in range(Rows):\n",
        "    if(prediction_02[0,0] > prediction_02[0,1]):\n",
        "      Prediction.append(0)\n",
        "    else:\n",
        "      Prediction.append(1)\n",
        "  loc_grao =[];k=0\n",
        "  for i in Prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0   179.0  143.110397  143.200531  ...    7.936738    1.423832    0.163697\n",
            "1   151.0   70.868607   75.767075  ...  132.851166  133.280350  132.582474\n",
            "2   184.0   81.042526   55.286385  ...   60.179104   71.006134   77.475426\n",
            "3   153.0   76.858650   71.529678  ...   90.010727   89.943863   87.801620\n",
            "4   181.0  156.541138  161.980453  ...  109.038612  105.996063  100.600815\n",
            "5   115.0  128.372696  127.141846  ...  159.319168  145.101852  136.904785\n",
            "6   168.0  129.416672  136.527786  ...  199.500000  211.083328  223.694443\n",
            "7   140.0  119.239998   98.360001  ...  121.199997  124.680000  121.879997\n",
            "8   116.0    0.000000    0.000000  ...  135.076096  139.269913  144.694397\n",
            "9   174.0   74.715164   75.104378  ...  128.536667  130.178772  132.705368\n",
            "10  173.0  123.028664  123.569885  ...   76.781181   76.153961   75.761833\n",
            "11  151.0  139.099915  137.538757  ...  175.028519  167.589661  110.919693\n",
            "12  195.0  128.809357  129.016953  ...  167.490356  155.417023   91.735497\n",
            "13  131.0   83.206337   90.797623  ...  134.826462  132.913162  128.924942\n",
            "14  175.0  122.624001  120.195206  ...  146.939178  143.345596  132.388794\n",
            "15  130.0  118.205444  128.949127  ...   35.988640    3.714320    1.337988\n",
            "16  104.0  101.315102  101.571007  ...   11.470415   12.116865   11.786984\n",
            "17  139.0  172.653900  169.662125  ...   98.819000   97.350861   98.765175\n",
            "18  144.0  133.202942  128.383484  ...   76.585655   76.666672   76.942131\n",
            "19  111.0  118.529335  114.002274  ...  134.329514  132.154694  133.059174\n",
            "20  133.0    0.000000    0.000000  ...   10.814405   10.116344    9.689751\n",
            "21  126.0   76.913582   79.827164  ...   10.641975   11.395061   11.098766\n",
            "22  112.0  104.125000  106.250000  ...    0.000000    0.000000    0.000000\n",
            "23  160.0  204.847488  199.291870  ...   87.241875   87.505623   92.355614\n",
            "24  138.0  149.285019  133.663086  ...  107.323883   94.876076   86.544212\n",
            "25  118.0  169.979294  174.153961  ...   74.261993   53.199944   48.374317\n",
            "26  120.0  123.263329  120.896667  ...   57.492226   55.899998   59.155556\n",
            "27  168.0  137.694443  115.805557  ...   96.250000   97.500000   99.750000\n",
            "28  162.0   90.386223   92.628555  ...    7.134736    6.859473    7.060051\n",
            "29  165.0  136.386032  132.065231  ...    8.525326    8.023397    7.400147\n",
            "30  199.0  118.834518  122.961494  ...  157.893448  150.863281  151.699829\n",
            "31  107.0  118.136429  122.556023  ...   97.193466   95.622063   94.838058\n",
            "32  184.0   78.640358   92.338379  ...   66.115303   66.865776   61.439507\n",
            "33  176.0   87.735023  113.149780  ...  109.277893  112.029953   85.059914\n",
            "34  138.0    0.000000    0.000000  ...   49.053978   50.637260   55.860954\n",
            "35  196.0  128.612244  144.244888  ...  103.673470  119.836731  128.102036\n",
            "36  196.0  137.897949  140.000000  ...    6.489796    6.938776    6.836735\n",
            "37  140.0   77.239998   81.040001  ...   10.160000   10.480000   10.080000\n",
            "38  172.0  160.334244  167.636581  ...   98.063812  100.591675  106.489998\n",
            "39  114.0    0.000000    0.000000  ...  136.668823  138.170517   83.433678\n",
            "40  115.0   56.210278   58.780415  ...  152.328979  149.244370  148.386292\n",
            "41  192.0    5.118923  100.107201  ...  122.305550  122.703545  121.590706\n",
            "42  101.0  134.885406  146.687393  ...  135.895798  137.330475  139.058533\n",
            "43  167.0  124.149567  125.699783  ...  110.449539   94.630257   90.697731\n",
            "44  164.0  182.486603  168.982742  ...  118.102913  134.441406  150.158829\n",
            "45  142.0   81.918671  108.541168  ...   83.502686   84.736954   92.635788\n",
            "46  150.0   82.062935   59.571201  ...    6.338667    6.216711    5.330667\n",
            "47  115.0   61.774666   68.479843  ...    7.935879    7.829414    7.303591\n",
            "48  145.0  158.235336  123.190102  ...  143.081512  145.681381  148.912109\n",
            "49  121.0  100.923706  101.404144  ...   88.654053   88.617920   91.757736\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "7f4c982b-da76-4677-cc31-16e1791a032c"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_paper_fev_2021' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "535396e8-5928-4387-9205-8ba4af8208c0"
      },
      "source": [
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "\n",
        "%cd Doutorado\n",
        "\n",
        "PSD_imageJ = 'Amostra7.csv' \n",
        "PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "   Unnamed: 0   Area\n",
            "0           1  1.387\n",
            "1           2  1.626\n",
            "2           3  1.336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tEPjIBnv_xM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed655cb5-df59-4b7d-fdb6-b44336d41e5b"
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfagXc-Mv3oa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekBHQOT_6CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "1a461a3a-a529-4c2e-c7e2-296813282b0a"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>179.0</td>\n",
              "      <td>143.110397</td>\n",
              "      <td>143.200531</td>\n",
              "      <td>114.685814</td>\n",
              "      <td>57.343777</td>\n",
              "      <td>66.776878</td>\n",
              "      <td>67.710938</td>\n",
              "      <td>69.173615</td>\n",
              "      <td>69.259766</td>\n",
              "      <td>70.185577</td>\n",
              "      <td>70.920387</td>\n",
              "      <td>75.010399</td>\n",
              "      <td>88.933548</td>\n",
              "      <td>91.696861</td>\n",
              "      <td>84.758743</td>\n",
              "      <td>80.456131</td>\n",
              "      <td>81.059975</td>\n",
              "      <td>83.078590</td>\n",
              "      <td>82.079811</td>\n",
              "      <td>85.089447</td>\n",
              "      <td>101.249557</td>\n",
              "      <td>120.568954</td>\n",
              "      <td>129.134750</td>\n",
              "      <td>133.141022</td>\n",
              "      <td>136.569321</td>\n",
              "      <td>136.677887</td>\n",
              "      <td>135.779419</td>\n",
              "      <td>134.373734</td>\n",
              "      <td>139.571884</td>\n",
              "      <td>145.259521</td>\n",
              "      <td>141.579483</td>\n",
              "      <td>98.577194</td>\n",
              "      <td>59.042854</td>\n",
              "      <td>66.175148</td>\n",
              "      <td>67.203712</td>\n",
              "      <td>67.841270</td>\n",
              "      <td>67.762367</td>\n",
              "      <td>69.083488</td>\n",
              "      <td>69.102959</td>\n",
              "      <td>73.573166</td>\n",
              "      <td>...</td>\n",
              "      <td>0.435348</td>\n",
              "      <td>2.242221</td>\n",
              "      <td>4.206829</td>\n",
              "      <td>40.610500</td>\n",
              "      <td>100.846909</td>\n",
              "      <td>110.561462</td>\n",
              "      <td>113.712036</td>\n",
              "      <td>117.396996</td>\n",
              "      <td>123.267662</td>\n",
              "      <td>89.946358</td>\n",
              "      <td>6.963797</td>\n",
              "      <td>0.907930</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016136</td>\n",
              "      <td>0.705315</td>\n",
              "      <td>1.916576</td>\n",
              "      <td>3.336569</td>\n",
              "      <td>18.846666</td>\n",
              "      <td>78.470657</td>\n",
              "      <td>109.195061</td>\n",
              "      <td>106.043289</td>\n",
              "      <td>68.852318</td>\n",
              "      <td>7.936738</td>\n",
              "      <td>1.423832</td>\n",
              "      <td>0.163697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>151.0</td>\n",
              "      <td>70.868607</td>\n",
              "      <td>75.767075</td>\n",
              "      <td>104.228378</td>\n",
              "      <td>119.083931</td>\n",
              "      <td>120.578575</td>\n",
              "      <td>122.450241</td>\n",
              "      <td>121.882904</td>\n",
              "      <td>123.978775</td>\n",
              "      <td>125.395821</td>\n",
              "      <td>127.091530</td>\n",
              "      <td>129.500809</td>\n",
              "      <td>131.361084</td>\n",
              "      <td>133.136261</td>\n",
              "      <td>130.788559</td>\n",
              "      <td>127.228851</td>\n",
              "      <td>121.034035</td>\n",
              "      <td>113.307449</td>\n",
              "      <td>107.306831</td>\n",
              "      <td>100.201584</td>\n",
              "      <td>96.404991</td>\n",
              "      <td>92.801941</td>\n",
              "      <td>91.744446</td>\n",
              "      <td>91.142792</td>\n",
              "      <td>92.902718</td>\n",
              "      <td>94.725594</td>\n",
              "      <td>128.679977</td>\n",
              "      <td>145.628036</td>\n",
              "      <td>148.548965</td>\n",
              "      <td>73.603310</td>\n",
              "      <td>73.084114</td>\n",
              "      <td>80.631073</td>\n",
              "      <td>112.483444</td>\n",
              "      <td>122.542618</td>\n",
              "      <td>123.782555</td>\n",
              "      <td>124.864265</td>\n",
              "      <td>127.164162</td>\n",
              "      <td>129.114960</td>\n",
              "      <td>130.360703</td>\n",
              "      <td>131.460648</td>\n",
              "      <td>...</td>\n",
              "      <td>119.074509</td>\n",
              "      <td>122.571388</td>\n",
              "      <td>127.572395</td>\n",
              "      <td>129.475113</td>\n",
              "      <td>127.783035</td>\n",
              "      <td>126.142311</td>\n",
              "      <td>126.660713</td>\n",
              "      <td>129.961533</td>\n",
              "      <td>131.104828</td>\n",
              "      <td>131.096054</td>\n",
              "      <td>130.764755</td>\n",
              "      <td>129.326752</td>\n",
              "      <td>57.029518</td>\n",
              "      <td>62.113327</td>\n",
              "      <td>64.135788</td>\n",
              "      <td>66.811989</td>\n",
              "      <td>68.970009</td>\n",
              "      <td>78.230919</td>\n",
              "      <td>88.543045</td>\n",
              "      <td>92.503929</td>\n",
              "      <td>89.680450</td>\n",
              "      <td>91.772552</td>\n",
              "      <td>90.756943</td>\n",
              "      <td>89.264374</td>\n",
              "      <td>84.672653</td>\n",
              "      <td>80.503265</td>\n",
              "      <td>88.827072</td>\n",
              "      <td>97.863861</td>\n",
              "      <td>111.369141</td>\n",
              "      <td>120.319458</td>\n",
              "      <td>124.872429</td>\n",
              "      <td>128.561737</td>\n",
              "      <td>129.774261</td>\n",
              "      <td>126.690285</td>\n",
              "      <td>127.132637</td>\n",
              "      <td>128.506866</td>\n",
              "      <td>130.099869</td>\n",
              "      <td>132.851166</td>\n",
              "      <td>133.280350</td>\n",
              "      <td>132.582474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184.0</td>\n",
              "      <td>81.042526</td>\n",
              "      <td>55.286385</td>\n",
              "      <td>36.031193</td>\n",
              "      <td>31.470226</td>\n",
              "      <td>69.982040</td>\n",
              "      <td>86.557175</td>\n",
              "      <td>90.822769</td>\n",
              "      <td>93.288750</td>\n",
              "      <td>95.243851</td>\n",
              "      <td>98.049622</td>\n",
              "      <td>90.976364</td>\n",
              "      <td>85.028351</td>\n",
              "      <td>82.667755</td>\n",
              "      <td>82.925789</td>\n",
              "      <td>83.387985</td>\n",
              "      <td>86.479668</td>\n",
              "      <td>89.042061</td>\n",
              "      <td>86.710304</td>\n",
              "      <td>85.172958</td>\n",
              "      <td>85.227310</td>\n",
              "      <td>87.127586</td>\n",
              "      <td>89.345451</td>\n",
              "      <td>91.636101</td>\n",
              "      <td>96.590263</td>\n",
              "      <td>102.348282</td>\n",
              "      <td>108.422012</td>\n",
              "      <td>110.585526</td>\n",
              "      <td>97.175323</td>\n",
              "      <td>88.544884</td>\n",
              "      <td>76.032608</td>\n",
              "      <td>50.875706</td>\n",
              "      <td>39.081757</td>\n",
              "      <td>78.537796</td>\n",
              "      <td>90.132790</td>\n",
              "      <td>91.932884</td>\n",
              "      <td>93.307175</td>\n",
              "      <td>97.403114</td>\n",
              "      <td>102.267960</td>\n",
              "      <td>95.396027</td>\n",
              "      <td>...</td>\n",
              "      <td>106.382317</td>\n",
              "      <td>112.907364</td>\n",
              "      <td>109.444695</td>\n",
              "      <td>81.005196</td>\n",
              "      <td>61.894611</td>\n",
              "      <td>64.993843</td>\n",
              "      <td>67.077499</td>\n",
              "      <td>64.901222</td>\n",
              "      <td>58.323719</td>\n",
              "      <td>62.222111</td>\n",
              "      <td>69.273628</td>\n",
              "      <td>73.543938</td>\n",
              "      <td>163.169647</td>\n",
              "      <td>144.025040</td>\n",
              "      <td>113.846397</td>\n",
              "      <td>100.420120</td>\n",
              "      <td>105.364357</td>\n",
              "      <td>101.948952</td>\n",
              "      <td>94.009918</td>\n",
              "      <td>91.879944</td>\n",
              "      <td>89.963135</td>\n",
              "      <td>89.483452</td>\n",
              "      <td>89.220695</td>\n",
              "      <td>89.723061</td>\n",
              "      <td>94.002365</td>\n",
              "      <td>97.467850</td>\n",
              "      <td>99.834122</td>\n",
              "      <td>102.763695</td>\n",
              "      <td>103.968330</td>\n",
              "      <td>109.808121</td>\n",
              "      <td>96.525513</td>\n",
              "      <td>64.242432</td>\n",
              "      <td>64.307175</td>\n",
              "      <td>66.638466</td>\n",
              "      <td>66.517487</td>\n",
              "      <td>63.780712</td>\n",
              "      <td>58.834118</td>\n",
              "      <td>60.179104</td>\n",
              "      <td>71.006134</td>\n",
              "      <td>77.475426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>153.0</td>\n",
              "      <td>76.858650</td>\n",
              "      <td>71.529678</td>\n",
              "      <td>69.017815</td>\n",
              "      <td>71.112991</td>\n",
              "      <td>72.039696</td>\n",
              "      <td>71.999786</td>\n",
              "      <td>66.734077</td>\n",
              "      <td>64.741852</td>\n",
              "      <td>64.789780</td>\n",
              "      <td>66.387207</td>\n",
              "      <td>67.682312</td>\n",
              "      <td>68.239189</td>\n",
              "      <td>68.351273</td>\n",
              "      <td>73.514244</td>\n",
              "      <td>77.269684</td>\n",
              "      <td>72.727936</td>\n",
              "      <td>54.847286</td>\n",
              "      <td>54.798840</td>\n",
              "      <td>94.810593</td>\n",
              "      <td>113.772705</td>\n",
              "      <td>116.269264</td>\n",
              "      <td>115.121330</td>\n",
              "      <td>108.668304</td>\n",
              "      <td>109.357002</td>\n",
              "      <td>107.677818</td>\n",
              "      <td>106.447357</td>\n",
              "      <td>105.580383</td>\n",
              "      <td>69.512619</td>\n",
              "      <td>76.583710</td>\n",
              "      <td>71.003380</td>\n",
              "      <td>68.261002</td>\n",
              "      <td>71.407928</td>\n",
              "      <td>72.917648</td>\n",
              "      <td>71.827896</td>\n",
              "      <td>67.962151</td>\n",
              "      <td>65.182541</td>\n",
              "      <td>63.178520</td>\n",
              "      <td>64.888374</td>\n",
              "      <td>73.281944</td>\n",
              "      <td>...</td>\n",
              "      <td>84.832504</td>\n",
              "      <td>81.045830</td>\n",
              "      <td>77.373749</td>\n",
              "      <td>75.728310</td>\n",
              "      <td>79.932640</td>\n",
              "      <td>84.967880</td>\n",
              "      <td>88.870651</td>\n",
              "      <td>91.023071</td>\n",
              "      <td>91.838234</td>\n",
              "      <td>91.845154</td>\n",
              "      <td>93.556412</td>\n",
              "      <td>95.296944</td>\n",
              "      <td>110.772102</td>\n",
              "      <td>116.879250</td>\n",
              "      <td>118.398567</td>\n",
              "      <td>116.703407</td>\n",
              "      <td>115.775139</td>\n",
              "      <td>114.309372</td>\n",
              "      <td>110.972366</td>\n",
              "      <td>109.571884</td>\n",
              "      <td>111.079727</td>\n",
              "      <td>111.134659</td>\n",
              "      <td>109.091087</td>\n",
              "      <td>106.923630</td>\n",
              "      <td>103.380112</td>\n",
              "      <td>102.128288</td>\n",
              "      <td>97.767097</td>\n",
              "      <td>90.450684</td>\n",
              "      <td>83.307022</td>\n",
              "      <td>81.060631</td>\n",
              "      <td>83.933197</td>\n",
              "      <td>85.800941</td>\n",
              "      <td>87.493828</td>\n",
              "      <td>89.104919</td>\n",
              "      <td>90.996841</td>\n",
              "      <td>91.187790</td>\n",
              "      <td>90.431854</td>\n",
              "      <td>90.010727</td>\n",
              "      <td>89.943863</td>\n",
              "      <td>87.801620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>181.0</td>\n",
              "      <td>156.541138</td>\n",
              "      <td>161.980453</td>\n",
              "      <td>165.838562</td>\n",
              "      <td>173.262619</td>\n",
              "      <td>170.653259</td>\n",
              "      <td>143.633118</td>\n",
              "      <td>106.784416</td>\n",
              "      <td>93.053078</td>\n",
              "      <td>158.754623</td>\n",
              "      <td>169.179993</td>\n",
              "      <td>159.111298</td>\n",
              "      <td>150.516571</td>\n",
              "      <td>146.173752</td>\n",
              "      <td>141.333923</td>\n",
              "      <td>144.524536</td>\n",
              "      <td>169.633087</td>\n",
              "      <td>199.351959</td>\n",
              "      <td>218.166611</td>\n",
              "      <td>234.475204</td>\n",
              "      <td>224.459579</td>\n",
              "      <td>99.456497</td>\n",
              "      <td>108.186996</td>\n",
              "      <td>112.918411</td>\n",
              "      <td>114.555962</td>\n",
              "      <td>120.166641</td>\n",
              "      <td>136.742737</td>\n",
              "      <td>149.167221</td>\n",
              "      <td>151.327530</td>\n",
              "      <td>151.182327</td>\n",
              "      <td>154.480469</td>\n",
              "      <td>146.619370</td>\n",
              "      <td>127.148659</td>\n",
              "      <td>99.970604</td>\n",
              "      <td>87.637222</td>\n",
              "      <td>88.608353</td>\n",
              "      <td>89.408936</td>\n",
              "      <td>142.302689</td>\n",
              "      <td>170.420319</td>\n",
              "      <td>161.787292</td>\n",
              "      <td>...</td>\n",
              "      <td>196.440338</td>\n",
              "      <td>221.149796</td>\n",
              "      <td>224.531784</td>\n",
              "      <td>223.905273</td>\n",
              "      <td>209.317688</td>\n",
              "      <td>157.735565</td>\n",
              "      <td>139.222916</td>\n",
              "      <td>138.167023</td>\n",
              "      <td>125.952751</td>\n",
              "      <td>113.071823</td>\n",
              "      <td>101.252617</td>\n",
              "      <td>96.742683</td>\n",
              "      <td>156.271866</td>\n",
              "      <td>150.834839</td>\n",
              "      <td>76.289795</td>\n",
              "      <td>104.485222</td>\n",
              "      <td>130.997040</td>\n",
              "      <td>134.318497</td>\n",
              "      <td>135.918396</td>\n",
              "      <td>143.433350</td>\n",
              "      <td>157.617661</td>\n",
              "      <td>168.060822</td>\n",
              "      <td>165.061676</td>\n",
              "      <td>168.668335</td>\n",
              "      <td>175.004929</td>\n",
              "      <td>179.028229</td>\n",
              "      <td>179.876526</td>\n",
              "      <td>179.254395</td>\n",
              "      <td>202.867264</td>\n",
              "      <td>221.347443</td>\n",
              "      <td>221.279846</td>\n",
              "      <td>220.214462</td>\n",
              "      <td>208.625122</td>\n",
              "      <td>162.372620</td>\n",
              "      <td>133.576630</td>\n",
              "      <td>125.227814</td>\n",
              "      <td>112.774162</td>\n",
              "      <td>109.038612</td>\n",
              "      <td>105.996063</td>\n",
              "      <td>100.600815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "0  179.0  143.110397  143.200531  ...    7.936738    1.423832    0.163697\n",
              "1  151.0   70.868607   75.767075  ...  132.851166  133.280350  132.582474\n",
              "2  184.0   81.042526   55.286385  ...   60.179104   71.006134   77.475426\n",
              "3  153.0   76.858650   71.529678  ...   90.010727   89.943863   87.801620\n",
              "4  181.0  156.541138  161.980453  ...  109.038612  105.996063  100.600815\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q09DRGPtM75"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "\n",
        "# Area = np.array(PSD_new.iloc[:,1])\n",
        "Area = PSD_new['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aUb2_-jsY1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4236bd-3701-4117-f235-46b39d3dce03"
      },
      "source": [
        "PSD_new.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.387, 1.626, 1.336, 0.64 , 2.211, 1.12 , 0.974, 1.237, 1.29 ,\n",
              "       3.755, 2.778, 1.256, 1.386, 1.302, 1.071, 1.497, 1.518, 1.244,\n",
              "       1.532, 1.325, 1.519, 1.895, 1.22 , 1.241, 1.301, 1.429, 0.667,\n",
              "       2.157, 1.052, 2.082, 1.517, 1.281, 0.784, 1.067, 2.764, 1.215,\n",
              "       0.943, 2.182, 1.486, 1.569, 2.667, 0.709, 1.006, 1.6  , 1.408,\n",
              "       3.16 , 2.465, 2.284, 1.273, 1.256, 3.021, 1.701, 1.955, 5.248,\n",
              "       1.627, 1.367, 1.592, 2.718, 1.658, 1.128, 2.192, 1.508, 2.547,\n",
              "       1.945, 1.606, 3.482, 1.756, 1.457, 1.864, 1.821, 1.314, 1.715,\n",
              "       1.015, 1.345, 1.265, 1.844, 1.396, 1.785, 1.694, 1.413, 1.368,\n",
              "       2.21 , 1.034, 1.367, 1.943, 1.008, 1.279, 1.579, 1.444, 1.879,\n",
              "       1.466, 2.154, 1.794, 3.149, 1.883, 1.692, 1.163, 1.297, 2.949,\n",
              "       1.09 , 1.444, 1.524])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J705kDqsE8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607cca70-534e-4a39-df5f-d1e2aa35c6eb"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK1GBUHWiIr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8c256fd7-4251-410c-8ec6-dc1838663366"
      },
      "source": [
        "Freq = [10.52631579, 24.21052632, 36.84210526, 14.73684211,  7.36842105, 0.]\n",
        "Freq2 = [12.90153, 28.11527, 27.66761, 20.21617, 10.34227, 0.]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434, 0.]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "cc30a977-33c3-41f3-8acf-161bf6bfcdfd"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2cc526c810>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "0c9f7e1b-93c2-41df-d88e-c3e3b6286816"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.02941176, 0.12745098, 0.43137255, 0.71568627, 0.8627451 ,\n",
              "         0.92156863, 0.97058824, 0.99019608, 0.99019608, 1.        ],\n",
              "        [0.22      , 0.38      , 0.58      , 0.84      , 0.98      ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.8181562 , 0.99483548, 1.17151475, 1.34819403, 1.52487331,\n",
              "        1.70155258, 1.87823186, 2.05491113, 2.23159041, 2.40826969,\n",
              "        2.58494896]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAP6klEQVR4nO3df6xkZX3H8ffHBZQq5Uf32pr94WK6pq7FRrJB65qWRpsuENk2Nc2S2lhL3aQpxkZjsv0RJJg0a01KMcHqxhKrKVBqq9l016IJGBMtlIui8qPouuKytyasAtdSoXTtt3/MrB0u9945y87cmfvwfiWTnXPOs/N877nPfvbMc+acSVUhSVr9njfpAiRJo2GgS1IjDHRJaoSBLkmNMNAlqRGnTKrjtWvX1qZNmybVvSStSnfdddf3qmpmsW0TC/RNmzYxOzs7qe4laVVK8p2ltjnlIkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhoxNNCTXJ/k4ST3LLE9ST6Y5GCSryU5f/RlSpKG6XKE/jFg+zLbLwI29x+7gL8++bIkSSdqaKBX1ReAR5ZpsgP4ePXcDpyV5CWjKlCS1M0orhRdBzw0sHykv+67Cxsm2UXvKJ6NGzeOoGtpDK45D+YPT7oKjdm2J69ljkWvoB+7dc97lC/++VtG/roreul/Ve0F9gJs3brVr0rSdJo/DFfNT7oKjdnc7v08uOeSifS9aff+sbzuKAJ9DtgwsLy+v07SKrFtz63MPfbEpMtYUevOOn3SJYzcKAJ9H3BFkpuA1wDzVfWM6RZJ02vusScmdrSq0Rka6EluBC4E1iY5ArwXOBWgqj4MHAAuBg4CPwTeNq5i9RwzqbnsMz2/o9VpaKBX1WVDthfwhyOrSDrOuWzphEzsfuiSnmlSc9ktzic/Fxno0hRxLlsnw3u5SFIjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhrhhUXSApO886BXbOpkGOjSAl6tqdXKKRdJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjfDSf02tbU9ey9zu/Sver/dT0WploGtqzTHjPVWkE+CUiyQ1wkCXpEYY6JLUCOfQNdw158H84Ql0fMME+pRWLwNdw80fhqvmV77fCXzCRVrNnHKRpEYY6JLUCANdkhrRKdCTbE/yQJKDSXYvsn1jktuSfCXJ15JcPPpSJUnLGRroSdYA1wEXAVuAy5JsWdDsz4Cbq+rVwE7gQ6MuVJK0vC5H6BcAB6vqUFU9BdwE7FjQpoCf7D8/E/iP0ZUoSeqiS6CvAx4aWD7SXzfoKuAtSY4AB4B3LPZCSXYlmU0ye/To0WdRriRpKaM6KXoZ8LGqWg9cDHwiyTNeu6r2VtXWqto6MzMzoq4lSdAt0OeADQPL6/vrBl0O3AxQVf8KvABYO4oCJUnddAn0O4HNSc5Nchq9k577FrQ5DLwBIMkr6AW6cyqStIKGBnpVHQOuAG4B7qf3aZZ7k1yd5NJ+s3cDb0/yVeBG4HerqsZVtCTpmTrdy6WqDtA72Tm47sqB5/cB20ZbmiTpRHilqCQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIa0enmXHpu2/bktczt3r/i/a476/QV71NazQx0DTXHDA/uuWTSZUgawikXSWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmN6BToSbYneSDJwSS7l2jzW0nuS3JvkhtGW6YkaZih3ymaZA1wHfCrwBHgziT7quq+gTabgT8GtlXVo0lePK6CJUmL63KEfgFwsKoOVdVTwE3AjgVt3g5cV1WPAlTVw6MtU5I0TJdAXwc8NLB8pL9u0MuBlyf5YpLbk2wfVYGSpG6GTrmcwOtsBi4E1gNfSHJeVT022CjJLmAXwMaNG0fUtSQJuh2hzwEbBpbX99cNOgLsq6r/qapvA9+gF/BPU1V7q2prVW2dmZl5tjVLkhbRJdDvBDYnOTfJacBOYN+CNp+md3ROkrX0pmAOjbBOSdIQQwO9qo4BVwC3APcDN1fVvUmuTnJpv9ktwPeT3AfcBrynqr4/rqIlSc/UaQ69qg4ABxasu3LgeQHv6j80DtecB/OHJ9S5lxVIq8GoTopq3OYPw1Xzk+l79/7J9CvphHjpvyQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhpxyqQLUDfbnryWud37J9L3urNOn0i/kk6Mgb5KzDHDg3sumXQZkqaYUy6S1AgDXZIa0SnQk2xP8kCSg0l2L9PuN5NUkq2jK1GS1MXQQE+yBrgOuAjYAlyWZMsi7c4A3gncMeoiJUnDdTlCvwA4WFWHquop4CZgxyLt3ge8H3hyhPVJkjrqEujrgIcGlo/01/1YkvOBDVW17OfqkuxKMptk9ujRoydcrCRpaSd9UjTJ84C/BN49rG1V7a2qrVW1dWZm5mS7liQN6BLoc8CGgeX1/XXHnQH8PPD5JA8CrwX2eWJUklZWl0C/E9ic5NwkpwE7gX3HN1bVfFWtrapNVbUJuB24tKpmx1KxJGlRQ68UrapjSa4AbgHWANdX1b1JrgZmq2rf8q/QmGvOg/nDE+j4hgn0KWk16XTpf1UdAA4sWHflEm0vPPmyptj8YbhqfuX7ndB9XCStHl4pKkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSI06ZdAHPyjXnwfzhyfR95sbJ9CtJQ3QK9CTbgWuBNcBHq2rPgu3vAn4fOAYcBX6vqr4z4lr/3/xhuGp+bC8vSavR0CmXJGuA64CLgC3AZUm2LGj2FWBrVb0K+CTwF6MuVJK0vC5z6BcAB6vqUFU9BdwE7BhsUFW3VdUP+4u3A+tHW6YkaZgugb4OeGhg+Uh/3VIuBz6z2IYku5LMJpk9evRo9yolSUON9FMuSd4CbAU+sNj2qtpbVVurauvMzMwou5ak57wuJ0XngA0Dy+v7654myRuBPwV+uar+ezTlSZK66nKEfiewOcm5SU4DdgL7BhskeTXwEeDSqnp49GVKkoYZGuhVdQy4ArgFuB+4uaruTXJ1kkv7zT4AvAj4hyR3J9m3xMtJksak0+fQq+oAcGDBuisHnr9xxHVJkk6Ql/5LUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjVudX0E3Qtj23MvfYEyve77qzTl/xPiWtLgb6CZp77Ake3HPJpMuQpGdwykWSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqxKr8TtFtT17L3O79E+nbL2uWNK1WZaDPMeMXNUvSAk65SFIjOgV6ku1JHkhyMMnuRbY/P8nf97ffkWTTqAuVJC1vaKAnWQNcB1wEbAEuS7JlQbPLgUer6meBa4D3j7pQSdLyuhyhXwAcrKpDVfUUcBOwY0GbHcDf9p9/EnhDkoyuTEnSMF1Oiq4DHhpYPgK8Zqk2VXUsyTzwU8D3Bhsl2QXs6i8+nuSBgc1rF7ZfTib7HuCEap0wax0Pax2P50ytJ5FhL11qw4p+yqWq9gJ7F9uWZLaqtq5kPc+WtY6HtY6HtY7HNNbaZcplDtgwsLy+v27RNklOAc4Evj+KAiVJ3XQJ9DuBzUnOTXIasBPYt6DNPuCt/edvBm6tqhpdmZKkYYZOufTnxK8AbgHWANdX1b1JrgZmq2of8DfAJ5IcBB6hF/onatGpmCllreNhreNhreMxdbXGA2lJaoNXikpSIwx0SWrE2AO9w20Drklyd//xjSSPDWz70cC2hSdix1Hr9UkeTnLPEtuT5IP9n+VrSc4f2PbWJN/sP9662N9f4Vp/u1/j15N8KckvDGx7sL/+7iSzU1DrhUnmB37XVw5sW3b8TKDW9wzUeU9/jJ7T37bS+3VDktuS3Jfk3iTvXKTNVIzZjrVOxZjtWOvUjNmnqaqxPeidRP0W8DLgNOCrwJZl2r+D3knX48uPj7O+Rfr/JeB84J4ltl8MfAYI8Frgjv76c4BD/T/P7j8/e8K1vu54DfRu23DHwLYHgbVTtF8vBP75ZMfPStS6oO2b6H2ia1L79SXA+f3nZwDfWLh/pmXMdqx1KsZsx1qnZswOPsZ9hN7ltgGDLgNuHHNNS6qqL9D7lM5SdgAfr57bgbOSvAT4NeBzVfVIVT0KfA7YPslaq+pL/VoAbqd3/cBEdNivSznR8XPSTrDWSY/X71bVl/vP/xO4n95V24OmYsx2qXVaxmzH/bqUFR+zg8Yd6IvdNmDRHZPkpcC5wK0Dq1+QZDbJ7Ul+fXxldrbUz9P555yQy+kdpR1XwGeT3JXe7RimwS8m+WqSzyR5ZX/d1O7XJD9BLwD/cWD1xPZrenc4fTVwx4JNUzdml6l10FSM2SG1Tt2YnaYvuNgJfLKqfjSw7qVVNZfkZcCtSb5eVd+aUH2rUpJfofeP4/UDq1/f368vBj6X5N/7R6aT8mV6v+vHk1wMfBrYPMF6ungT8MWqGjyan8h+TfIiev+x/FFV/WDc/Z2MLrVOy5gdUutUjtlxH6F3uW3AcTtZ8Pa1qub6fx4CPk/vf8pJWurnOZGfc8UkeRXwUWBHVf34VgwD+/Vh4FP03iZOTFX9oKoe7z8/AJyaZC1Tul/7lhuvK7Zfk5xKL3T+rqr+aZEmUzNmO9Q6NWN2WK1TO2bHOUFP7x3AIXpTKcdPELxykXY/R++kRwbWnQ08v/98LfBNVuDkArCJpU/eXcLTTzD9W3/9OcC3+zWf3X9+zoRr3QgcBF63YP0LgTMGnn8J2D7hWn/m+O+e3j/Uw/193Gn8rGSt/e1n0ptnf+Ek92t/H30c+Ktl2kzFmO1Y61SM2Y61TtWYPf4Y65RLdbttAPSOdm6q/t7pewXwkST/S++dxJ6qum+c9Sa5kd7Z67VJjgDvBU7t/ywfBg7Q+9TAQeCHwNv62x5J8j56970BuLqe/lZ8ErVeSe8Wxh9K79b0x6p3Z7ifBj7VX3cKcENV/cuEa30z8AdJjgFPADv7Y2HR8TPhWgF+A/hsVf3XwF9d8f0KbAN+B/h6krv76/6EXjBO25jtUuu0jNkutU7NmB3kpf+S1AivFJWkRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqRH/BzNctUICslsAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xENlBUUxfTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4eb849ff-c7ff-4c74-a525-0d4929f09b4d"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r_squared = 0.8738192940600722\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KukfpGTTKlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "8b687257-60bf-43ac-b08d-7644e67c7959"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.873819</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.972789</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.227424</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2  ...  loss test                                 Details\n",
              "0  20  20  ...   0.227424  3 layers of Convolution: 64, 128, 256 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHa1j4HT9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "1ad0e310-6b1a-47df-f833-e70a9b175dbc"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.8181562  0.99483548 1.17151475 1.34819403 1.52487331 1.70155258\n",
            " 1.87823186 2.05491113 2.23159041 2.40826969 2.58494896]\n",
            "[[ 2.94117647  9.80392157 30.39215686 28.43137255 14.70588235  5.88235294\n",
            "   4.90196078  1.96078431  0.          0.98039216]\n",
            " [22.         16.         20.         26.         14.          2.\n",
            "   0.          0.          0.          0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a1ff04-5590-44cf-fa31-d2bea23e6646"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "4d84918d-8c4d-4b59-ce04-472ba2137d6f"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2cce794dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f3e18b-71a7-441e-8260-199f423cd0d4"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.3289030245084366,\n",
              "  1.4388493665910183,\n",
              "  1.3042423209535017,\n",
              "  0.9027033336764101,\n",
              "  1.6778356991700483,\n",
              "  1.1941642642883694,\n",
              "  1.113613629842976,\n",
              "  1.254988970803089,\n",
              "  1.2815923738491737,\n",
              "  2.186553107171316,\n",
              "  1.8807071689325485,\n",
              "  1.2645903954195463,\n",
              "  1.3284238815238665,\n",
              "  1.2875394701698204,\n",
              "  1.1677497815933682,\n",
              "  1.3805939296073044,\n",
              "  1.3902437300372827,\n",
              "  1.2585348599266302,\n",
              "  1.3966398900698307,\n",
              "  1.2988619621707653,\n",
              "  1.3907015741893414,\n",
              "  1.5533154661153457,\n",
              "  1.2463355264843006,\n",
              "  1.2570164179581493,\n",
              "  1.2870449283923413,\n",
              "  1.3488733481786004,\n",
              "  0.9215480325725586,\n",
              "  1.6572198701420842,\n",
              "  1.157345238492556,\n",
              "  1.6281537802488464,\n",
              "  1.3897857350553149,\n",
              "  1.2771138777750963,\n",
              "  0.9991095050455518,\n",
              "  1.165567069812981,\n",
              "  1.875962180228586,\n",
              "  1.2437789380968078,\n",
              "  1.0957485526731296,\n",
              "  1.6667959343039342,\n",
              "  1.3755122549350303,\n",
              "  1.413404699896484,\n",
              "  1.8427506249649406,\n",
              "  0.9501193805081709,\n",
              "  1.1317592420667806,\n",
              "  1.4272992929222168,\n",
              "  1.3389254195014408,\n",
              "  2.0058506827187097,\n",
              "  1.7715912276177528,\n",
              "  1.7053090981329784,\n",
              "  1.273119766733618,\n",
              "  1.2645903954195463,\n",
              "  1.9612385537320356,\n",
              "  1.4716590860639265,\n",
              "  1.5777145844408116,\n",
              "  2.584948960960377,\n",
              "  1.4392917491892008,\n",
              "  1.319287102056625,\n",
              "  1.4237265731938766,\n",
              "  1.8602862904913782,\n",
              "  1.4529388029682806,\n",
              "  1.1984215478959244,\n",
              "  1.6706109906436855,\n",
              "  1.3856569681781365,\n",
              "  1.8008167925806498,\n",
              "  1.5736743355948497,\n",
              "  1.4299729748651446,\n",
              "  2.1055688292639205,\n",
              "  1.4952620641730152,\n",
              "  1.3620242349823046,\n",
              "  1.540557857201846,\n",
              "  1.5226848692236787,\n",
              "  1.293459223084363,\n",
              "  1.4777028859756633,\n",
              "  1.1368105109938904,\n",
              "  1.3086279790944384,\n",
              "  1.269113085619237,\n",
              "  1.5322707725763225,\n",
              "  1.3332075624036517,\n",
              "  1.507558485549488,\n",
              "  1.4686278591874,\n",
              "  1.341300666036808,\n",
              "  1.319769562157615,\n",
              "  1.6774562271083886,\n",
              "  1.1474012764748687,\n",
              "  1.319287102056625,\n",
              "  1.5728650404343092,\n",
              "  1.1328836926591555,\n",
              "  1.2761165219980004,\n",
              "  1.417901703622935,\n",
              "  1.355934328276106,\n",
              "  1.546744033302657,\n",
              "  1.3662244224803437,\n",
              "  1.6560670213972442,\n",
              "  1.5113542745679724,\n",
              "  2.0023564433863985,\n",
              "  1.5483895061438226,\n",
              "  1.467760644550703,\n",
              "  1.2168720518308382,\n",
              "  1.2850648580991957,\n",
              "  1.937726352564777,\n",
              "  1.1780624362746346,\n",
              "  1.355934328276106,\n",
              "  1.3929885377045959],\n",
              " [1.4392399979174149,\n",
              "  1.171297817765324,\n",
              "  1.5554712997671425,\n",
              "  1.391864771935398,\n",
              "  1.5569745736418361,\n",
              "  0.9879355023819225,\n",
              "  1.3709874582793338,\n",
              "  1.2765949448325764,\n",
              "  0.9549019019335143,\n",
              "  1.4178738241562283,\n",
              "  1.4363453782446227,\n",
              "  1.325976073101348,\n",
              "  1.7884945946412167,\n",
              "  0.9979081621430174,\n",
              "  1.6670251584839877,\n",
              "  1.1895665053516307,\n",
              "  0.9155583387926838,\n",
              "  1.2190583547103704,\n",
              "  1.3222622141473528,\n",
              "  0.8181562032946302,\n",
              "  1.307084384843073,\n",
              "  0.9852501650816491,\n",
              "  0.9312008127313961,\n",
              "  1.3763311148215127,\n",
              "  1.4190253317695067,\n",
              "  0.8805949103901842,\n",
              "  0.9807074020468233,\n",
              "  1.4105052733004246,\n",
              "  1.3431159742636476,\n",
              "  1.2334911552613208,\n",
              "  1.6428512620843212,\n",
              "  0.9155642939452294,\n",
              "  1.6279535034838932,\n",
              "  1.1597816857989598,\n",
              "  1.072188341202813,\n",
              "  1.5640156514899444,\n",
              "  1.608811892331342,\n",
              "  1.1239660147628263,\n",
              "  1.4460819542996504,\n",
              "  1.0516148663735472,\n",
              "  0.950741706653776,\n",
              "  1.4625829552019796,\n",
              "  0.956936199519779,\n",
              "  1.4903534329907082,\n",
              "  1.403294805673062,\n",
              "  1.2198855768542,\n",
              "  1.3500475701359986,\n",
              "  1.1392636892846044,\n",
              "  1.3097432257493486,\n",
              "  1.0017696020371722]]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "03890442-2973-4b8b-af6c-0d572ee4952f"
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4,1.6, 1.8,2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2cc526c1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fee6ca28-ca2b-4a50-faa2-0a8451eb75e1"
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e831c8d7-4d29-4cee-8ff9-da7980132b2a"
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.92156863, 11.76470588, 40.19607843, 23.52941176,  8.82352941,\n",
              "        6.8627451 ])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb54b26-2770-44ad-bd8b-6b6b851a1948"
      },
      "source": [
        "bins_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "126a09b1-f6cc-48f6-a2e4-4b93a588d97a"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "      <th>0.8</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.4</th>\n",
              "      <th>1.6</th>\n",
              "      <th>1.8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.873819</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.972789</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.227424</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "      <td>24.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2       R^2  acc train  acc test  ...   1.0   1.2   1.4   1.6  1.8\n",
              "0  20  20  0.873819        1.0  0.972789  ...  16.0  26.0  24.0  10.0  0.0\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f6288a85-e5d2-4ed6-a58f-8b6a826939ca"
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_35751d00-6821-48ee-a84e-fb86fb1ff847\", \"output.xlsx\", 5236)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}