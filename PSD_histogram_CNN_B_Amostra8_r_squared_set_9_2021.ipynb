{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_Amostra8_r_squared_jul_29_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/PSD_histogram_CNN_B_Amostra8_r_squared_set_9_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZEvJvfoibE4",
        "outputId": "9c70938a-7423-4573-d873-b11072b3ccf8"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.11-cp37-cp37m-manylinux2010_x86_64.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n",
            "Installing collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VcTdaNVh9EE",
        "outputId": "93074fe7-6caf-4c7f-f55c-9dc610a63b16"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marquesgabi_fev_2020'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 73 (delta 37), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n",
            "/content/marquesgabi_fev_2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7SRrc8mH2N",
        "outputId": "f1ac465b-36b3-4cd3-c404-ddf3e9b10ba8"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 431, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (180/180), done.\u001b[K\n",
            "remote: Total 431 (delta 80), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (431/431), 165.74 MiB | 28.36 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "f4d51087-9bb4-4e3b-9d15-a72859e6e8af"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[9] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgqAnaFyCjp",
        "outputId": "de454855-e3c5-406b-c29e-30877495cc0a"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 22.94 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN5MN5a_v4np",
        "outputId": "0d7b0e72-a1c5-4d31-e2e8-35500a7fbccd"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     199   23.659630   12.210524  ...    0.144214    0.000000    0.000000\n",
            "1     103  138.383057  141.610138  ...   70.819687   70.543121   70.174194\n",
            "2     181   86.141853   83.723915  ...   46.017094   31.137541   21.119595\n",
            "3     184   15.643666   42.573250  ...   24.736294   37.264175   52.614361\n",
            "4     111   32.395180   33.052753  ...   96.830368   98.672432   99.654167\n",
            "5     174   34.026428   38.155106  ...  129.197388  135.061432  135.827728\n",
            "6     128   51.588867   47.212891  ...   25.693359    8.851562    2.413086\n",
            "7     106   81.850830   80.169815  ...   42.343540   41.600571   38.224281\n",
            "8     107   92.778236   91.275749  ...   64.123329   62.246834   61.955978\n",
            "9     154   90.256210   93.033066  ...  104.776863  107.314056  106.702492\n",
            "10    191   74.077393   79.236458  ...   89.792229   92.054337   91.526451\n",
            "11    121  105.084152  105.014069  ...  126.205383  131.408585  132.505768\n",
            "12    116   44.297264   41.611176  ...    9.491082    2.764566    1.027348\n",
            "13    198   43.188244   59.120697  ...   91.987961   99.321701  108.623596\n",
            "14    140   67.279999   70.239998  ...   77.839996   79.400002   80.279999\n",
            "15    171   41.330360   42.084915  ...    5.968742    5.933347    6.073151\n",
            "16    186   78.872818   79.980461  ...    5.796162    5.831773    5.666667\n",
            "17    132   38.737377   38.894402  ...   84.618919   82.804413   80.618011\n",
            "18    137   73.172569   70.769249  ...   92.688797   93.587296   94.284500\n",
            "19    154  121.966957   55.355373  ...    3.983471    1.603306    1.057851\n",
            "20    136    1.933391    1.249135  ...   16.139275    2.185121    1.121107\n",
            "21    111   82.245522   81.288452  ...    9.619755    9.415470    9.235939\n",
            "22    103   99.395325  103.178345  ...   38.255348   38.250164   39.875950\n",
            "23    174   75.175850   66.350388  ...    4.715286    4.492668    2.866297\n",
            "24    145   93.774025   93.370514  ...   75.088181   71.749199   70.521904\n",
            "25    139   50.156200   42.656796  ...   57.011333   60.815533   65.265099\n",
            "26    160   50.899998   51.340626  ...  112.051872  114.486252  128.608734\n",
            "27    100   88.652794   89.670410  ...   76.726395   77.180794   74.278397\n",
            "28    126   19.567902   25.148148  ...   60.333336   64.740746   70.493828\n",
            "29    111   59.738655   58.913887  ...   58.581444   60.493057   60.115982\n",
            "30    168   46.055557   33.527779  ...   85.055557   86.750000   89.055557\n",
            "31    107  111.320114  110.256966  ...  105.322395  118.723724  121.987244\n",
            "32    166  132.449112  130.813171  ...   37.071564   33.867325   39.486427\n",
            "33    110   92.717682   96.120651  ...    8.675702    8.803305    8.747768\n",
            "34    181   26.420197   54.008427  ...    0.058973    0.331614    0.189738\n",
            "35    157   52.472107   57.018501  ...   58.071724   63.564564   67.519547\n",
            "36    185   28.880495   30.617062  ...   90.471252   89.516747   89.059715\n",
            "37    178   66.106682   83.974121  ...   52.465855   53.241135   53.097214\n",
            "38    115   79.801659   83.321968  ...   50.615578   36.723476   29.608919\n",
            "39    177   99.636230   97.181900  ...   43.705257   41.432182   40.287872\n",
            "40    124   87.816849   91.079079  ...    8.283038    8.546305    7.715920\n",
            "41    130   70.846153   76.778473  ...   84.157875   85.570183   87.766159\n",
            "42    110   83.294876   82.955704  ...  109.035706  109.226440  100.987091\n",
            "43    130   89.037155   89.906273  ...   52.269112   50.608284   48.300121\n",
            "44    182   86.994095   88.816574  ...   63.159767   65.082848   65.532547\n",
            "45    157   95.366905   94.978821  ...    0.723964    0.980689    0.579699\n",
            "46    187   75.003922   76.498657  ...   51.439846   52.985844   54.671455\n",
            "47    196   87.081635   73.530609  ...  127.836731  122.938774  128.122452\n",
            "48    171   39.121609   70.539963  ...   12.331521    9.889129   10.933893\n",
            "49    181   67.670006   57.000549  ...   10.345533   15.383933   34.102592\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xzpQ1Pz0fX5L",
        "outputId": "9a49208d-195c-48e4-e108-6dfafe9aab15"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "98c244b1-d52e-4175-bbd3-17351d3850bf"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 22.09 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 32, 64, 128 '\n",
        "N1 = 200\n",
        "N2 = 10\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=32, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "5076edbe-39f0-4953-f151-b7f5d9235332"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 76ms/step - loss: 0.5660 - accuracy: 0.7289 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.2987 - accuracy: 0.8980 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.2750 - accuracy: 0.8688 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.2014 - accuracy: 0.9096 - val_loss: 0.6937 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.1140 - accuracy: 0.9563 - val_loss: 0.6953 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0893 - accuracy: 0.9767 - val_loss: 0.6970 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0599 - accuracy: 0.9738 - val_loss: 0.6982 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0739 - accuracy: 0.9767 - val_loss: 0.6985 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0731 - accuracy: 0.9679 - val_loss: 0.7025 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0294 - accuracy: 0.9854 - val_loss: 0.6987 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0426 - accuracy: 0.9883 - val_loss: 0.7061 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0176 - accuracy: 0.9971 - val_loss: 0.7091 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.7065 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.7090 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7322 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7432 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0032 - accuracy: 0.9971 - val_loss: 0.7617 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7703 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0040 - accuracy: 0.9971 - val_loss: 0.7770 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7878 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0068 - accuracy: 0.9971 - val_loss: 1.0003 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0066 - accuracy: 0.9971 - val_loss: 0.8651 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.7580 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.9921 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 1.6921 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0470 - accuracy: 0.9796 - val_loss: 2.9424 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0269 - accuracy: 0.9883 - val_loss: 2.8299 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0599 - accuracy: 0.9825 - val_loss: 4.6416 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0204 - accuracy: 0.9913 - val_loss: 7.1915 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0348 - accuracy: 0.9854 - val_loss: 6.6043 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 9.3237 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 7.2989 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0056 - accuracy: 0.9971 - val_loss: 6.6726 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 6.6505 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.9719 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 7.2076e-04 - accuracy: 1.0000 - val_loss: 6.9401 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.6597 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.9258e-04 - accuracy: 1.0000 - val_loss: 6.3627 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 6.0565 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 8.0310e-04 - accuracy: 1.0000 - val_loss: 6.6223 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 7.1593e-04 - accuracy: 1.0000 - val_loss: 6.8751 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.6917e-04 - accuracy: 1.0000 - val_loss: 7.0054 - val_accuracy: 0.5102\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.8490e-04 - accuracy: 1.0000 - val_loss: 6.8656 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 4.8877e-04 - accuracy: 1.0000 - val_loss: 6.2043 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 2.5442e-04 - accuracy: 1.0000 - val_loss: 4.9197 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.9727e-04 - accuracy: 1.0000 - val_loss: 3.5242 - val_accuracy: 0.5102\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.1287e-04 - accuracy: 1.0000 - val_loss: 2.8188 - val_accuracy: 0.5102\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 8.1276e-04 - accuracy: 1.0000 - val_loss: 2.2165 - val_accuracy: 0.5102\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.3256e-04 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.5578\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8912 - val_accuracy: 0.5102\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.1035e-04 - accuracy: 1.0000 - val_loss: 3.7699 - val_accuracy: 0.5102\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 6.4902e-04 - accuracy: 1.0000 - val_loss: 3.5961 - val_accuracy: 0.5102\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 5.0949e-04 - accuracy: 1.0000 - val_loss: 3.0363 - val_accuracy: 0.5238\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 1.1087e-04 - accuracy: 1.0000 - val_loss: 2.6664 - val_accuracy: 0.5510\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 4.1616e-04 - accuracy: 1.0000 - val_loss: 2.5878 - val_accuracy: 0.5782\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 2.2786e-04 - accuracy: 1.0000 - val_loss: 2.0885 - val_accuracy: 0.6054\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0040 - accuracy: 0.9971 - val_loss: 0.7100 - val_accuracy: 0.7279\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 3.8612 - val_accuracy: 0.5102\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.5314 - val_accuracy: 0.5102\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 16.2266 - val_accuracy: 0.5102\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 5.0595e-04 - accuracy: 1.0000 - val_loss: 19.5593 - val_accuracy: 0.5102\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 5.0622e-04 - accuracy: 1.0000 - val_loss: 21.1123 - val_accuracy: 0.5102\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 6.4986e-04 - accuracy: 1.0000 - val_loss: 21.2126 - val_accuracy: 0.5102\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.2854e-04 - accuracy: 1.0000 - val_loss: 20.8032 - val_accuracy: 0.5102\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 1.2803e-04 - accuracy: 1.0000 - val_loss: 19.9490 - val_accuracy: 0.5102\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 9.4503e-05 - accuracy: 1.0000 - val_loss: 18.6121 - val_accuracy: 0.5102\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.2939e-04 - accuracy: 1.0000 - val_loss: 17.1237 - val_accuracy: 0.5102\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 6.9832e-05 - accuracy: 1.0000 - val_loss: 15.3913 - val_accuracy: 0.5102\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.5570e-04 - accuracy: 1.0000 - val_loss: 13.7802 - val_accuracy: 0.5102\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.2669e-04 - accuracy: 1.0000 - val_loss: 12.4774 - val_accuracy: 0.5102\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 1.9014e-04 - accuracy: 1.0000 - val_loss: 11.1491 - val_accuracy: 0.5102\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 7.5401e-05 - accuracy: 1.0000 - val_loss: 9.8169 - val_accuracy: 0.5102\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 1.9086e-04 - accuracy: 1.0000 - val_loss: 8.9221 - val_accuracy: 0.5102\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.2470e-04 - accuracy: 1.0000 - val_loss: 9.1019 - val_accuracy: 0.5102\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 5.4404e-05 - accuracy: 1.0000 - val_loss: 8.4112 - val_accuracy: 0.5102\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 4.2777e-04 - accuracy: 1.0000 - val_loss: 4.4883 - val_accuracy: 0.5102\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 8.4838e-05 - accuracy: 1.0000 - val_loss: 3.7168 - val_accuracy: 0.5102\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.0604e-04 - accuracy: 1.0000 - val_loss: 3.3935 - val_accuracy: 0.5238\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 2.0392e-04 - accuracy: 1.0000 - val_loss: 2.4567 - val_accuracy: 0.5782\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 7.1006e-04 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.7075\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 3.7579e-04 - accuracy: 1.0000 - val_loss: 2.4347 - val_accuracy: 0.6395\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.0134e-04 - accuracy: 1.0000 - val_loss: 6.2190 - val_accuracy: 0.5102\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.0113e-04 - accuracy: 1.0000 - val_loss: 3.4875 - val_accuracy: 0.5646\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.7495e-04 - accuracy: 1.0000 - val_loss: 4.3109 - val_accuracy: 0.5238\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.2163e-04 - accuracy: 1.0000 - val_loss: 4.0911 - val_accuracy: 0.5374\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 7.4580e-05 - accuracy: 1.0000 - val_loss: 3.3080 - val_accuracy: 0.5510\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 5.9421e-04 - accuracy: 1.0000 - val_loss: 4.3753 - val_accuracy: 0.5374\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 1.2810e-04 - accuracy: 1.0000 - val_loss: 6.4710 - val_accuracy: 0.5102\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9184\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 1.2320e-04 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.8844\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 4.5654e-04 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9184\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9524\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 6.8986e-05 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.8163\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 9.1404e-04 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.8299\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.9437e-04 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.8707\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 2.9960e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8163\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 2.7927e-05 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 0.7755\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 6.2575e-05 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.7619\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 3.1453e-05 - accuracy: 1.0000 - val_loss: 0.8510 - val_accuracy: 0.8027\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 4.0797e-05 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.8571\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 4.1333e-05 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.8707\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 5.2432e-05 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9048\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 3.8642e-05 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9116\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0662 - val_accuracy: 0.6190\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0170 - accuracy: 0.9971 - val_loss: 12.3354 - val_accuracy: 0.5102\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 54.2584 - val_accuracy: 0.5102\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0788 - accuracy: 0.9679 - val_loss: 367.3077 - val_accuracy: 0.5102\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.2002 - accuracy: 0.9592 - val_loss: 313.3511 - val_accuracy: 0.5102\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.1031 - accuracy: 0.9796 - val_loss: 349.8424 - val_accuracy: 0.5102\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0305 - accuracy: 0.9942 - val_loss: 197.5619 - val_accuracy: 0.5102\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0210 - accuracy: 0.9913 - val_loss: 247.0668 - val_accuracy: 0.5102\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.0313 - accuracy: 0.9825 - val_loss: 203.6867 - val_accuracy: 0.5102\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 217.9498 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 235.4854 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 238.5538 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 206.0903 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 176.1987 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 153.5723 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.0047 - accuracy: 0.9971 - val_loss: 130.9712 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 79.1868 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 9.8631e-04 - accuracy: 1.0000 - val_loss: 61.0357 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 5.0784e-04 - accuracy: 1.0000 - val_loss: 51.4800 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 3.1250e-04 - accuracy: 1.0000 - val_loss: 45.1142 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 5.1156e-04 - accuracy: 1.0000 - val_loss: 39.7372 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 34.4189 - val_accuracy: 0.5102\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 29.6198 - val_accuracy: 0.5102\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 2.7691e-04 - accuracy: 1.0000 - val_loss: 25.5265 - val_accuracy: 0.5102\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 6.6242e-04 - accuracy: 1.0000 - val_loss: 22.7004 - val_accuracy: 0.5102\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 7.1156e-04 - accuracy: 1.0000 - val_loss: 16.1077 - val_accuracy: 0.5102\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.0027 - accuracy: 0.9971 - val_loss: 11.1052 - val_accuracy: 0.5102\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 15.5436 - val_accuracy: 0.5102\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 7.7487e-04 - accuracy: 1.0000 - val_loss: 23.6721 - val_accuracy: 0.5102\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 3.2010e-04 - accuracy: 1.0000 - val_loss: 27.6826 - val_accuracy: 0.5102\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 4.3982e-04 - accuracy: 1.0000 - val_loss: 26.7988 - val_accuracy: 0.5102\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 1.7756e-04 - accuracy: 1.0000 - val_loss: 24.3901 - val_accuracy: 0.5102\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 5.9627e-04 - accuracy: 1.0000 - val_loss: 20.7841 - val_accuracy: 0.5102\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 16.7886 - val_accuracy: 0.5102\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 3.3585e-04 - accuracy: 1.0000 - val_loss: 23.0627 - val_accuracy: 0.5102\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 25.3994 - val_accuracy: 0.5102\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 23.6413 - val_accuracy: 0.5102\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 4.4191e-04 - accuracy: 1.0000 - val_loss: 21.0717 - val_accuracy: 0.5102\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 26.8257 - val_accuracy: 0.5102\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 2.3276e-04 - accuracy: 1.0000 - val_loss: 26.5143 - val_accuracy: 0.5102\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 3.2316e-04 - accuracy: 1.0000 - val_loss: 25.2445 - val_accuracy: 0.5102\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 26.0343 - val_accuracy: 0.5102\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 1.3120e-04 - accuracy: 1.0000 - val_loss: 24.0701 - val_accuracy: 0.5102\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.4432e-04 - accuracy: 1.0000 - val_loss: 21.1341 - val_accuracy: 0.5102\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 1.8496e-04 - accuracy: 1.0000 - val_loss: 18.7519 - val_accuracy: 0.5102\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 1.4705e-04 - accuracy: 1.0000 - val_loss: 17.2829 - val_accuracy: 0.5102\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 2.1653e-04 - accuracy: 1.0000 - val_loss: 15.7942 - val_accuracy: 0.5102\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.5809e-04 - accuracy: 1.0000 - val_loss: 14.2112 - val_accuracy: 0.5102\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 1.9351e-04 - accuracy: 1.0000 - val_loss: 12.8194 - val_accuracy: 0.5102\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.0197e-04 - accuracy: 1.0000 - val_loss: 11.6893 - val_accuracy: 0.5102\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 1.0665e-04 - accuracy: 1.0000 - val_loss: 10.7426 - val_accuracy: 0.5102\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.7432e-04 - accuracy: 1.0000 - val_loss: 9.4523 - val_accuracy: 0.5102\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 7.5320e-05 - accuracy: 1.0000 - val_loss: 7.9251 - val_accuracy: 0.5170\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 1.1141e-04 - accuracy: 1.0000 - val_loss: 7.0767 - val_accuracy: 0.5170\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 2.3888e-04 - accuracy: 1.0000 - val_loss: 6.3622 - val_accuracy: 0.5170\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 7.8947e-05 - accuracy: 1.0000 - val_loss: 5.6579 - val_accuracy: 0.5170\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 6.7866e-05 - accuracy: 1.0000 - val_loss: 4.8400 - val_accuracy: 0.5238\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 4.5741e-04 - accuracy: 1.0000 - val_loss: 4.1352 - val_accuracy: 0.5510\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 7.8574e-05 - accuracy: 1.0000 - val_loss: 4.3937 - val_accuracy: 0.5442\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 7.5430e-05 - accuracy: 1.0000 - val_loss: 3.9404 - val_accuracy: 0.5782\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.2410e-04 - accuracy: 1.0000 - val_loss: 2.7532 - val_accuracy: 0.6259\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.0546e-04 - accuracy: 1.0000 - val_loss: 1.5793 - val_accuracy: 0.7143\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 6.2231e-05 - accuracy: 1.0000 - val_loss: 1.1239 - val_accuracy: 0.7687\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 1.6277e-04 - accuracy: 1.0000 - val_loss: 2.2688 - val_accuracy: 0.6463\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.5172e-04 - accuracy: 1.0000 - val_loss: 1.8860 - val_accuracy: 0.6667\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 3.4282e-05 - accuracy: 1.0000 - val_loss: 1.4432 - val_accuracy: 0.7143\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 3.2328e-05 - accuracy: 1.0000 - val_loss: 1.2014 - val_accuracy: 0.7619\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 6.6584e-05 - accuracy: 1.0000 - val_loss: 1.1436 - val_accuracy: 0.7755\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 4.4070e-05 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.7959\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 4.7560e-05 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.8027\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 3.2614e-05 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.8163\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.1356e-04 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.8980\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 4.3463e-05 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9184\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 4.5763e-05 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9184\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 8.0419e-05 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9184\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 1.9088e-04 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9252\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 7.1325e-05 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9320\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 3.8240e-05 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9388\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 7.1498e-05 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9592\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 3.9748e-05 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9728\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 2.1617e-04 - accuracy: 1.0000 - val_loss: 3.1000 - val_accuracy: 0.5714\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 2.6595e-05 - accuracy: 1.0000 - val_loss: 5.2625 - val_accuracy: 0.5170\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 1.2012e-04 - accuracy: 1.0000 - val_loss: 5.1128 - val_accuracy: 0.5170\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 5.6417e-05 - accuracy: 1.0000 - val_loss: 3.3238 - val_accuracy: 0.5646\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 2.3366e-05 - accuracy: 1.0000 - val_loss: 2.2038 - val_accuracy: 0.6122\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 6.5256e-05 - accuracy: 1.0000 - val_loss: 1.3598 - val_accuracy: 0.7143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2Q1QDQTGqqV",
        "outputId": "b8b1c7bf-8b64-4bfb-c4bb-b3dba18b5b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred_test= model.predict(X_test)\n",
        "Rows, Cols = pred_test.shape\n",
        "Prediction =[]\n",
        "for i in range(Rows):\n",
        "  if(pred_test[0,0] > pred_test[0,1]):\n",
        "    Prediction.append(0)\n",
        "  else:\n",
        "    Prediction.append(1)\n",
        "  \n",
        "\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': Prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   1\n",
            "Actual     \n",
            "0        72\n",
            "1        75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH"
      },
      "source": [
        "#pred_test"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2_t9FpLG42n",
        "outputId": "cbe34c21-203c-4567-eaab-a851a03e35f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[9] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  prediction_02 = model.predict(result)\n",
        "  Rows, Cols = prediction_02.shape\n",
        "  Prediction =[]\n",
        "  for i in range(Rows):\n",
        "    if(prediction_02[0,0] > prediction_02[0,1]):\n",
        "      Prediction.append(0)\n",
        "    else:\n",
        "      Prediction.append(1)\n",
        "  loc_grao =[];k=0\n",
        "  for i in Prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0   104.0   43.434914   50.031067  ...   59.769234   61.696754   61.551781\n",
            "1   195.0   48.955109   59.175964  ...   87.651077   76.448242   65.528946\n",
            "2   128.0  102.390625  110.763672  ...    1.261719    0.370117    0.444336\n",
            "3   128.0    0.567383    1.719727  ...   41.034180   35.852539   22.966797\n",
            "4   140.0   67.799995   74.519997  ...   71.080002   72.000000   71.559998\n",
            "5   178.0   42.075874   25.098473  ...    9.701428    8.841183   10.411693\n",
            "6   121.0   75.837440   75.715866  ...    0.158732    0.000000    0.000000\n",
            "7   169.0   82.135262   80.665627  ...   54.697666   57.281258   60.694016\n",
            "8   102.0   64.841995   58.083817  ...   21.852751   12.712420    4.798540\n",
            "9   131.0   77.534462   79.864395  ...   40.231106   26.821106   15.360352\n",
            "10  151.0   82.039696   80.248978  ...   97.346046   99.904663   98.196045\n",
            "11  143.0    0.000000    0.000000  ...   39.460564   41.162502   41.736221\n",
            "12  135.0  125.463257  121.302269  ...   66.999496   68.412399   69.569817\n",
            "13  169.0   89.934204   89.362579  ...  101.177437  101.778397  102.325432\n",
            "14  178.0   33.091911   37.384296  ...    6.256408    6.045702    5.761899\n",
            "15  165.0   91.415100   93.791519  ...   38.021122   18.668873   14.163527\n",
            "16  134.0   40.667412   42.410339  ...   56.793274   60.312325   69.223885\n",
            "17  191.0   43.968945   32.976868  ...  103.945335  103.927742  106.320229\n",
            "18  179.0   45.087917   49.427986  ...   49.359196   47.884903   44.510033\n",
            "19  106.0   65.433250   69.672485  ...   49.555714   47.672836   48.355644\n",
            "20  196.0   49.979591   65.346939  ...    6.102041    5.571428    5.367347\n",
            "21  160.0   76.946869   75.728127  ...  110.277496  138.831863  147.003128\n",
            "22  114.0   71.641739   79.421974  ...   73.361031   76.142815   80.128036\n",
            "23  108.0   77.326469   80.854599  ...   52.943756   56.680382   61.197529\n",
            "24  133.0   71.786705   68.036011  ...   21.102493   19.224377   18.819944\n",
            "25  139.0   34.759586   45.522278  ...   52.897263   56.727650   57.559490\n",
            "26  129.0   35.951206   37.513130  ...    8.388258    8.211586    8.482483\n",
            "27  165.0   56.505676   59.755554  ...   77.418213   78.202652   79.196808\n",
            "28  178.0   37.796875   55.452477  ...   40.493629   47.885120   52.716583\n",
            "29  153.0   39.577259   40.389679  ...   78.550095   77.971336   74.655609\n",
            "30  200.0   21.864801   15.507200  ...   43.140400   38.979195   41.547596\n",
            "31  169.0   83.055840   83.569542  ...   18.044395   18.189034   18.006756\n",
            "32  130.0   67.388870   70.802841  ...    0.000000    0.000000    0.000000\n",
            "33  139.0   88.871063   90.198318  ...  166.136841  175.838104  196.374817\n",
            "34  112.0   83.500000   89.312500  ...    9.187500    8.625000    8.250000\n",
            "35  159.0   75.045052   78.535103  ...   90.666229   95.030014   98.148880\n",
            "36  120.0   84.183334   85.063332  ...   76.367783   74.928886   75.048889\n",
            "37  123.0   83.676773   84.712540  ...    8.853395    8.778043    8.676912\n",
            "38  111.0  116.702217  116.508881  ...   78.996101   77.059250   77.818108\n",
            "39  194.0   77.911568   74.638527  ...  112.635757  109.510361   96.486862\n",
            "40  185.0  122.292862  127.030792  ...   11.599503    4.086867    1.008707\n",
            "41  152.0   62.031857   61.090023  ...   96.915512   96.111496  106.505531\n",
            "42  156.0  102.933594   88.453644  ...   29.377384   25.812622   23.562790\n",
            "43  197.0    1.279188    0.207065  ...   39.306499   28.269527   31.771912\n",
            "44  116.0   91.644463  103.137932  ...   81.992867   75.237816   70.753868\n",
            "45  152.0   42.853184   37.501381  ...  105.127419  104.201523   98.527695\n",
            "46  144.0   18.271606   21.682873  ...   17.913582   26.022377   29.283180\n",
            "47  154.0   80.173569   86.570251  ...    4.446281    5.330579    2.669421\n",
            "48  151.0   85.469940   84.047104  ...   95.932373   96.444633   97.819931\n",
            "49  104.0   37.834324   37.044384  ...    0.000000    0.000000    0.000000\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "ec298f13-b280-408e-955c-ccc88e056c6a"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marquesgabi_paper_fev_2021'...\n",
            "remote: Enumerating objects: 687, done.\u001b[K\n",
            "remote: Counting objects: 100% (448/448), done.\u001b[K\n",
            "remote: Compressing objects: 100% (446/446), done.\u001b[K\n",
            "remote: Total 687 (delta 282), reused 0 (delta 0), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (687/687), 5.59 MiB | 10.87 MiB/s, done.\n",
            "Resolving deltas: 100% (419/419), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "d127565b-1a68-490c-a768-ac763c51ad93"
      },
      "source": [
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "\n",
        "%cd Doutorado\n",
        "\n",
        "PSD_imageJ = 'Amostra8.csv' \n",
        "PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 431, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (180/180), done.\u001b[K\n",
            "remote: Total 431 (delta 80), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (431/431), 165.74 MiB | 27.56 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "   Unnamed: 0   Area\n",
            "0           1  0.807\n",
            "1           2  1.407\n",
            "2           3  1.177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tEPjIBnv_xM",
        "outputId": "f12aea44-7bf0-4e6a-82f1-e9cd13ddc178"
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfagXc-Mv3oa"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "PekBHQOT_6CP",
        "outputId": "2ac35241-fcad-4f70-9477-2e8d236a5a92"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>104.0</td>\n",
              "      <td>43.434914</td>\n",
              "      <td>50.031067</td>\n",
              "      <td>65.464508</td>\n",
              "      <td>79.613914</td>\n",
              "      <td>89.809181</td>\n",
              "      <td>95.189354</td>\n",
              "      <td>96.352081</td>\n",
              "      <td>88.757416</td>\n",
              "      <td>84.977814</td>\n",
              "      <td>81.217461</td>\n",
              "      <td>80.665688</td>\n",
              "      <td>94.020714</td>\n",
              "      <td>109.862442</td>\n",
              "      <td>113.724861</td>\n",
              "      <td>102.223381</td>\n",
              "      <td>91.945282</td>\n",
              "      <td>92.929008</td>\n",
              "      <td>95.671608</td>\n",
              "      <td>101.016273</td>\n",
              "      <td>109.460068</td>\n",
              "      <td>130.270721</td>\n",
              "      <td>121.263321</td>\n",
              "      <td>115.679001</td>\n",
              "      <td>105.640549</td>\n",
              "      <td>96.661255</td>\n",
              "      <td>91.846161</td>\n",
              "      <td>87.637573</td>\n",
              "      <td>84.917160</td>\n",
              "      <td>40.750004</td>\n",
              "      <td>46.838760</td>\n",
              "      <td>66.198227</td>\n",
              "      <td>80.232254</td>\n",
              "      <td>92.553261</td>\n",
              "      <td>95.991135</td>\n",
              "      <td>93.748528</td>\n",
              "      <td>87.566574</td>\n",
              "      <td>84.501480</td>\n",
              "      <td>82.142021</td>\n",
              "      <td>83.321014</td>\n",
              "      <td>...</td>\n",
              "      <td>55.710060</td>\n",
              "      <td>54.724857</td>\n",
              "      <td>56.297340</td>\n",
              "      <td>57.247047</td>\n",
              "      <td>55.424564</td>\n",
              "      <td>56.809174</td>\n",
              "      <td>57.294384</td>\n",
              "      <td>58.684914</td>\n",
              "      <td>61.636101</td>\n",
              "      <td>63.245567</td>\n",
              "      <td>66.405334</td>\n",
              "      <td>67.501488</td>\n",
              "      <td>72.005920</td>\n",
              "      <td>71.995567</td>\n",
              "      <td>71.812134</td>\n",
              "      <td>71.507408</td>\n",
              "      <td>69.610947</td>\n",
              "      <td>66.690834</td>\n",
              "      <td>67.402374</td>\n",
              "      <td>68.893494</td>\n",
              "      <td>67.300293</td>\n",
              "      <td>62.825451</td>\n",
              "      <td>62.025154</td>\n",
              "      <td>60.254440</td>\n",
              "      <td>59.785507</td>\n",
              "      <td>58.269238</td>\n",
              "      <td>56.708584</td>\n",
              "      <td>56.775150</td>\n",
              "      <td>57.156807</td>\n",
              "      <td>56.786987</td>\n",
              "      <td>57.313614</td>\n",
              "      <td>57.983734</td>\n",
              "      <td>57.186394</td>\n",
              "      <td>57.571007</td>\n",
              "      <td>58.958588</td>\n",
              "      <td>60.446754</td>\n",
              "      <td>59.415688</td>\n",
              "      <td>59.769234</td>\n",
              "      <td>61.696754</td>\n",
              "      <td>61.551781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>195.0</td>\n",
              "      <td>48.955109</td>\n",
              "      <td>59.175964</td>\n",
              "      <td>79.698151</td>\n",
              "      <td>81.431015</td>\n",
              "      <td>77.807182</td>\n",
              "      <td>75.206947</td>\n",
              "      <td>73.689240</td>\n",
              "      <td>73.975784</td>\n",
              "      <td>78.468071</td>\n",
              "      <td>81.799088</td>\n",
              "      <td>80.900055</td>\n",
              "      <td>82.629593</td>\n",
              "      <td>84.983940</td>\n",
              "      <td>88.864174</td>\n",
              "      <td>86.892448</td>\n",
              "      <td>79.338577</td>\n",
              "      <td>79.123581</td>\n",
              "      <td>84.940910</td>\n",
              "      <td>87.810051</td>\n",
              "      <td>91.114555</td>\n",
              "      <td>87.053261</td>\n",
              "      <td>50.086895</td>\n",
              "      <td>16.403315</td>\n",
              "      <td>22.160843</td>\n",
              "      <td>27.017412</td>\n",
              "      <td>32.474876</td>\n",
              "      <td>42.980492</td>\n",
              "      <td>59.732628</td>\n",
              "      <td>49.824913</td>\n",
              "      <td>56.295918</td>\n",
              "      <td>79.951195</td>\n",
              "      <td>84.033142</td>\n",
              "      <td>80.556213</td>\n",
              "      <td>77.451569</td>\n",
              "      <td>73.917885</td>\n",
              "      <td>74.069984</td>\n",
              "      <td>75.574074</td>\n",
              "      <td>76.581886</td>\n",
              "      <td>77.243027</td>\n",
              "      <td>...</td>\n",
              "      <td>87.032089</td>\n",
              "      <td>91.447983</td>\n",
              "      <td>104.483765</td>\n",
              "      <td>103.509201</td>\n",
              "      <td>80.852463</td>\n",
              "      <td>68.817757</td>\n",
              "      <td>66.986519</td>\n",
              "      <td>65.236450</td>\n",
              "      <td>57.879505</td>\n",
              "      <td>47.825539</td>\n",
              "      <td>43.517796</td>\n",
              "      <td>41.287106</td>\n",
              "      <td>98.119568</td>\n",
              "      <td>43.135155</td>\n",
              "      <td>40.021149</td>\n",
              "      <td>39.824802</td>\n",
              "      <td>40.855152</td>\n",
              "      <td>43.204395</td>\n",
              "      <td>45.992775</td>\n",
              "      <td>58.829960</td>\n",
              "      <td>76.139763</td>\n",
              "      <td>85.737968</td>\n",
              "      <td>87.755615</td>\n",
              "      <td>84.492020</td>\n",
              "      <td>85.113930</td>\n",
              "      <td>88.559296</td>\n",
              "      <td>87.641006</td>\n",
              "      <td>83.665253</td>\n",
              "      <td>84.450531</td>\n",
              "      <td>90.825966</td>\n",
              "      <td>101.482475</td>\n",
              "      <td>106.611893</td>\n",
              "      <td>101.723373</td>\n",
              "      <td>98.836853</td>\n",
              "      <td>101.666649</td>\n",
              "      <td>100.640640</td>\n",
              "      <td>97.252190</td>\n",
              "      <td>87.651077</td>\n",
              "      <td>76.448242</td>\n",
              "      <td>65.528946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128.0</td>\n",
              "      <td>102.390625</td>\n",
              "      <td>110.763672</td>\n",
              "      <td>114.280273</td>\n",
              "      <td>116.224609</td>\n",
              "      <td>116.556641</td>\n",
              "      <td>110.973633</td>\n",
              "      <td>105.530273</td>\n",
              "      <td>104.613281</td>\n",
              "      <td>103.979492</td>\n",
              "      <td>102.663086</td>\n",
              "      <td>102.393555</td>\n",
              "      <td>105.508789</td>\n",
              "      <td>112.567383</td>\n",
              "      <td>115.462891</td>\n",
              "      <td>109.448242</td>\n",
              "      <td>89.305664</td>\n",
              "      <td>64.904297</td>\n",
              "      <td>55.656250</td>\n",
              "      <td>57.569336</td>\n",
              "      <td>58.458984</td>\n",
              "      <td>59.189453</td>\n",
              "      <td>57.431641</td>\n",
              "      <td>56.761719</td>\n",
              "      <td>55.951172</td>\n",
              "      <td>53.748047</td>\n",
              "      <td>50.210938</td>\n",
              "      <td>45.539062</td>\n",
              "      <td>38.642578</td>\n",
              "      <td>112.307617</td>\n",
              "      <td>116.473633</td>\n",
              "      <td>119.007812</td>\n",
              "      <td>120.203125</td>\n",
              "      <td>119.298828</td>\n",
              "      <td>116.447266</td>\n",
              "      <td>108.733398</td>\n",
              "      <td>101.904297</td>\n",
              "      <td>100.302734</td>\n",
              "      <td>99.958008</td>\n",
              "      <td>102.530273</td>\n",
              "      <td>...</td>\n",
              "      <td>31.216797</td>\n",
              "      <td>26.101562</td>\n",
              "      <td>20.961914</td>\n",
              "      <td>21.011719</td>\n",
              "      <td>20.777344</td>\n",
              "      <td>20.072266</td>\n",
              "      <td>17.611328</td>\n",
              "      <td>11.184570</td>\n",
              "      <td>6.726562</td>\n",
              "      <td>3.207031</td>\n",
              "      <td>0.875977</td>\n",
              "      <td>0.519531</td>\n",
              "      <td>50.320312</td>\n",
              "      <td>51.544922</td>\n",
              "      <td>54.710938</td>\n",
              "      <td>57.589844</td>\n",
              "      <td>58.307617</td>\n",
              "      <td>57.253906</td>\n",
              "      <td>57.945312</td>\n",
              "      <td>58.265625</td>\n",
              "      <td>60.357422</td>\n",
              "      <td>61.512695</td>\n",
              "      <td>61.798828</td>\n",
              "      <td>61.610352</td>\n",
              "      <td>59.867188</td>\n",
              "      <td>53.805664</td>\n",
              "      <td>47.415039</td>\n",
              "      <td>42.628906</td>\n",
              "      <td>34.813477</td>\n",
              "      <td>27.379883</td>\n",
              "      <td>21.313477</td>\n",
              "      <td>20.309570</td>\n",
              "      <td>19.755859</td>\n",
              "      <td>16.092773</td>\n",
              "      <td>10.144531</td>\n",
              "      <td>6.057617</td>\n",
              "      <td>3.383789</td>\n",
              "      <td>1.261719</td>\n",
              "      <td>0.370117</td>\n",
              "      <td>0.444336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128.0</td>\n",
              "      <td>0.567383</td>\n",
              "      <td>1.719727</td>\n",
              "      <td>2.620117</td>\n",
              "      <td>2.025391</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.243164</td>\n",
              "      <td>0.608398</td>\n",
              "      <td>0.678711</td>\n",
              "      <td>0.692383</td>\n",
              "      <td>1.328125</td>\n",
              "      <td>1.034180</td>\n",
              "      <td>1.252930</td>\n",
              "      <td>0.904297</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>1.058594</td>\n",
              "      <td>5.312500</td>\n",
              "      <td>3.615234</td>\n",
              "      <td>1.328125</td>\n",
              "      <td>1.499023</td>\n",
              "      <td>1.380859</td>\n",
              "      <td>1.118164</td>\n",
              "      <td>1.218750</td>\n",
              "      <td>0.825195</td>\n",
              "      <td>0.170898</td>\n",
              "      <td>0.389648</td>\n",
              "      <td>0.293945</td>\n",
              "      <td>0.054688</td>\n",
              "      <td>0.095703</td>\n",
              "      <td>0.020508</td>\n",
              "      <td>0.393555</td>\n",
              "      <td>1.321289</td>\n",
              "      <td>1.423828</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.528320</td>\n",
              "      <td>0.897461</td>\n",
              "      <td>0.420898</td>\n",
              "      <td>0.442383</td>\n",
              "      <td>...</td>\n",
              "      <td>43.023438</td>\n",
              "      <td>47.666016</td>\n",
              "      <td>48.666016</td>\n",
              "      <td>47.324219</td>\n",
              "      <td>46.084961</td>\n",
              "      <td>44.558594</td>\n",
              "      <td>44.301758</td>\n",
              "      <td>43.291016</td>\n",
              "      <td>41.954102</td>\n",
              "      <td>41.436523</td>\n",
              "      <td>38.700195</td>\n",
              "      <td>31.705078</td>\n",
              "      <td>52.443359</td>\n",
              "      <td>53.617188</td>\n",
              "      <td>59.853516</td>\n",
              "      <td>65.923828</td>\n",
              "      <td>66.012695</td>\n",
              "      <td>63.388672</td>\n",
              "      <td>55.144531</td>\n",
              "      <td>42.896484</td>\n",
              "      <td>37.890625</td>\n",
              "      <td>44.108398</td>\n",
              "      <td>49.161133</td>\n",
              "      <td>47.625000</td>\n",
              "      <td>43.520508</td>\n",
              "      <td>44.411133</td>\n",
              "      <td>44.786133</td>\n",
              "      <td>45.388672</td>\n",
              "      <td>44.859375</td>\n",
              "      <td>45.520508</td>\n",
              "      <td>44.828125</td>\n",
              "      <td>45.387695</td>\n",
              "      <td>46.567383</td>\n",
              "      <td>44.507812</td>\n",
              "      <td>42.179688</td>\n",
              "      <td>42.435547</td>\n",
              "      <td>42.061523</td>\n",
              "      <td>41.034180</td>\n",
              "      <td>35.852539</td>\n",
              "      <td>22.966797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>140.0</td>\n",
              "      <td>67.799995</td>\n",
              "      <td>74.519997</td>\n",
              "      <td>76.080002</td>\n",
              "      <td>74.279999</td>\n",
              "      <td>73.879997</td>\n",
              "      <td>71.680000</td>\n",
              "      <td>70.360001</td>\n",
              "      <td>69.199997</td>\n",
              "      <td>71.080002</td>\n",
              "      <td>71.080002</td>\n",
              "      <td>68.760002</td>\n",
              "      <td>66.239998</td>\n",
              "      <td>66.080002</td>\n",
              "      <td>66.400002</td>\n",
              "      <td>63.199997</td>\n",
              "      <td>61.480000</td>\n",
              "      <td>60.439999</td>\n",
              "      <td>55.439999</td>\n",
              "      <td>54.919998</td>\n",
              "      <td>56.480000</td>\n",
              "      <td>60.840000</td>\n",
              "      <td>68.839996</td>\n",
              "      <td>76.199997</td>\n",
              "      <td>87.799995</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>127.399994</td>\n",
              "      <td>123.119995</td>\n",
              "      <td>116.079994</td>\n",
              "      <td>62.160000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>67.680000</td>\n",
              "      <td>68.879997</td>\n",
              "      <td>70.279999</td>\n",
              "      <td>72.599998</td>\n",
              "      <td>73.919998</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>72.919998</td>\n",
              "      <td>70.239998</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>101.879997</td>\n",
              "      <td>87.320000</td>\n",
              "      <td>58.840000</td>\n",
              "      <td>53.119999</td>\n",
              "      <td>50.840000</td>\n",
              "      <td>49.959999</td>\n",
              "      <td>49.480000</td>\n",
              "      <td>49.959999</td>\n",
              "      <td>57.879997</td>\n",
              "      <td>68.680000</td>\n",
              "      <td>71.839996</td>\n",
              "      <td>72.720001</td>\n",
              "      <td>62.119999</td>\n",
              "      <td>85.839996</td>\n",
              "      <td>94.919998</td>\n",
              "      <td>90.119995</td>\n",
              "      <td>77.839996</td>\n",
              "      <td>71.559998</td>\n",
              "      <td>72.159996</td>\n",
              "      <td>75.479996</td>\n",
              "      <td>77.759995</td>\n",
              "      <td>81.080002</td>\n",
              "      <td>77.400002</td>\n",
              "      <td>71.320000</td>\n",
              "      <td>75.239998</td>\n",
              "      <td>82.599998</td>\n",
              "      <td>89.519997</td>\n",
              "      <td>98.639999</td>\n",
              "      <td>103.199997</td>\n",
              "      <td>103.320000</td>\n",
              "      <td>85.479996</td>\n",
              "      <td>54.959999</td>\n",
              "      <td>48.959999</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>47.160000</td>\n",
              "      <td>50.039997</td>\n",
              "      <td>59.719997</td>\n",
              "      <td>71.080002</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>71.559998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...        781        782        783\n",
              "0  104.0   43.434914   50.031067  ...  59.769234  61.696754  61.551781\n",
              "1  195.0   48.955109   59.175964  ...  87.651077  76.448242  65.528946\n",
              "2  128.0  102.390625  110.763672  ...   1.261719   0.370117   0.444336\n",
              "3  128.0    0.567383    1.719727  ...  41.034180  35.852539  22.966797\n",
              "4  140.0   67.799995   74.519997  ...  71.080002  72.000000  71.559998\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VaZPe_AxNBK9",
        "outputId": "e4e546b1-fe55-45c1-ced2-f1f7f207ac67"
      },
      "source": [
        "PSD_new.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.743</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Area\n",
              "0           1  0.807\n",
              "1           2  1.407\n",
              "2           3  1.177\n",
              "3           4  1.289\n",
              "4           5  1.743"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dExnOsslHrab"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "\n",
        "# Area = np.array(PSD_new.iloc[:,1])\n",
        "Area = PSD_new['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8IJgjcFLssj",
        "outputId": "76d30e65-3886-4189-a773-f3565ed42987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "PSD_new"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>28</td>\n",
              "      <td>2.097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>29</td>\n",
              "      <td>1.871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>30</td>\n",
              "      <td>1.315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>31</td>\n",
              "      <td>1.034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>32</td>\n",
              "      <td>2.095</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0   Area\n",
              "0            1  0.807\n",
              "1            2  1.407\n",
              "2            3  1.177\n",
              "3            4  1.289\n",
              "4            5  1.743\n",
              "..         ...    ...\n",
              "94          28  2.097\n",
              "95          29  1.871\n",
              "96          30  1.315\n",
              "97          31  1.034\n",
              "98          32  2.095\n",
              "\n",
              "[99 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_sp1BcwKM9q",
        "outputId": "f1520373-0bc7-44c0-9175-e18b817270e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "PSD_new.iloc[:,1].values"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.807, 1.407, 1.177, 1.289, 1.743, 1.425, 2.553, 0.968, 1.43 ,\n",
              "       0.722, 1.235, 1.058, 1.342, 1.207, 1.682, 1.474, 1.997, 1.187,\n",
              "       2.082, 2.877, 1.386, 1.176, 0.96 , 1.147, 1.02 , 1.249, 1.704,\n",
              "       1.602, 1.303, 1.707, 2.264, 1.233, 0.84 , 1.105, 1.343, 0.811,\n",
              "       2.03 , 1.844, 2.266, 1.472, 1.009, 1.851, 0.941, 2.252, 1.269,\n",
              "       1.082, 1.065, 1.995, 2.063, 0.969, 1.389, 1.721, 1.355, 1.178,\n",
              "       1.529, 1.371, 1.423, 2.756, 0.854, 0.811, 0.69 , 1.752, 0.978,\n",
              "       1.108, 1.149, 0.994, 1.594, 1.492, 1.322, 1.564, 1.29 , 1.057,\n",
              "       1.193, 1.413, 1.477, 2.21 , 1.27 , 1.865, 1.088, 2.316, 1.855,\n",
              "       0.882, 1.587, 1.075, 2.179, 1.749, 0.957, 1.24 , 1.586, 2.507,\n",
              "       1.864, 1.281, 2.137, 1.282, 2.097, 1.871, 1.315, 1.034, 2.095])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J705kDqsE8f",
        "outputId": "9e0b37b3-c93c-48de-ccae-61643bc4cd7d"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mK1GBUHWiIr4",
        "outputId": "ff72cc3e-b687-43a4-c4f5-c3eeb7c45976"
      },
      "source": [
        "Freq = [10.52631579, 24.21052632, 36.84210526, 14.73684211,  7.36842105, 0.]\n",
        "Freq2 = [12.90153, 28.11527, 27.66761, 20.21617, 10.34227, 0.]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434, 0.]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOrUlEQVR4nO3dfYxmZX3G8e/VBYqtL2D3KdmCdq1VkTRlsSOl1RhErUD/ABLSlLZKDcnaVgw2poGatEBfEkyqNI2tzSqUtbFSAlioUVuitISo2EGXZWFrQUQLXdnxrYJNbBZ//eM5W8ZxZp8zz8vM3sP3k5zMOfdzzp7fzUwu7jlzzn1SVUiS2vND612AJGk8BrgkNcoAl6RGGeCS1CgDXJIadcRanmzz5s21devWtTylJDXv7rvv/lpVDZa2r2mAb926lfn5+bU8pSQ1L8mXl2v3EookNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqTZ/E1MaWKzPR8XW5LxeRVsMRuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrUyABPcnSSzya5J8l9Sa7s2q9L8qUku7pl2+zLlSQd1Oc+8O8CZ1TVE0mOBO5M8rHus9+rqhtnV54kaSUjA7yqCnii2zyyW3ziQpLWWa9r4Ek2JdkF7Aduq6q7uo/+NMnuJFcn+eEVjt2eZD7J/MLCwpTKliT1CvCqerKqtgEnAKcm+Rng94ETgZcDzwUuXeHYHVU1V1Vzg8EPvFRZkjSmVd2FUlXfAm4HzqyqfTX0XeBvgFNnUaAkaXl97kIZJDmmW38G8Drg35Ns6doCnAvsmWWhkqTv1+culC3AziSbGAb+DVX1kSSfTDIAAuwCfmuGdUqSluhzF8pu4JRl2s+YSUWSpF58ElOSGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqVJ+30h+d5LNJ7klyX5Iru/YXJLkryYNJ/j7JUbMvV5J0UJ8R+HeBM6rqZGAbcGaS04B3AldX1U8D3wQuml2ZkqSlRgZ4DT3RbR7ZLQWcAdzYte8Ezp1JhZpYMtki6fDU6xp4kk1JdgH7gduALwLfqqoD3S6PAMevcOz2JPNJ5hcWFqZRsySJngFeVU9W1TbgBOBU4MS+J6iqHVU1V1Vzg8FgzDIlSUut6i6UqvoWcDvwC8AxSY7oPjoBeHTKtUmSDqHPXSiDJMd0688AXgfsZRjk53e7XQjcMqsiJUk/6IjRu7AF2JlkE8PAv6GqPpLkfuD6JH8CfB64ZoZ1SpKWGBngVbUbOGWZ9ocYXg+XJK0Dn8SUpEYZ4JLUKANckhplgEtSowxwSWpUn9sIdTgZa3KSmnoZktafI3BJapQjcK2rumLRxhVj/HZR/nahpy9H4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqP6vJX+eUluT3J/kvuSXNK1X5Hk0SS7uuXs2ZcrSTqoz2RWB4C3V9XnkjwLuDvJbd1nV1fVn82uPEnSSvq8lX4fsK9bfzzJXuD4WRcmSTq0VV0DT7IVOAW4q2u6OMnuJNcmOXaFY7YnmU8yv7CwMFGxEkCop5aw6kXaKHoHeJJnAjcBb6uqbwPvBV4IbGM4Qn/XcsdV1Y6qmququcFgMIWSJUnQM8CTHMkwvD9YVTcDVNVjVfVkVX0PeB9w6uzKlCQt1eculADXAHur6t2L2rcs2u08YM/0y5MkraTPXSivAN4A3JtkV9f2DuCCJNsYvjH3YeDNM6lQkrSsPneh3Aks96efj06/nKeXXLn6v6j5BkhJB/kkpiQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RG9ZkL5Wll0vmiy2fdJa0RR+CS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRvV5K/3zktye5P4k9yW5pGt/bpLbkjzQfT129uVKkg7qMwI/ALy9qk4CTgPekuQk4DLgE1X1IuAT3bYkaY2MDPCq2ldVn+vWHwf2AscD5wA7u912AufOqkipKcn4i7QKq7oGnmQrcApwF3BcVe3rPvoqcNwKx2xPMp9kfmFhYYJSJUmL9Q7wJM8EbgLeVlXfXvxZVRWw7DROVbWjquaqam4wGExUrCTpKb0CPMmRDMP7g1V1c9f8WJIt3edbgP2zKVGStJw+d6EEuAbYW1XvXvTRrcCF3fqFwC3TL0+StJI+84G/AngDcG+SXV3bO4CrgBuSXAR8GfiV2ZQobXw5eAVyzL9jOg/909PIAK+qO1n5x+o10y1HktSXT2JKUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjerzVvprk+xPsmdR2xVJHk2yq1vOnm2ZkqSl+ozArwPOXKb96qra1i0fnW5ZkqRRRgZ4Vd0BfGMNapEkrcIk18AvTrK7u8Ry7Eo7JdmeZD7J/MLCwgSnkyQtNm6Avxd4IbAN2Ae8a6Udq2pHVc1V1dxgMBjzdJKkpY4Y56CqeuzgepL3AR+ZWkXSYSRXZtXH1AzqkJYz1gg8yZZFm+cBe1baV5I0GyNH4Ek+BJwObE7yCHA5cHqSbQwHGw8Db55hjZKkZYwM8Kq6YJnma2ZQiyRpFXwSU5IaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqrCcxm5HVP0Xnc3SSWuEIXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNGhngSa5Nsj/JnkVtz01yW5IHuq/HzrZMSdJSfWYjvA54D/CBRW2XAZ+oqquSXNZtXzr98p6SK1c/s6DzCkrayEaOwKvqDuAbS5rPAXZ26zuBc6dcl6TDRTLZopkZ9xr4cVW1r1v/KnDclOqRJPU08R8xq6o4xNWKJNuTzCeZX1hYmPR0kqTOuAH+WJItAN3X/SvtWFU7qmququYGg8GYp5MkLTVugN8KXNitXwjcMp1yJEl99bmN8EPAp4GXJHkkyUXAVcDrkjwAvLbbliStoZG3EVbVBSt89Jop1yJJWgWfxJSkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEb1eaGDpA3CF6NsLI7AJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqokfpkzwMPA48CRyoqrlpFCVJGm0ac6G8uqq+NoV/R5K0Cl5CkaRGTRrgBfxzkruTbF9uhyTbk8wnmV9YWJjwdJKkgyYN8FdW1cuAs4C3JHnV0h2qakdVzVXV3GAwmPB0kqSDJgrwqnq0+7of+DBw6jSKkiSNNnaAJ/nRJM86uA78ErBnWoVJkg5tkrtQjgM+nOTgv/N3VfXxqVQlSRpp7ACvqoeAk6dYiyRpFbyNUJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqGrMRStL3CbV4Y9WqRu8jR+CS1CwDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJatREAZ7kzCRfSPJgksumVZQkabSxAzzJJuAvgbOAk4ALkpw0rcIkSYc2yQj8VODBqnqoqv4XuB44ZzplSZJGmWQ+8OOB/1y0/Qjw80t3SrId2N5tPpHkCxOcc1XGmIa4z1Gbga+tePR4J+1to/Vpo/UHNl6fNlp/ZuiQfZrQTy7XOPMXOlTVDmDHrM+zVpLMV9XcetcxTRutTxutP7Dx+rTR+gPr06dJLqE8Cjxv0fYJXZskaQ1MEuD/BrwoyQuSHAX8KnDrdMqSJI0y9iWUqjqQ5GLgn4BNwLVVdd/UKjt8bZjLQYtstD5ttP7AxuvTRusPrEOfUr49VJKa5JOYktQoA1ySGmWAr2DUNAFJnp/k9iSfT7I7ydnrUWdfSa5Nsj/JnhU+T5K/6Pq7O8nL1rrG1ejRn1/v+nFvkk8lOXmta1ytUX1atN/LkxxIcv5a1TaOPv1JcnqSXUnuS/Kva1nfOHr83D0nyT8muafr05tmWlBVuSxZGP5R9ovATwFHAfcAJy3ZZwfw2936ScDD6133iD69CngZsGeFz88GPsbwCYzTgLvWu+YJ+/OLwLHd+lmHe3/69KnbZxPwSeCjwPnrXfOE36NjgPuB53fbP77eNU+hT+8A3tmtD4BvAEfNqh5H4MvrM01AAc/u1p8D/Nca1rdqVXUHwx+mlZwDfKCGPgMck2TL2lS3eqP6U1WfqqpvdpufYficwmGtx/cI4K3ATcD+2Vc0mR79+TXg5qr6Srf/RuhTAc9KEuCZ3b4HZlWPAb685aYJOH7JPlcAv5HkEYajobeuTWkz06fPrbqI4W8XTUtyPHAe8N71rmVKXgwcm+Rfktyd5I3rXdAUvAd4KcMB3b3AJVX1vVmdzAAf3wXAdVV1AsPLD3+bxP+eh5kkr2YY4Jeudy1T8OfApbMMhDV2BPBzwC8Drwf+IMmL17ekib0e2AX8BLANeE+SZx/6kPHNfC6URvWZJuAi4EyAqvp0kqMZTmZz2P8auIINNzVCkp8F3g+cVVVfX+96pmAOuH742zmbgbOTHKiqf1jfssb2CPD1qvoO8J0kdwAnA/+xvmVN5E3AVTW8CP5gki8BJwKfncXJHDEur880AV8BXgOQ5KXA0cDCmlY5XbcCb+zuRjkN+O+q2rfeRY0ryfOBm4E3VFXLgfD/quoFVbW1qrYCNwK/03B4A9wCvDLJEUl+hOFspnvXuaZJLc6F44CXAA/N6mSOwJdRK0wTkOSPgPmquhV4O/C+JL/L8A8Xv9n9X/ewlORDwOnA5u66/eXAkQBV9dcMr+OfDTwI/A/DkcRhq0d//hD4MeCvuhHrgTrMZ7/r0aemjOpPVe1N8nFgN/A94P1VdchbKNdbj+/RHwPXJbmX4R1dl1bVrKaY9VF6SWqVl1AkqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrU/wGTdmEsXLg07QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d1a26358-7b5d-418d-b0ba-7622dee281c1"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa7411b3a50>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "05300fc3-7126-4486-dce0-bb09a92732b9"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.        , 0.07070707, 0.23232323, 0.47474747,\n",
              "         0.66666667, 0.81818182, 0.90909091, 0.96969697, 1.        ],\n",
              "        [0.02      , 0.12      , 0.3       , 0.42      , 0.64      ,\n",
              "         0.74      , 0.88      , 1.        , 1.        , 1.        ]]),\n",
              " array([0.68557554, 0.80841051, 0.93124549, 1.05408047, 1.17691545,\n",
              "        1.29975043, 1.42258541, 1.54542039, 1.66825537, 1.79109035,\n",
              "        1.91392533]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xENlBUUxfTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "69bda00a-660a-4238-c2a6-a738055cf7aa"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r_squared = 0.9025425772317928\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KukfpGTTKlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "8035127b-4036-4a7d-cd57-12ba79310005"
      },
      "source": [
        "df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.902543</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.359778</td>\n",
              "      <td>3 layers of Convolution: 32, 64, 128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    N1  N2  ...  loss test                                Details\n",
              "0  200  10  ...   1.359778  3 layers of Convolution: 32, 64, 128 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHa1j4HT9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "52eca8ad-bebb-465e-fbc0-4c359540f264"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.68557554 0.80841051 0.93124549 1.05408047 1.17691545 1.29975043\n",
            " 1.42258541 1.54542039 1.66825537 1.79109035 1.91392533]\n",
            "[[ 0.          0.          7.07070707 16.16161616 24.24242424 19.19191919\n",
            "  15.15151515  9.09090909  6.06060606  3.03030303]\n",
            " [ 2.         10.         18.         12.         22.         10.\n",
            "  14.         12.          0.          0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53741274-9eab-4572-c1a0-da176329315b"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200.00000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "b9c55eb3-6f07-4248-96ff-708b0d059cc4"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa73ba32550>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAR/0lEQVR4nO3df5DV1XnH8fcjP8K0EiWwIIJ0kZAoRCGySlKZjpFqCM7EOGOI2hpMdTBandjkD1GnhTTOhCQmVpMaBxNHazDGGDE62lRjsY6JxrIRBbONsSniKgqiY9JUIcjTP/bCIO5y7+7e3btn9/2a2dnvz3ufs8t+OPd7z/fcyEwkSeU5oNEFSJJ6xgCXpEIZ4JJUKANckgplgEtSoQxwSSpU1QCPiMMiYk1E/Coino6Iz1W2L4+IFyJiXeVrYd+XK0naLaqNA4+IicDEzPxlRIwGWoFPAIuA/83Mq/q+TEnSvoZXOyAzNwObK8u/j4g2YFJPnmzcuHHZ3Nzck1MlachqbW19JTOb9t1eNcD3FhHNwAeBXwDHAxdFxKeBtcAXMvO1/Z3f3NzM2rVru/OUkjTkRcRznW2v+U3MiDgQ+BFwSWb+Dvg2MA2YTUcP/etdnLckItZGxNqtW7d2u3BJUudqCvCIGEFHeK/KzDsBMvPlzHwrM3cBNwDHdXZuZq7MzJbMbGlqescrAElSD9UyCiWA7wJtmfmNvbZP3Ouw04AN9S9PktSVWq6BHw+cDayPiHWVbZcDZ0bEbCCBjcD5fVKhpEHjj3/8I+3t7bz55puNLmVAGjVqFJMnT2bEiBE1HV/LKJRHgOhk133drE3SENfe3s7o0aNpbm6m48W9dstMtm3bRnt7O1OnTq3pHO/ElNRv3nzzTcaOHWt4dyIiGDt2bLdenRjgkvqV4d217v5sDHBJQ8qBBx7Y6BIAOOGEE3p9X0y3buSRpHpqXnpvXR9v44pT6vp4A50BrgGpJ3/YQ+2PV73z0EMPsWzZMg4++GDWr1/PokWLOOqoo7jmmmt44403uOuuu5g2bRr33HMPV155JTt27GDs2LGsWrWKCRMmsHXrVs466yxefPFFPvzhD/PAAw/Q2trKuHHj+N73vse1117Ljh07mDt3Ltdddx3Dhg2rexu8hCJpyHryySe5/vrraWtr45ZbbuGZZ57h8ccf57zzzuOb3/wmAPPmzeOxxx7jiSee4IwzzuCrX/0qAF/84hc58cQTefrppzn99NPZtGkTAG1tbfzgBz/gZz/7GevWrWPYsGGsWrWqT+q3By5pyDr22GOZOLHjnsRp06Zx8sknA3DUUUexZs0aoGPo46c+9Sk2b97Mjh079gzxe+SRR1i9ejUACxYsYMyYMQA8+OCDtLa2cuyxxwLwxhtvMH78+D6p3wCXNGS9613v2rN8wAEH7Fk/4IAD2LlzJwAXX3wxn//85/n4xz/OQw89xPLly/f7mJnJ4sWL+fKXv9xnde/mJRRJ2o/XX3+dSZM6ZtC++eab92w//vjjuf322wG4//77ee21jslY58+fzx133MGWLVsAePXVV3nuuU4nE+w1A1yS9mP58uV88pOfZM6cOYwbN27P9mXLlnH//ffzgQ98gB/+8IcccsghjB49mhkzZnDllVdy8sknc/TRR3PSSSexefPmdzzuzp073/YKoCeqfiJPPbW0tKTzgasWjkIZnNra2jjyyCMbXUZdbN++nWHDhjF8+HAeffRRLrjgAtatW1f9xMq5733ve9mwYQMHHXTQ2/Z19jOKiNbMbNn3cbwGLkk9sGnTJhYtWsSuXbsYOXIkN9xwQ03nrV27lrPPPpsLL7zwHeHdXQa4JPXA9OnTeeKJJ7p9XktLC21tbXWpwWvgklQoA1ySCmWAS1KhDHBJKpQBLmlIeemllzjjjDOYNm0ac+bMYeHChTzzzDNExJ75TwAuuugibrrpJgDOOeccJk2axPbt2wF45ZVXaG5ubkD1b+coFEmNs7x3w+je+Xiv73d3ZnLaaaexePFibrvtNqBjQquXX36Z8ePHc80113D++eczcuTId5w7bNgwbrzxRi644IL61twL9sAlDRlr1qxhxIgRfPazn92zbdasWRx22GE0NTUxf/78t90uv7dLLrmEq6++es8cKQOBAS5pyNiwYQNz5szpcv+ll17KVVddxVtvvfWOfVOmTGHevHnccsstfVlitxjgklRx+OGHM3fuXG699dZO91922WV87WtfY9euXf1cWecMcElDxsyZM2ltbd3vMZdffjlf+cpX6GyeqOnTpzN79uw9sxA2mgEuacg48cQT2b59OytXrtyz7amnnuL555/fs37EEUcwY8YM7rnnnk4f44orruCqq67q81prYYBLGjIigtWrV/PTn/6UadOmMXPmTC677DIOOeSQtx13xRVX0N7e3uljzJw5k2OOOaY/yq3KYYSSGqfKsL++cOihh3Z6CWTDhg17lmfNmvW269y7x4Pvduedd/ZZfd1hD1ySCmWAS1KhDHBJKpQBLqlf9efHOJamuz8bA1xSvxk1ahTbtm0zxDuRmWzbto1Ro0bVfI6jUCT1m8mTJ9Pe3s7WrVsbXcqANGrUKCZPnlzz8Qa4pH4zYsQIpk6d2ugyBg0voUhSoaoGeEQcFhFrIuJXEfF0RHyusv09EfFARPym8n1M35crSdqtlh74TuALmTkD+BDwtxExA1gKPJiZ04EHK+uSpH5SNcAzc3Nm/rKy/HugDZgEnArsnvn8ZuATfVWkJOmdunUNPCKagQ8CvwAmZObmyq6XgAl1rUyStF81B3hEHAj8CLgkM3+3977sGNTZ6cDOiFgSEWsjYq1DhySpfmoK8IgYQUd4r8rM3dNwvRwREyv7JwJbOjs3M1dmZktmtjQ1NdWjZkkStY1CCeC7QFtmfmOvXXcDiyvLi4Ef1788SVJXarmR53jgbGB9RKyrbLscWAHcHhHnAs8Bi/qmRElSZ6oGeGY+AkQXu+fXtxxJUq28E1OSCmWAS1KhDHBJKpQBLkmFcjpZaR/NS+/t9jkbV5zSB5VI+2cPXJIKZYBLUqEMcEkqlAEuSYUywCWpUAa4JBXKAJekQhngklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCgDXJIKNbzRBWjgal56b7fP2bjilD6oRFJn7IFLUqEMcEkqlAEuSYWqGuARcWNEbImIDXttWx4RL0TEusrXwr4tU5K0r1p64DcBCzrZfnVmzq583VffsiRJ1VQN8Mx8GHi1H2qRJHVDb66BXxQRT1UusYypW0WSpJr0dBz4t4EvAVn5/nXgbzo7MCKWAEsApkyZ0sOnk4aO7o6/d+z90NWjHnhmvpyZb2XmLuAG4Lj9HLsyM1sys6WpqamndUqS9tGjAI+IiXutngZs6OpYSVLfqHoJJSK+D5wAjIuIdmAZcEJEzKbjEspG4Pw+rFGS1ImqAZ6ZZ3ay+bt9UIskqRu8E1OSCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgplgEtSoQxwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqEMcEkqlAEuSYUywCWpUAa4JBXKAJekQhngklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVanijC5DqZvlB3Tz+9b6pQ+on9sAlqVAGuCQVygCXpEIZ4JJUqKoBHhE3RsSWiNiw17b3RMQDEfGbyvcxfVumJGlftfTAbwIW7LNtKfBgZk4HHqysS5L6UdUAz8yHgVf32XwqcHNl+WbgE3WuS5JURU+vgU/IzM2V5ZeACXWqR5JUo16/iZmZCWRX+yNiSUSsjYi1W7du7e3TSZIqehrgL0fERIDK9y1dHZiZKzOzJTNbmpqaevh0kqR99TTA7wYWV5YXAz+uTzmSpFrVMozw+8CjwPsjoj0izgVWACdFxG+Av6ysS5L6UdXJrDLzzC52za9zLZKkbvBOTEkqlAEuSYUywCWpUH6gw2DkBxuoh5qX3tut4zeuOKWPKlEt7IFLUqEMcEkqlAEuSYUywCWpUAa4JBXKAJekQhngklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgrlBzoMcN2dYB9g46g+KEQDlx/gMWTZA5ekQhngklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVyht5VF/eVDK01PH33d2b1jauOKV7zz0I2QOXpEIZ4JJUKANckgplgEtSoXr1JmZEbAR+D7wF7MzMlnoUJUmqrh6jUD6Sma/U4XEkSd3gJRRJKlRvAzyB+yOiNSKW1KMgSVJtensJZV5mvhAR44EHIuK/MvPhvQ+oBPsSgClTpvTy6QriDS1Di79vNUCveuCZ+ULl+xZgNXBcJ8eszMyWzGxpamrqzdNJkvbS4wCPiD+NiNG7l4GTgQ31KkyStH+9uYQyAVgdEbsf59bM/EldqpIkVdXjAM/M3wKz6liLJKkbHEYoSYUywCWpUAa4JBXKAJekQhngklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVygCXpELV4zMxJalozUvv7dbxG1ec0keVdI89cEkqlAEuSYUywCWpUAa4JBXKAJekQhngklQoA1ySCmWAS1KhDHBJKpQBLkmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgplgEtSoQb3BzosP6ibx7/eN3VIUh+wBy5JhTLAJalQBrgkFcoAl6RC9SrAI2JBRPw6Ip6NiKX1KkqSVF2PAzwihgH/DHwMmAGcGREz6lWYJGn/etMDPw54NjN/m5k7gNuAU+tTliSpmt4E+CTg+b3W2yvbJEn9IDKzZydGnA4syMzzKutnA3Mz86J9jlsCLKmsvh/4dc/L7RfjgFcaXUSdDJa2DJZ2wOBpy2BpB5TRlj/LzKZ9N/bmTswXgMP2Wp9c2fY2mbkSWNmL5+lXEbE2M1saXUc9DJa2DJZ2wOBpy2BpB5Tdlt5cQvlPYHpETI2IkcAZwN31KUuSVE2Pe+CZuTMiLgL+DRgG3JiZT9etMknSfvVqMqvMvA+4r061DBTFXO6pwWBpy2BpBwyetgyWdkDBbenxm5iSpMbyVnpJKtSQDfBq0wBExJSIWBMRT0TEUxGxsBF1VhMRN0bElojY0MX+iIhrK+18KiKO6e8aa1FDO/6qUv/6iPh5RMzq7xprVa0tex13bETsrAzJHXBqaUdEnBAR6yLi6Yj4j/6srztq+Pd1UETcExFPVtrymf6usUcyc8h90fGm638DhwMjgSeBGfscsxK4oLI8A9jY6Lq7aMtfAMcAG7rYvxD4VyCADwG/aHTNPWzHnwNjKssfG6jtqKUtlWOGAf9Ox3tIpze65h7+Tg4GfgVMqayPb3TNvWjL5cBXKstNwKvAyEbXXe1rqPbAa5kGIIF3V5YPAl7sx/pqlpkP0/GPrSunAv+SHR4DDo6Iif1TXe2qtSMzf56Zr1VWH6PjvoMBqYbfCcDFwI+ALX1fUc/U0I6zgDszc1Pl+JLbksDoiAjgwMqxO/ujtt4YqgFeyzQAy4G/joh2OnpJF/dPaXU3GKc8OJeOVxVFiohJwGnAtxtdSy+9DxgTEQ9FRGtEfLrRBfXCt4Aj6eiorQc+l5m7GltSdUM1wGtxJnBTZk6m4zLELRHhz6vBIuIjdAT4pY2upRf+Cbi0hICoYjgwBzgF+Cjw9xHxvsaW1GMfBdYBhwKzgW9FxLv3f0rjDe4PNe5aLdMAnAssAMjMRyNiFB1zJgzYl4ldqGnKgxJExNHAd4CPZea2RtfTCy3AbR2v1hkHLIyInZl5V2PL6rZ2YFtm/gH4Q0Q8DMwCnmlsWT3yGWBFdlwEfzYi/gc4Ani8sWXt31DtUdYyDcAmYD5ARBwJjAK29muV9XE38OnKaJQPAa9n5uZGF9VdETEFuBM4OzNLDIg9MnNqZjZnZjNwB3BhgeEN8GNgXkQMj4g/AeYCbQ2uqaf2/nufQMfEe79taEU1GJI98OxiGoCI+EdgbWbeDXwBuCEi/o6ONzjOqfzvPKBExPeBE4Bxlev1y4ARAJl5PR3X7xcCzwL/R0dPY8CpoR3/AIwFrqv0XHfmAJ2AqIa2FKFaOzKzLSJ+AjwF7AK+k5n7HTrZKDX8Tr4E3BQR6+kYsXVpZg70GQq9E1OSSjVUL6FIUvEMcEkqlAEuSYUywCWpUAa4JBXKAJekQhngklQoA1ySCvX/fc5/NWqXD0AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86ef59c-86df-42d5-89a8-edc0fa9181fa"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.0136588738827657,\n",
              "  1.3384498643738487,\n",
              "  1.2241743928678164,\n",
              "  1.2810955363139882,\n",
              "  1.4897169283032898,\n",
              "  1.3469841688927182,\n",
              "  1.802936648279376,\n",
              "  1.1101783096888704,\n",
              "  1.349345229721172,\n",
              "  0.9587903583676608,\n",
              "  1.2539740179716348,\n",
              "  1.1606409601292735,\n",
              "  1.3071677279655385,\n",
              "  1.2396774300177211,\n",
              "  1.4634168627716928,\n",
              "  1.369947111730825,\n",
              "  1.5945718456175375,\n",
              "  1.2293637946517857,\n",
              "  1.6281537802488464,\n",
              "  1.9139253303624628,\n",
              "  1.3284238815238665,\n",
              "  1.2236542422631285,\n",
              "  1.1055812783082735,\n",
              "  1.2084724894722394,\n",
              "  1.1396070970426018,\n",
              "  1.2610615335399848,\n",
              "  1.4729562736988213,\n",
              "  1.428191076384995,\n",
              "  1.2880338220675407,\n",
              "  1.474252319944901,\n",
              "  1.697826354277848,\n",
              "  1.2529582429827641,\n",
              "  1.034176589165282,\n",
              "  1.1861406733319428,\n",
              "  1.3076546595257188,\n",
              "  1.016167934339702,\n",
              "  1.607692842495848,\n",
              "  1.5322707725763225,\n",
              "  1.6985761120332168,\n",
              "  1.3690173884396646,\n",
              "  1.1334454996327699,\n",
              "  1.5351763407845973,\n",
              "  1.09458595441189,\n",
              "  1.6933208363283037,\n",
              "  1.2711180048559307,\n",
              "  1.1737313097142148,\n",
              "  1.1644741796806608,\n",
              "  1.59377316194829,\n",
              "  1.6207076173044417,\n",
              "  1.110751600875899,\n",
              "  1.329860792578359,\n",
              "  1.480285532081299,\n",
              "  1.3134837582232015,\n",
              "  1.224694322554825,\n",
              "  1.3952717527062835,\n",
              "  1.3212158853994709,\n",
              "  1.3460385849440337,\n",
              "  1.8732453617425853,\n",
              "  1.0427591146587158,\n",
              "  1.016167934339702,\n",
              "  0.9373021315815206,\n",
              "  1.4935580612671222,\n",
              "  1.1158979678944616,\n",
              "  1.1877497276642752,\n",
              "  1.2095256247391792,\n",
              "  1.1249889365974903,\n",
              "  1.4246205931081612,\n",
              "  1.3782864001160509,\n",
              "  1.2973907191512837,\n",
              "  1.411150823960995,\n",
              "  1.2815923738491737,\n",
              "  1.1600923233885598,\n",
              "  1.2324669475767085,\n",
              "  1.341300666036808,\n",
              "  1.3713405148152793,\n",
              "  1.6774562271083886,\n",
              "  1.2716187407449044,\n",
              "  1.540971041561482,\n",
              "  1.1769811488175403,\n",
              "  1.7172136691765054,\n",
              "  1.5368341990871126,\n",
              "  1.0597156592484673,\n",
              "  1.4214890634453377,\n",
              "  1.169928421139644,\n",
              "  1.6656497134685673,\n",
              "  1.4922787821790537,\n",
              "  1.103852455861539,\n",
              "  1.2565098628628435,\n",
              "  1.4210411387253952,\n",
              "  1.7866201439172942,\n",
              "  1.540557857201846,\n",
              "  1.2771138777750963,\n",
              "  1.6495189926457479,\n",
              "  1.2776122636975893,\n",
              "  1.6340083614564633,\n",
              "  1.5434478249035466,\n",
              "  1.2939513133525307,\n",
              "  1.1474012764748687,\n",
              "  1.6332289631953525],\n",
              " [0.8839576145686846,\n",
              "  1.5796494075804377,\n",
              "  1.1589432348955973,\n",
              "  0.9281175798097757,\n",
              "  1.1154445422241994,\n",
              "  1.4965266736356846,\n",
              "  0.8741056239672461,\n",
              "  1.387189845938759,\n",
              "  0.6855755351819821,\n",
              "  0.9962324125775431,\n",
              "  1.3023261945525673,\n",
              "  1.1822266439259996,\n",
              "  1.251019877819206,\n",
              "  1.2117131336648257,\n",
              "  1.6039808427204765,\n",
              "  1.5203316476708542,\n",
              "  1.054458532755461,\n",
              "  1.5124201339962329,\n",
              "  1.5777951835318402,\n",
              "  0.9977522383361532,\n",
              "  1.5203600813377716,\n",
              "  1.2884075068710137,\n",
              "  0.9464934862421213,\n",
              "  0.9905508524166737,\n",
              "  1.325402776913876,\n",
              "  1.0263723954832547,\n",
              "  1.267773576276364,\n",
              "  1.4761007547718934,\n",
              "  1.5630711325300657,\n",
              "  1.4081444455981806,\n",
              "  1.5564004128348534,\n",
              "  1.1862005262040813,\n",
              "  0.9034005276219993,\n",
              "  1.248033140876009,\n",
              "  0.9672273240832585,\n",
              "  1.2918381939681616,\n",
              "  0.9217511910354489,\n",
              "  1.0841832825386388,\n",
              "  1.0239407909426643,\n",
              "  1.502409203458156,\n",
              "  1.6530074233570526,\n",
              "  1.2884510334164176,\n",
              "  1.3594650564883732,\n",
              "  1.4752771545736296,\n",
              "  1.0565107878788398,\n",
              "  1.2313164612934693,\n",
              "  1.0518381550918576,\n",
              "  1.2003535051767011,\n",
              "  1.0989363689529155,\n",
              "  0.9756941562244482]]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "82b1404d-7f91-40df-f29d-8a47cee3789d"
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4,1.6, 1.8,2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa73cfeed50>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8f11e607-0e3b-4ea3-d42d-00705f3c7caf"
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e5c721-0718-48b1-9322-6cf2dc5c46b8"
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.02020202, 24.24242424, 37.37373737, 20.2020202 , 13.13131313,\n",
              "        3.03030303])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42e2757-1ecb-4e36-ab1d-8beea349f47a"
      },
      "source": [
        "bins_list"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "83df230f-726a-4eba-e1bc-1503fbb112ab"
      },
      "source": [
        "df"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "      <th>0.8</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.4</th>\n",
              "      <th>1.6</th>\n",
              "      <th>1.8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.902543</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.359778</td>\n",
              "      <td>3 layers of Convolution: 32, 64, 128</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    N1  N2       R^2  acc train  acc test  ...   1.0   1.2   1.4  1.6  1.8\n",
              "0  200  10  0.902543        1.0  0.714286  ...  22.0  26.0  24.0  4.0  0.0\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e2bb9332-b396-42c1-886f-b2fa545637b9"
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_41460490-d66c-4ab0-9d3b-b1e789efe118\", \"output.xlsx\", 5238)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}