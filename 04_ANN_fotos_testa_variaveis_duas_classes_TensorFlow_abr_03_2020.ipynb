{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_ANN_fotos_testa_variaveis_duas_classes_TensorFlow_abr_03_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/04_ANN_fotos_testa_variaveis_duas_classes_TensorFlow_abr_03_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js5iK5Sw_oZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rede neural com duas classes grao=2 e nao grao=1+3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPzMNtMQeqs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score \n",
        "from mpl_toolkits.mplot3d import Axes3D, axes3d\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import re\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkPGXHfRpji7",
        "colab_type": "code",
        "outputId": "2475bff1-4c20-4040-da2e-40af4bf33afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_mar_2020 #clonar do Github\n",
        "%cd marquesgabi_mar_2020\n",
        "\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_mar_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_mar_2020\n",
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_mar_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYWpJccwpn_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqImBAP-3H6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Digite os parametros { run: \"auto\", vertical-output: true }\n",
        "#@markdown Enter neurons hidden layer\n",
        "N_Hidden=22  #@param {type:\"number\"}\n",
        "#@markdown Activation function\n",
        "\n",
        "Ativa='tanh'#@param [\"tanh\", \"identity\", \"logistic\",\"relu\"] {allow-input: true}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vZxttY2XZ2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# funcao normatiza dados\n",
        "def Normatiza(x):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x[i].max()\n",
        "        min_x=x[i].min()\n",
        "        a=(max_x+min_x)/2\n",
        "        b=(max_x-min_x)/2\n",
        "        x[i]=(x[i]-a)/b\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quDi173pXomN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# funcao retorna os dados a forma original\n",
        "def Original(x,x_old):\n",
        "    strings=list(x)\n",
        "    for i in strings:\n",
        "        max_x=x_old[i].max()\n",
        "        min_x=x_old[i].min()\n",
        "        a=(max_x+min_x)/2\n",
        "        b=(max_x-min_x)/2\n",
        "        x[i]=x[i]*b+a\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UxbasKHkWsQ",
        "colab_type": "code",
        "outputId": "2b2f2720-032e-4b7c-cdc4-355cc9c9a9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "df_contraste= pd.read_csv('Contraste_Completo_mar_2020.csv') \n",
        "#df_contraste= np.delete(df_contraste, 0, axis=1) # delete first colunm\n",
        "del df_contraste['Unnamed: 0']\n",
        "Nomes=list(df_contraste.columns)\n",
        "#del df_contraste['Unnamed: 0'] # delete first colunm\n",
        "print(Nomes)\n",
        "print(df_contraste.head())\n",
        "print(df_contraste.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Type', 'ASM', 'constrast', 'correl', 'variance', 'inv diff mom', 'sum aveg', 'sum var', 'sum entropy', 'entropy', 'dif var', 'dif entropy', 'IMC1', 'IMC2', 'colors']\n",
            "   Type      ASM  constrast   correl  ...  dif entropy     IMC1     IMC2  colors\n",
            "0     1  0.05766   93.16340  0.15346  ...      2.72958 -0.64142  0.98102  0.4125\n",
            "1     1  0.05013  402.45588  0.32031  ...      2.88069 -0.79959  0.99822  0.4100\n",
            "2     1  0.05287  154.89461  0.28263  ...      2.93133 -0.74008  0.99509  0.4225\n",
            "3     1  0.05011  397.55801  0.21760  ...      2.99470 -0.78154  0.99769  0.5300\n",
            "4     1  0.05408  108.01144  0.34926  ...      2.80948 -0.72303  0.99423  0.4900\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "(720, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXeE24jTqNPo",
        "colab_type": "code",
        "outputId": "d62b5b9c-363d-4d50-f36c-c6465ed402ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "df_fracionado= pd.read_csv('Contraste_Fracionado_mar_2020.csv') \n",
        "del df_fracionado['Unnamed: 0']\n",
        "Nomes_fracionado=list(df_fracionado.columns)\n",
        "print(df_fracionado)\n",
        "#df_fracionado= np.delete(df_fracionado, 0, axis=1) # delete first colunm\n",
        "#del df_fracionado['Unnamed: 0'] # delete first colunm\n",
        "#del df_fracionado['Type'] # delete first colunm\n",
        "\n",
        "print(df_fracionado.head())\n",
        "#print(df_fracionado.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     N_peaks  Media_proem        Area  ...      Mode       Mean          Sd\n",
            "0          2     13.64931  1407.70370  ...   7.52778   93.16340   101.41799\n",
            "1          2    268.50231  6954.06944  ...  36.37500  402.45588   374.61667\n",
            "2          2     16.58218  2372.18981  ...  46.93750  154.89461   109.03101\n",
            "3          2      6.75694  5663.77546  ...  77.49306  397.55801   451.88121\n",
            "4          3     25.91667  1681.69907  ...  10.22917  108.01144    94.42290\n",
            "..       ...          ...         ...  ...       ...        ...         ...\n",
            "715        2      2.82755  2325.76157  ...  10.03472  185.27614   346.45698\n",
            "716        2     10.04282  1243.38426  ...   8.18056   88.03431    95.03825\n",
            "717        3     12.63426   466.21296  ...   6.06944   29.09273    21.04542\n",
            "718        2     21.59028  4145.96991  ...  24.84028  563.94812  1900.11526\n",
            "719        0      0.00000  5489.27083  ...  19.20139  405.43096   487.97502\n",
            "\n",
            "[720 rows x 10 columns]\n",
            "   N_peaks  Media_proem        Area  ...      Mode       Mean         Sd\n",
            "0        2     13.64931  1407.70370  ...   7.52778   93.16340  101.41799\n",
            "1        2    268.50231  6954.06944  ...  36.37500  402.45588  374.61667\n",
            "2        2     16.58218  2372.18981  ...  46.93750  154.89461  109.03101\n",
            "3        2      6.75694  5663.77546  ...  77.49306  397.55801  451.88121\n",
            "4        3     25.91667  1681.69907  ...  10.22917  108.01144   94.42290\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuUrZMNmVuZB",
        "colab_type": "code",
        "outputId": "082bf80f-fd44-46ca-d12d-1d3c4132f7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#print(Nomes_contraste)\n",
        "print(Nomes_fracionado)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['N_peaks', 'Media_proem', 'Area', 'Width_peaks', 'Width_peaks_max', 'Width_peaks_min', 'Median', 'Mode', 'Mean', 'Sd']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljOhLeDav5__",
        "colab_type": "code",
        "outputId": "8fd42cf4-e2fe-4754-89db-aa709e098507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "#ANN_Completo é o dataframe que tem todas as variaveis juntas\n",
        "\n",
        "ANN_Completo = pd.concat([df_contraste, df_fracionado], axis=1)\n",
        "print(ANN_Completo.head())\n",
        "print(ANN_Completo.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Type      ASM  constrast   correl  ...     Median      Mode       Mean         Sd\n",
            "0     1  0.05766   93.16340  0.15346  ...   53.48611   7.52778   93.16340  101.41799\n",
            "1     1  0.05013  402.45588  0.32031  ...  256.77083  36.37500  402.45588  374.61667\n",
            "2     1  0.05287  154.89461  0.28263  ...  120.70833  46.93750  154.89461  109.03101\n",
            "3     1  0.05011  397.55801  0.21760  ...  149.81944  77.49306  397.55801  451.88121\n",
            "4     1  0.05408  108.01144  0.34926  ...   66.18750  10.22917  108.01144   94.42290\n",
            "\n",
            "[5 rows x 25 columns]\n",
            "(720, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gVOPf_LhXhb",
        "colab_type": "code",
        "outputId": "4e3a15e4-af61-4aba-8851-627ffce070a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "#Aqui iremos escolher quais variáveis iremos utilizar na ANN\n",
        "\n",
        "Colunms=['N_peaks', 'Media_proem', 'Area', 'Width_peaks', 'Width_peaks_max', 'Width_peaks_min', 'Median', 'Mode','Mean', 'Sd']\n",
        "\n",
        "#Colunms=['N_peaks', 'Media_proem', 'Area', 'Width_peaks', \n",
        "         # 'Width_peaks_max', 'Width_peaks_min', 'Median', \n",
        "          #'Mode', 'Mean', 'Sd']\n",
        "\n",
        "#'ASM', 'constrast', 'correl', 'variance', 'inv diff mom', 'sum aveg', 'sum var', 'sum entropy', 'entropy', 'dif var', 'dif entropy', 'IMC1', 'IMC2', 'colors'\n",
        "#'N_peaks', 'Media_proem', 'Area', 'Width_peaks', 'Width_peaks_max', 'Width_peaks_min', 'Median', 'Mode', 'Mean', 'Sd'\n",
        "\n",
        "\n",
        "del df_contraste['Type'] # delete first colunm\n",
        "\n",
        "Nomes_contraste=list(df_contraste.columns)\n",
        "for ii in Nomes_contraste:\n",
        "  Colunms.append(ii)\n",
        "#X=df.iloc[:,2:12]\n",
        "#y=df.iloc[:,1].astype(int)\n",
        "X=ANN_Completo[Colunms]\n",
        "print(X)\n",
        "#y=df['Type'].astype(int)\n",
        "y=ANN_Completo['Type']\n",
        "print(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     N_peaks  Media_proem        Area  ...     IMC1     IMC2  colors\n",
            "0          2     13.64931  1407.70370  ... -0.64142  0.98102  0.4125\n",
            "1          2    268.50231  6954.06944  ... -0.79959  0.99822  0.4100\n",
            "2          2     16.58218  2372.18981  ... -0.74008  0.99509  0.4225\n",
            "3          2      6.75694  5663.77546  ... -0.78154  0.99769  0.5300\n",
            "4          3     25.91667  1681.69907  ... -0.72303  0.99423  0.4900\n",
            "..       ...          ...         ...  ...      ...      ...     ...\n",
            "715        2      2.82755  2325.76157  ... -0.72472  0.99488  0.5300\n",
            "716        2     10.04282  1243.38426  ... -0.76055  0.99696  0.4400\n",
            "717        3     12.63426   466.21296  ... -0.71517  0.99219  0.5225\n",
            "718        2     21.59028  4145.96991  ... -0.71082  0.99428  0.5325\n",
            "719        0      0.00000  5489.27083  ... -0.73096  0.99265  0.5100\n",
            "\n",
            "[720 rows x 24 columns]\n",
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "715    3\n",
            "716    3\n",
            "717    3\n",
            "718    3\n",
            "719    3\n",
            "Name: Type, Length: 720, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPuT29HY0h6B",
        "colab_type": "code",
        "outputId": "fa1c76b4-1c5d-43fd-d55e-0c6b8466f865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(Colunms)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['N_peaks', 'Media_proem', 'Area', 'Width_peaks', 'Width_peaks_max', 'Width_peaks_min', 'Median', 'Mode', 'Mean', 'Sd', 'ASM', 'constrast', 'correl', 'variance', 'inv diff mom', 'sum aveg', 'sum var', 'sum entropy', 'entropy', 'dif var', 'dif entropy', 'IMC1', 'IMC2', 'colors']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_R9MQraX2K_",
        "colab_type": "code",
        "outputId": "a5a78caa-d737-4b7a-9f1d-bc740f3b3b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "\n",
        "# separa os dados variaveis de entrada em normatizados e originais\n",
        "X_OLD=[]\n",
        "X_OLD=X.copy()\n",
        "X=Normatiza(X)\n",
        "#print(X)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KotvGJ_5hx9",
        "colab_type": "code",
        "outputId": "2d93b746-b8a8-4c2e-fcc3-1c7e12336c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "print(y.ravel())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWa39a4s6S47",
        "colab_type": "code",
        "outputId": "26e207dd-fd81-4b2a-f12d-519d3ee6ec25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# esta parte encontra os indices do indefinido para depois \n",
        "# usar os indicies para unir indefinido e buraco\n",
        "\n",
        "Ind=[i for i, e in enumerate(y) if e == 3]\n",
        "print(Ind)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDoiL_NQ6CJZ",
        "colab_type": "code",
        "outputId": "17510dd2-7fa3-48ed-9f2a-bfdea48f0bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "# esta parte une indefinido e buraco no numero 1 e passa a ser uma so \n",
        "# classe por enquanto os dados nao estao balanceados \n",
        "# tem o dobro da classe 1 que a classe 2\n",
        "for i in Ind:\n",
        "  y[i]=1\n",
        "print(y.ravel())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grM2ZPKvmVNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ceb47b75-6f49-4266-84a6-be66715352ab"
      },
      "source": [
        "#Podemos colocar essa parte que automaticamente escolhe o número de neuronios da camada oculta nao é?????\n",
        "'''N=10\n",
        "M=10\n",
        "test=Original(y_test,Y_OLD)\n",
        "resist_obs_test=[]\n",
        "resist_obs_test=test['Resistence'].copy()\n",
        "Melhor=1e99 #toda vez que fizer o teste e o valor da iteracao der menor que o erro. r^2 nao costuma ser o melhor para calcular o erro. MSE=1/n(yexp-ycal)^2 \n",
        "ir=0\n",
        "jr=0\n",
        "for i in range(1,N): #numero de neuronios da primeira camada oculta\n",
        "    for j in range(1,M):\n",
        "        col_names=list(y_train)\n",
        "        clf=rede(i,j)\n",
        "        clf.fit(x_train, y_train)\n",
        "        y_calc_train=[]\n",
        "        y_calc_test=[]\n",
        "        y_calc_train=clf.predict(x_train)\n",
        "        y_calc_test=clf.predict(x_test)\n",
        "        y_calc_train=pd.DataFrame(y_calc_train)\n",
        "        y_calc_test=pd.DataFrame(y_calc_test)\n",
        "        y_calc_train.columns = col_names\n",
        "        y_calc_test.columns = col_names\n",
        "        y_calc_train=Original(y_calc_train,Y_OLD)\n",
        "        y_calc_test=Original(y_calc_test,Y_OLD)\n",
        "        resist_calc_test=[]\n",
        "        resist_calc_test=y_calc_test['Resistence'].copy()\n",
        "        mse=mean_squared_error(resist_obs_test,resist_calc_test)\n",
        "        R2=r2_score(resist_obs_test,resist_calc_test)\n",
        "        print(\"Neuronios=\",i,j,\"MSE teste=\",mse,\"R^2 teste=\",R2)\n",
        "        if(mse<Melhor):\n",
        "            Melhor=mse.copy()\n",
        "            ix=i\n",
        "            jx=j\n",
        "            R2r=R2\n",
        "print(\"\\n Melhor resposta:\")\n",
        "print(\"Neuronios=\",ix,jx,\"MSE teste=\",Melhor,\"R^2 teste=\",R2r)'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N=10\\nM=10\\ntest=Original(y_test,Y_OLD)\\nresist_obs_test=[]\\nresist_obs_test=test[\\'Resistence\\'].copy()\\nMelhor=1e99 #toda vez que fizer o teste e o valor da iteracao der menor que o erro. r^2 nao costuma ser o melhor para calcular o erro. MSE=1/n(yexp-ycal)^2 \\nir=0\\njr=0\\nfor i in range(1,N): #numero de neuronios da primeira camada oculta\\n    for j in range(1,M):\\n        col_names=list(y_train)\\n        clf=rede(i,j)\\n        clf.fit(x_train, y_train)\\n        y_calc_train=[]\\n        y_calc_test=[]\\n        y_calc_train=clf.predict(x_train)\\n        y_calc_test=clf.predict(x_test)\\n        y_calc_train=pd.DataFrame(y_calc_train)\\n        y_calc_test=pd.DataFrame(y_calc_test)\\n        y_calc_train.columns = col_names\\n        y_calc_test.columns = col_names\\n        y_calc_train=Original(y_calc_train,Y_OLD)\\n        y_calc_test=Original(y_calc_test,Y_OLD)\\n        resist_calc_test=[]\\n        resist_calc_test=y_calc_test[\\'Resistence\\'].copy()\\n        mse=mean_squared_error(resist_obs_test,resist_calc_test)\\n        R2=r2_score(resist_obs_test,resist_calc_test)\\n        print(\"Neuronios=\",i,j,\"MSE teste=\",mse,\"R^2 teste=\",R2)\\n        if(mse<Melhor):\\n            Melhor=mse.copy()\\n            ix=i\\n            jx=j\\n            R2r=R2\\nprint(\"\\n Melhor resposta:\")\\nprint(\"Neuronios=\",ix,jx,\"MSE teste=\",Melhor,\"R^2 teste=\",R2r)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi9gBj86i0V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Test Split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
        "                                                    #random_state=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoPO53S3bif2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a rede neural \n",
        "#N_Hidden=(22,22,22)\n",
        "\n",
        "#clf = MLPClassifier(solver='lbfgs',activation=Ativa,alpha=1e-5,\n",
        "                    #hidden_layer_sizes=N_Hidden,random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIlihyomimyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "eb79f802-90eb-4593-d91f-32a5edc925ba"
      },
      "source": [
        "# define a rede neural\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2216 - accuracy: 0.9337\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0976 - accuracy: 0.9696\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0694 - accuracy: 0.9778\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0511 - accuracy: 0.9838\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0421 - accuracy: 0.9860\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.9775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0717049241065979, 0.9775000214576721]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCd7bGM8bm04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# treina a rede neural\n",
        "#clf.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSXYEWkmbu1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# usa a rede neural treina em calculos para treino e teste\n",
        "#y_calc_train=clf.predict(X_train)\n",
        "#y_pred=clf.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuJNYvbGcjVE",
        "colab_type": "code",
        "outputId": "9905d03b-ce42-436f-f940-8c0a001bb47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Evaluating the Algorithm\n",
        "print(confusion_matrix(y, y_test))\n",
        "print(classification_report(y, y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bc5d6fa8c2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [720, 10000]",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: Current TensorFlow version is 2.2.0-rc2. To use TF 1.x instead,\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\nyou run \"import tensorflow\".\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2NNm47T9Aon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "[[31  5 15]\n",
        " [ 8 41 11]\n",
        " [12 12 27]]\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           1       0.61      0.61      0.61        51\n",
        "           2       0.71      0.68      0.69        60\n",
        "           3       0.51      0.53      0.52        51\n",
        "\n",
        "    accuracy                           0.61       162\n",
        "   macro avg       0.61      0.61      0.61       162\n",
        "weighted avg       0.61      0.61      0.61       162\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzmsl4clwqy1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_2coHl9nOW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}