{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_Amostra8_r_squared_jul_29_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/PSD_histogram_CNN_B_Amostra8_r_squared_jul_29_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZEvJvfoibE4",
        "outputId": "5d53f465-f0da-4060-8182-9a92c2942916"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VcTdaNVh9EE",
        "outputId": "50a25a28-7b72-446d-fead-cd6d1c28e096"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7SRrc8mH2N",
        "outputId": "1465f8ee-7665-4c04-9e32-df271f3617ee"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "320e2f4d-ac98-4497-cb1a-87c9dff5378b"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[9] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgqAnaFyCjp",
        "outputId": "d3b5906c-427e-4e0f-df12-21b5bc11756e"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN5MN5a_v4np",
        "outputId": "a2051465-56c0-4fe8-89dd-379a7cb41632"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     132   75.520660   78.283752  ...   74.650146   76.238754   78.292938\n",
            "1     111   68.502144   73.171249  ...    4.061765    0.891811    0.000000\n",
            "2     172   97.262848   97.586266  ...   20.719307   25.994053   34.431046\n",
            "3     196   39.734692   40.918365  ...   54.591835   77.285713   79.795914\n",
            "4     185    2.192520   34.437313  ...   70.243126   71.859077   74.512108\n",
            "5     105   62.911110   67.453339  ...   83.368896   86.053345   91.253342\n",
            "6     108   77.519890   80.238678  ...    9.388203   10.481482    9.790123\n",
            "7     185   79.270210   80.697243  ...   84.447914  106.566574  118.715111\n",
            "8     123   52.105431   52.942097  ...   63.274311   61.951221   60.357727\n",
            "9     138   77.532661   78.274101  ...  107.059433   98.079391   72.163406\n",
            "10    127   77.668549   84.858948  ...   62.668488   64.525887   65.944443\n",
            "11    134   81.349075   84.315887  ...    0.580976    0.229450    0.165293\n",
            "12    143   75.359634   69.176346  ...   91.585938   91.084351   89.999512\n",
            "13    119   79.664368   75.359856  ...    0.000000    0.000000    0.000000\n",
            "14    150   74.137947   71.614220  ...   81.091911   80.410843   84.197159\n",
            "15    126   85.827164   83.802467  ...   95.456795   92.975311   98.530869\n",
            "16    163   34.549965   49.891304  ...   49.215672   51.482330   49.100006\n",
            "17    136   71.519035   72.711075  ...    0.000000    0.005190    0.067474\n",
            "18    114   77.791641   79.214211  ...   83.785164   84.430283   78.833496\n",
            "19    163  105.150658   92.829468  ...   80.642395   82.429634   83.647072\n",
            "20    110   81.421814   81.980499  ...  123.121323  119.174210  106.210243\n",
            "21    123   79.973488   81.961067  ...  102.112312  105.286865  104.218323\n",
            "22    162   58.503429   46.286385  ...   61.441246   69.902451   76.912666\n",
            "23    100   33.662395   35.308800  ...   70.363205   47.203201   43.161598\n",
            "24    154   43.148762   42.553719  ...   46.099174   34.892567   32.644630\n",
            "25    152   47.271465   50.903046  ...   23.760387   19.700140   12.628809\n",
            "26    188    0.431417    0.269353  ...   59.814396   51.162964   43.569939\n",
            "27    168  100.805557   93.861115  ...   54.611111   57.000000   78.277779\n",
            "28    188   84.033043   87.034859  ...   63.205067   47.033051   46.708916\n",
            "29    108   59.511658   32.041149  ...   65.164604   75.255142   82.919067\n",
            "30    108   91.779144   92.836761  ...   70.171463   70.113853   67.711937\n",
            "31    187   82.950951   75.758293  ...    0.000000    0.000000    0.000000\n",
            "32    134   67.912682   68.779686  ...   90.644020   94.890396   97.212082\n",
            "33    195   47.923401   45.596138  ...   69.780647   61.039452   61.353672\n",
            "34    158  103.265823   79.856750  ...   79.431175   79.480370   76.741058\n",
            "35    164   88.218918   93.761452  ...   63.839382   59.647827   55.634743\n",
            "36    165   70.739761   77.685516  ...  102.686096   72.093117   55.141266\n",
            "37    164  100.503281  104.325989  ...    6.126115    6.059488    6.271862\n",
            "38    177   37.288387   30.354044  ...  136.030212  141.876266  125.551460\n",
            "39    116   57.302021   53.750294  ...   62.996429   53.533882   73.737213\n",
            "40    100   35.534401   39.302402  ...  100.633606   99.611198  100.782394\n",
            "41    130   84.003326   83.273849  ...   59.962605   63.454201   67.406395\n",
            "42    141   34.474575   33.245163  ...    6.249032    6.316634    6.877169\n",
            "43    119   49.145332   51.193771  ...   82.031143   98.688583  111.152252\n",
            "44    148  107.933533  112.141716  ...   60.726807   62.101536   65.833466\n",
            "45    127   71.720505   70.338524  ...   94.290039   85.066032   60.346951\n",
            "46    154   49.247936   48.768597  ...   82.413223   78.280998   63.289257\n",
            "47    100  108.204803  107.236801  ...   51.908798   54.076797   53.167999\n",
            "48    146   97.471764  105.328392  ...   76.134361   73.176582   64.518669\n",
            "49    170   70.866859   77.824089  ...  103.923744   63.654541   62.574951\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xzpQ1Pz0fX5L",
        "outputId": "41a66d04-eeb5-4415-9cbb-f87f69556f01"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "06879f1b-be9e-45cf-ebf8-cd5f89cb1d51"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 32, 64, 128 '\n",
        "N1 = 200\n",
        "N2 = 10\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=32, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "64ea2f27-a1b1-4822-9f5f-a47adf74e8d3"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 21s 133ms/step - loss: 0.8154 - accuracy: 0.6351 - val_loss: 0.6934 - val_accuracy: 0.4898\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.3891 - accuracy: 0.8008 - val_loss: 0.6934 - val_accuracy: 0.4898\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.2957 - accuracy: 0.8699 - val_loss: 0.6932 - val_accuracy: 0.4898\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.1621 - accuracy: 0.9569 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.1231 - accuracy: 0.9589 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0550 - accuracy: 0.9967 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0636 - accuracy: 0.9770 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.6932 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0403 - accuracy: 0.9881 - val_loss: 0.6944 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0494 - accuracy: 0.9816 - val_loss: 0.6936 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0667 - accuracy: 0.9735 - val_loss: 0.6947 - val_accuracy: 0.4898\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.1232 - accuracy: 0.9530 - val_loss: 0.6920 - val_accuracy: 0.7891\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.6912 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6889 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 8.0986e-04 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 8.1546e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 9.0298e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7048 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 5.5814e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.0994e-04 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 6.1664e-04 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.6513e-04 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6871 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 7.4553e-04 - accuracy: 1.0000 - val_loss: 0.7452 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 8.1786e-04 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.9333e-04 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 6.9411e-04 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.1316e-04 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 4.6757e-04 - accuracy: 1.0000 - val_loss: 0.8201 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.5433e-04 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.0670e-04 - accuracy: 1.0000 - val_loss: 1.3256 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.7474e-04 - accuracy: 1.0000 - val_loss: 1.4382 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.4963e-04 - accuracy: 1.0000 - val_loss: 1.5311 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.4068e-04 - accuracy: 1.0000 - val_loss: 1.5954 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.0622e-04 - accuracy: 1.0000 - val_loss: 1.6748 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.9246e-04 - accuracy: 1.0000 - val_loss: 1.6456 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.5570e-04 - accuracy: 1.0000 - val_loss: 1.4359 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.9711e-04 - accuracy: 1.0000 - val_loss: 1.1915 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.2747e-04 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.5510\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.3526e-04 - accuracy: 1.0000 - val_loss: 2.5453 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.2678e-04 - accuracy: 1.0000 - val_loss: 2.5667 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.5884e-04 - accuracy: 1.0000 - val_loss: 1.7739 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.1614e-04 - accuracy: 1.0000 - val_loss: 1.1758 - val_accuracy: 0.5442\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 9.0826e-05 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.6531\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.6482e-04 - accuracy: 1.0000 - val_loss: 2.3340 - val_accuracy: 0.5170\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.4090e-04 - accuracy: 1.0000 - val_loss: 3.2492 - val_accuracy: 0.5102\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.2286e-04 - accuracy: 1.0000 - val_loss: 3.1874 - val_accuracy: 0.5102\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 9.4070e-05 - accuracy: 1.0000 - val_loss: 3.4280 - val_accuracy: 0.5102\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.0433e-04 - accuracy: 1.0000 - val_loss: 2.8808 - val_accuracy: 0.5102\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 8.6633e-05 - accuracy: 1.0000 - val_loss: 2.3690 - val_accuracy: 0.5306\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.3689e-04 - accuracy: 1.0000 - val_loss: 1.2633 - val_accuracy: 0.6327\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.0221e-04 - accuracy: 1.0000 - val_loss: 0.5569 - val_accuracy: 0.8095\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.2345 - val_accuracy: 0.5102\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.6479e-04 - accuracy: 1.0000 - val_loss: 3.2855 - val_accuracy: 0.5102\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 8.8636e-05 - accuracy: 1.0000 - val_loss: 4.0918 - val_accuracy: 0.5102\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.4291e-05 - accuracy: 1.0000 - val_loss: 4.1036 - val_accuracy: 0.5102\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 3.7088e-04 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.7755\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.7616e-05 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.7211\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.0920e-04 - accuracy: 1.0000 - val_loss: 1.5054 - val_accuracy: 0.6327\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.2651e-04 - accuracy: 1.0000 - val_loss: 1.6646 - val_accuracy: 0.6190\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.6750e-05 - accuracy: 1.0000 - val_loss: 1.3866 - val_accuracy: 0.6667\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.1786e-05 - accuracy: 1.0000 - val_loss: 1.1981 - val_accuracy: 0.7007\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.9607e-04 - accuracy: 1.0000 - val_loss: 2.6848 - val_accuracy: 0.5646\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.6069e-05 - accuracy: 1.0000 - val_loss: 3.5680 - val_accuracy: 0.5238\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.3187e-04 - accuracy: 1.0000 - val_loss: 3.0850 - val_accuracy: 0.5374\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.0374e-05 - accuracy: 1.0000 - val_loss: 2.5966 - val_accuracy: 0.5714\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.2428e-05 - accuracy: 1.0000 - val_loss: 1.7382 - val_accuracy: 0.6395\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.3693e-05 - accuracy: 1.0000 - val_loss: 1.6424 - val_accuracy: 0.6735\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.2964e-05 - accuracy: 1.0000 - val_loss: 1.7327 - val_accuracy: 0.6599\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 6.6054e-05 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.7075\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.8472e-05 - accuracy: 1.0000 - val_loss: 1.8862 - val_accuracy: 0.6667\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 6.5048e-05 - accuracy: 1.0000 - val_loss: 1.1069 - val_accuracy: 0.7687\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.1132e-05 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.8776\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 4.2432e-05 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9524\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.8009e-05 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9592\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.6614e-05 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9320\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 4.7659e-05 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9116\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.2556e-05 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9048\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.5269e-05 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9048\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.4602e-05 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9184\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 7.4856e-05 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9388\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.5762e-05 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9728\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.0071e-04 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.8980\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.1286e-05 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.8707\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 5.6038e-05 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.8776\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 5.5066e-05 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9184\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.9325e-05 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9524\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.8997e-05 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9456\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.8472e-05 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9388\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.8474e-05 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9524\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.7191e-05 - accuracy: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.8435\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.9597e-05 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.8163\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.9893e-05 - accuracy: 1.0000 - val_loss: 0.9071 - val_accuracy: 0.7823\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.2840e-05 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.7959\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.8884e-05 - accuracy: 1.0000 - val_loss: 2.8278 - val_accuracy: 0.6395\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.6207e-05 - accuracy: 1.0000 - val_loss: 5.0153 - val_accuracy: 0.5374\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.6747e-05 - accuracy: 1.0000 - val_loss: 5.2936 - val_accuracy: 0.5238\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.6196e-05 - accuracy: 1.0000 - val_loss: 4.7846 - val_accuracy: 0.5374\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.5039e-05 - accuracy: 1.0000 - val_loss: 4.4102 - val_accuracy: 0.5374\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.5164e-05 - accuracy: 1.0000 - val_loss: 3.6798 - val_accuracy: 0.5782\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.3563e-05 - accuracy: 1.0000 - val_loss: 3.6370 - val_accuracy: 0.5850\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.2734e-05 - accuracy: 1.0000 - val_loss: 3.0278 - val_accuracy: 0.5918\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.5412e-05 - accuracy: 1.0000 - val_loss: 3.1588 - val_accuracy: 0.5782\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.3114e-04 - accuracy: 1.0000 - val_loss: 2.6593 - val_accuracy: 0.5850\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 8.6426e-05 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7551\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.3717e-05 - accuracy: 1.0000 - val_loss: 1.7156 - val_accuracy: 0.6190\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.8463e-04 - accuracy: 1.0000 - val_loss: 10.9454 - val_accuracy: 0.5102\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.2996e-05 - accuracy: 1.0000 - val_loss: 26.9605 - val_accuracy: 0.5102\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.9002e-04 - accuracy: 1.0000 - val_loss: 20.4578 - val_accuracy: 0.5102\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 9.3920e-05 - accuracy: 1.0000 - val_loss: 18.3468 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.4424e-05 - accuracy: 1.0000 - val_loss: 17.2928 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.0894e-04 - accuracy: 1.0000 - val_loss: 15.9903 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.7878e-05 - accuracy: 1.0000 - val_loss: 14.9771 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.1573e-05 - accuracy: 1.0000 - val_loss: 14.1520 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.2131e-05 - accuracy: 1.0000 - val_loss: 13.1230 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.9442e-05 - accuracy: 1.0000 - val_loss: 11.8765 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.1818e-05 - accuracy: 1.0000 - val_loss: 11.1412 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.7016e-05 - accuracy: 1.0000 - val_loss: 10.0664 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.7186e-05 - accuracy: 1.0000 - val_loss: 9.1855 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.1776e-05 - accuracy: 1.0000 - val_loss: 8.3361 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.5682e-05 - accuracy: 1.0000 - val_loss: 7.3103 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.4290e-05 - accuracy: 1.0000 - val_loss: 6.2143 - val_accuracy: 0.5102\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.0250e-05 - accuracy: 1.0000 - val_loss: 5.7317 - val_accuracy: 0.5102\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.9329e-05 - accuracy: 1.0000 - val_loss: 5.5104 - val_accuracy: 0.5102\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.1106e-04 - accuracy: 1.0000 - val_loss: 6.6418 - val_accuracy: 0.5102\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.0948e-05 - accuracy: 1.0000 - val_loss: 7.7540 - val_accuracy: 0.5102\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.8923e-05 - accuracy: 1.0000 - val_loss: 8.0014 - val_accuracy: 0.5102\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.6310e-05 - accuracy: 1.0000 - val_loss: 7.7240 - val_accuracy: 0.5102\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.4856e-05 - accuracy: 1.0000 - val_loss: 7.2241 - val_accuracy: 0.5102\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 9.0172e-06 - accuracy: 1.0000 - val_loss: 6.6571 - val_accuracy: 0.5102\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.3492e-05 - accuracy: 1.0000 - val_loss: 6.0663 - val_accuracy: 0.5102\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.4114e-05 - accuracy: 1.0000 - val_loss: 5.5270 - val_accuracy: 0.5102\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.1564e-05 - accuracy: 1.0000 - val_loss: 5.0276 - val_accuracy: 0.5102\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.8301e-05 - accuracy: 1.0000 - val_loss: 4.3296 - val_accuracy: 0.5374\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 9.7197e-06 - accuracy: 1.0000 - val_loss: 3.8874 - val_accuracy: 0.5442\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.1559e-05 - accuracy: 1.0000 - val_loss: 3.5963 - val_accuracy: 0.5510\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 8.6440e-06 - accuracy: 1.0000 - val_loss: 3.0794 - val_accuracy: 0.5646\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.4042e-05 - accuracy: 1.0000 - val_loss: 2.3566 - val_accuracy: 0.6327\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.2232e-05 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.7347\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.3065e-05 - accuracy: 1.0000 - val_loss: 1.3724 - val_accuracy: 0.7415\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.8492e-05 - accuracy: 1.0000 - val_loss: 1.0457 - val_accuracy: 0.7891\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 7.4793e-06 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.8435\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.1346e-05 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.8367\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.5718e-06 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8503\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.3017e-05 - accuracy: 1.0000 - val_loss: 0.7658 - val_accuracy: 0.8231\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.5880e-05 - accuracy: 1.0000 - val_loss: 1.1739 - val_accuracy: 0.7755\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.8448e-05 - accuracy: 1.0000 - val_loss: 1.1571 - val_accuracy: 0.7619\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.1166e-05 - accuracy: 1.0000 - val_loss: 1.5698 - val_accuracy: 0.7007\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.1162e-05 - accuracy: 1.0000 - val_loss: 1.6509 - val_accuracy: 0.7007\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.5116e-06 - accuracy: 1.0000 - val_loss: 1.5074 - val_accuracy: 0.7075\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.1040e-05 - accuracy: 1.0000 - val_loss: 1.2452 - val_accuracy: 0.7279\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.6378e-05 - accuracy: 1.0000 - val_loss: 1.2424 - val_accuracy: 0.7347\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.2707e-05 - accuracy: 1.0000 - val_loss: 0.8448 - val_accuracy: 0.8367\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.5997e-05 - accuracy: 1.0000 - val_loss: 0.6394 - val_accuracy: 0.8707\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.0821e-05 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.8912\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 7.8817e-06 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9048\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 8.9654e-06 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9048\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 8.1172e-06 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9048\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.0356e-05 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9184\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 9.9126e-06 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9184\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.2077e-06 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9252\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.9170e-06 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9456\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 7.0890e-06 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9524\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 8.3033e-06 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9524\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 7.0738e-06 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9524\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 2.5614e-05 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9388\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 7.4910e-06 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8639\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.0782e-05 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8503\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 7.1150e-06 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.8707\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 4.3048e-06 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.8980\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.2242e-06 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9048\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.7350e-05 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9116\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 5.4461e-06 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9320\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.5145e-05 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.8707\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.0497e-04 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8707\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.0844e-06 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.8503\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 8.4780e-06 - accuracy: 1.0000 - val_loss: 0.6282 - val_accuracy: 0.8776\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.3120e-05 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8912\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 7.2942e-06 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8980\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 3.3030e-06 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.9048\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 6.1269e-06 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9184\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.7793e-06 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9388\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 4.3666e-06 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9456\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 6.7557e-06 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9524\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.6746e-05 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9184\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 5.5320e-05 - accuracy: 1.0000 - val_loss: 6.6119 - val_accuracy: 0.5170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpf0XlSARX78",
        "outputId": "184b62c9-ac55-4007-83ca-d085178bc16d"
      },
      "source": [
        "pred_test= model.predict_classes(X_test)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predict  0   1\n",
            "Actual        \n",
            "0        1  71\n",
            "1        0  75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFNNrlWV9tH",
        "outputId": "aef10ad1-ad19-458a-c90a-86d58516656e"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QISvYcJBgWbE",
        "outputId": "d1ca2fb5-284f-4e75-c97f-a4f82c6562d1"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[9] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  prediction = model.predict_classes(result)\n",
        "  loc_grao =[];k=0\n",
        "  for i in prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "7   131.0   97.322128  101.073997  ...  104.243225  102.746399  104.808525\n",
            "9   184.0    0.810019    0.680529  ...   71.267960   76.353958   83.704620\n",
            "45  108.0   60.458160   54.718796  ...   82.632370   83.438957   83.175583\n",
            "48  105.0   78.608894   77.853333  ...   10.088890    9.991112    9.866667\n",
            "2   100.0   59.633598   59.734398  ...    7.081600    6.713600    6.427200\n",
            "34  191.0    0.664675    1.139607  ...   72.726242   82.103951   79.537903\n",
            "4   168.0  109.472221  109.222221  ...   76.027779   66.722221   56.805557\n",
            "10  104.0   50.020714   53.168640  ...  102.698235   99.846153   97.606514\n",
            "8   121.0   63.640877   62.761971  ...   21.836010   18.004507   12.372107\n",
            "16  136.0   52.291527   41.566612  ...  118.751732  109.801903  107.208481\n",
            "21  150.0  100.487465  100.243561  ...    2.606044    0.950756    0.537600\n",
            "41  104.0    2.366864    1.745562  ...   10.565089   10.057693    9.871303\n",
            "7   124.0   76.093651   76.437042  ...   97.432877   97.274704   97.890732\n",
            "9   161.0   57.209831   62.052933  ...   81.328926   81.217392   82.888474\n",
            "27  115.0   24.520830   26.514782  ...  119.499802  119.138969  118.827286\n",
            "28  189.0   61.389576   62.237312  ...   63.220860   61.016457   59.452679\n",
            "44  167.0  108.309265  109.272949  ...   74.987389   69.934067   61.180862\n",
            "48  104.0   51.301777   54.826927  ...   92.914207   90.214508   88.544388\n",
            "13  101.0   53.651505   54.662189  ...   54.795513   55.072346   54.023628\n",
            "17  184.0  118.521263  119.531647  ...   38.069939   36.125237   33.661625\n",
            "38  120.0   94.910004   96.262222  ...   12.784445   18.413334   17.604445\n",
            "47  100.0    0.518400    0.332800  ...   10.480000   10.209600   10.876801\n",
            "48  144.0   64.912041   64.452156  ...   86.792435   87.471443   89.373459\n",
            "25  147.0   96.875282   95.600906  ...    9.002268    4.791384    2.024943\n",
            "46  194.0   14.288552   15.248910  ...   59.895947   57.690079   55.191410\n",
            "\n",
            "[25 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "de66c0ab-ba37-4deb-b035-c53bc57f2c06"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_paper_fev_2021' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "8f6c9bd7-20db-47af-a837-7cb295171983"
      },
      "source": [
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "\n",
        "%cd Doutorado\n",
        "\n",
        "PSD_imageJ = 'Amostra7.csv' \n",
        "PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "   Unnamed: 0   Area\n",
            "0           1  1.387\n",
            "1           2  1.626\n",
            "2           3  1.336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tEPjIBnv_xM",
        "outputId": "5cd97b34-31f4-4606-eb97-9457b1661f5f"
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfagXc-Mv3oa"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "PekBHQOT_6CP",
        "outputId": "f61230ac-3799-4f8d-cc0e-9123cd61d369"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>131.0</td>\n",
              "      <td>97.322128</td>\n",
              "      <td>101.073997</td>\n",
              "      <td>103.561790</td>\n",
              "      <td>100.327950</td>\n",
              "      <td>94.200974</td>\n",
              "      <td>86.890327</td>\n",
              "      <td>86.315712</td>\n",
              "      <td>84.842133</td>\n",
              "      <td>81.245438</td>\n",
              "      <td>83.941086</td>\n",
              "      <td>86.143112</td>\n",
              "      <td>88.087639</td>\n",
              "      <td>89.808914</td>\n",
              "      <td>91.282143</td>\n",
              "      <td>91.292404</td>\n",
              "      <td>84.393860</td>\n",
              "      <td>47.951576</td>\n",
              "      <td>19.098711</td>\n",
              "      <td>21.498980</td>\n",
              "      <td>37.013577</td>\n",
              "      <td>53.496010</td>\n",
              "      <td>100.258781</td>\n",
              "      <td>124.950058</td>\n",
              "      <td>131.963516</td>\n",
              "      <td>128.569946</td>\n",
              "      <td>130.519257</td>\n",
              "      <td>130.795868</td>\n",
              "      <td>130.995270</td>\n",
              "      <td>106.265289</td>\n",
              "      <td>95.021324</td>\n",
              "      <td>98.589935</td>\n",
              "      <td>99.995445</td>\n",
              "      <td>92.961777</td>\n",
              "      <td>88.456093</td>\n",
              "      <td>87.588837</td>\n",
              "      <td>79.421707</td>\n",
              "      <td>75.488655</td>\n",
              "      <td>80.222183</td>\n",
              "      <td>85.847328</td>\n",
              "      <td>...</td>\n",
              "      <td>107.695885</td>\n",
              "      <td>104.234886</td>\n",
              "      <td>94.738533</td>\n",
              "      <td>91.203064</td>\n",
              "      <td>91.909264</td>\n",
              "      <td>91.743431</td>\n",
              "      <td>91.418388</td>\n",
              "      <td>93.897148</td>\n",
              "      <td>94.357780</td>\n",
              "      <td>99.692322</td>\n",
              "      <td>99.404869</td>\n",
              "      <td>103.388092</td>\n",
              "      <td>80.248001</td>\n",
              "      <td>82.411156</td>\n",
              "      <td>84.966553</td>\n",
              "      <td>86.481377</td>\n",
              "      <td>89.022079</td>\n",
              "      <td>90.646347</td>\n",
              "      <td>89.614174</td>\n",
              "      <td>91.687958</td>\n",
              "      <td>92.500717</td>\n",
              "      <td>93.507423</td>\n",
              "      <td>98.367516</td>\n",
              "      <td>95.606834</td>\n",
              "      <td>95.334419</td>\n",
              "      <td>102.339256</td>\n",
              "      <td>107.637657</td>\n",
              "      <td>108.174347</td>\n",
              "      <td>108.573105</td>\n",
              "      <td>105.994568</td>\n",
              "      <td>100.750885</td>\n",
              "      <td>98.775711</td>\n",
              "      <td>97.275032</td>\n",
              "      <td>93.409645</td>\n",
              "      <td>92.942780</td>\n",
              "      <td>94.739754</td>\n",
              "      <td>98.767670</td>\n",
              "      <td>104.243225</td>\n",
              "      <td>102.746399</td>\n",
              "      <td>104.808525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>184.0</td>\n",
              "      <td>0.810019</td>\n",
              "      <td>0.680529</td>\n",
              "      <td>1.481096</td>\n",
              "      <td>2.292060</td>\n",
              "      <td>3.209357</td>\n",
              "      <td>3.271266</td>\n",
              "      <td>2.685728</td>\n",
              "      <td>1.874291</td>\n",
              "      <td>0.992438</td>\n",
              "      <td>0.424858</td>\n",
              "      <td>0.092628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056238</td>\n",
              "      <td>0.082703</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019849</td>\n",
              "      <td>0.095936</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.387051</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.596881</td>\n",
              "      <td>1.093573</td>\n",
              "      <td>0.138941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.578922</td>\n",
              "      <td>20.278353</td>\n",
              "      <td>25.055292</td>\n",
              "      <td>23.411623</td>\n",
              "      <td>21.157843</td>\n",
              "      <td>20.434780</td>\n",
              "      <td>16.519373</td>\n",
              "      <td>13.472589</td>\n",
              "      <td>9.657844</td>\n",
              "      <td>7.465028</td>\n",
              "      <td>3.198015</td>\n",
              "      <td>...</td>\n",
              "      <td>91.597343</td>\n",
              "      <td>90.659248</td>\n",
              "      <td>86.084587</td>\n",
              "      <td>81.449425</td>\n",
              "      <td>73.950844</td>\n",
              "      <td>72.313324</td>\n",
              "      <td>70.125710</td>\n",
              "      <td>70.099243</td>\n",
              "      <td>70.977310</td>\n",
              "      <td>74.114845</td>\n",
              "      <td>83.967857</td>\n",
              "      <td>73.927216</td>\n",
              "      <td>40.555763</td>\n",
              "      <td>40.547256</td>\n",
              "      <td>45.756142</td>\n",
              "      <td>46.795841</td>\n",
              "      <td>42.091209</td>\n",
              "      <td>38.169655</td>\n",
              "      <td>37.007561</td>\n",
              "      <td>38.781189</td>\n",
              "      <td>38.267479</td>\n",
              "      <td>36.624760</td>\n",
              "      <td>75.863884</td>\n",
              "      <td>93.290161</td>\n",
              "      <td>95.248581</td>\n",
              "      <td>91.744316</td>\n",
              "      <td>89.247635</td>\n",
              "      <td>98.275513</td>\n",
              "      <td>95.935715</td>\n",
              "      <td>92.344978</td>\n",
              "      <td>92.941383</td>\n",
              "      <td>85.496216</td>\n",
              "      <td>75.192810</td>\n",
              "      <td>74.985809</td>\n",
              "      <td>74.215965</td>\n",
              "      <td>73.715500</td>\n",
              "      <td>72.380432</td>\n",
              "      <td>71.267960</td>\n",
              "      <td>76.353958</td>\n",
              "      <td>83.704620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>108.0</td>\n",
              "      <td>60.458160</td>\n",
              "      <td>54.718796</td>\n",
              "      <td>51.137173</td>\n",
              "      <td>47.928665</td>\n",
              "      <td>47.381348</td>\n",
              "      <td>48.668037</td>\n",
              "      <td>50.798351</td>\n",
              "      <td>54.159122</td>\n",
              "      <td>58.120712</td>\n",
              "      <td>62.200272</td>\n",
              "      <td>63.061729</td>\n",
              "      <td>60.861454</td>\n",
              "      <td>55.718796</td>\n",
              "      <td>48.459534</td>\n",
              "      <td>47.238682</td>\n",
              "      <td>46.349792</td>\n",
              "      <td>44.422493</td>\n",
              "      <td>44.485592</td>\n",
              "      <td>45.727020</td>\n",
              "      <td>45.539093</td>\n",
              "      <td>46.412891</td>\n",
              "      <td>50.447186</td>\n",
              "      <td>55.692726</td>\n",
              "      <td>61.961590</td>\n",
              "      <td>68.517151</td>\n",
              "      <td>76.558289</td>\n",
              "      <td>79.953362</td>\n",
              "      <td>78.606308</td>\n",
              "      <td>65.005486</td>\n",
              "      <td>52.630997</td>\n",
              "      <td>51.183811</td>\n",
              "      <td>48.902603</td>\n",
              "      <td>48.524006</td>\n",
              "      <td>50.311386</td>\n",
              "      <td>53.375858</td>\n",
              "      <td>56.663918</td>\n",
              "      <td>60.934151</td>\n",
              "      <td>65.875168</td>\n",
              "      <td>66.508911</td>\n",
              "      <td>...</td>\n",
              "      <td>69.308640</td>\n",
              "      <td>69.705070</td>\n",
              "      <td>68.488342</td>\n",
              "      <td>70.270233</td>\n",
              "      <td>70.781891</td>\n",
              "      <td>72.255135</td>\n",
              "      <td>77.727013</td>\n",
              "      <td>81.499313</td>\n",
              "      <td>81.510284</td>\n",
              "      <td>82.897110</td>\n",
              "      <td>83.065849</td>\n",
              "      <td>81.515778</td>\n",
              "      <td>66.906731</td>\n",
              "      <td>68.846367</td>\n",
              "      <td>68.581619</td>\n",
              "      <td>67.995880</td>\n",
              "      <td>67.698212</td>\n",
              "      <td>68.381340</td>\n",
              "      <td>70.921814</td>\n",
              "      <td>74.661179</td>\n",
              "      <td>71.456787</td>\n",
              "      <td>69.595337</td>\n",
              "      <td>68.861450</td>\n",
              "      <td>69.367630</td>\n",
              "      <td>68.211250</td>\n",
              "      <td>67.145401</td>\n",
              "      <td>66.864197</td>\n",
              "      <td>66.499313</td>\n",
              "      <td>68.547325</td>\n",
              "      <td>69.385452</td>\n",
              "      <td>70.128944</td>\n",
              "      <td>71.074066</td>\n",
              "      <td>71.316864</td>\n",
              "      <td>74.155006</td>\n",
              "      <td>79.039780</td>\n",
              "      <td>81.991768</td>\n",
              "      <td>81.971191</td>\n",
              "      <td>82.632370</td>\n",
              "      <td>83.438957</td>\n",
              "      <td>83.175583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>105.0</td>\n",
              "      <td>78.608894</td>\n",
              "      <td>77.853333</td>\n",
              "      <td>72.395561</td>\n",
              "      <td>67.693344</td>\n",
              "      <td>65.977783</td>\n",
              "      <td>64.831116</td>\n",
              "      <td>65.168900</td>\n",
              "      <td>59.844448</td>\n",
              "      <td>40.520004</td>\n",
              "      <td>20.768890</td>\n",
              "      <td>12.982223</td>\n",
              "      <td>12.875557</td>\n",
              "      <td>10.093334</td>\n",
              "      <td>6.582223</td>\n",
              "      <td>4.524445</td>\n",
              "      <td>1.733334</td>\n",
              "      <td>1.604445</td>\n",
              "      <td>2.102222</td>\n",
              "      <td>1.995556</td>\n",
              "      <td>3.008889</td>\n",
              "      <td>4.017778</td>\n",
              "      <td>3.404445</td>\n",
              "      <td>2.933334</td>\n",
              "      <td>2.480000</td>\n",
              "      <td>3.013333</td>\n",
              "      <td>3.946667</td>\n",
              "      <td>33.884449</td>\n",
              "      <td>66.177780</td>\n",
              "      <td>79.497780</td>\n",
              "      <td>77.871124</td>\n",
              "      <td>70.013344</td>\n",
              "      <td>65.968895</td>\n",
              "      <td>64.537788</td>\n",
              "      <td>62.360008</td>\n",
              "      <td>58.546677</td>\n",
              "      <td>43.497784</td>\n",
              "      <td>19.382225</td>\n",
              "      <td>9.213334</td>\n",
              "      <td>9.551112</td>\n",
              "      <td>...</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>1.066667</td>\n",
              "      <td>0.995556</td>\n",
              "      <td>1.066667</td>\n",
              "      <td>0.751111</td>\n",
              "      <td>0.671111</td>\n",
              "      <td>0.706667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.244445</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.808889</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>10.160001</td>\n",
              "      <td>10.186668</td>\n",
              "      <td>10.422223</td>\n",
              "      <td>10.422224</td>\n",
              "      <td>10.297779</td>\n",
              "      <td>10.342224</td>\n",
              "      <td>10.017778</td>\n",
              "      <td>10.266667</td>\n",
              "      <td>9.488890</td>\n",
              "      <td>9.382223</td>\n",
              "      <td>9.728889</td>\n",
              "      <td>9.977778</td>\n",
              "      <td>9.844445</td>\n",
              "      <td>8.342222</td>\n",
              "      <td>8.986668</td>\n",
              "      <td>9.733334</td>\n",
              "      <td>9.733334</td>\n",
              "      <td>9.626669</td>\n",
              "      <td>9.484446</td>\n",
              "      <td>9.733335</td>\n",
              "      <td>9.657780</td>\n",
              "      <td>9.560001</td>\n",
              "      <td>9.684446</td>\n",
              "      <td>9.533336</td>\n",
              "      <td>9.875557</td>\n",
              "      <td>10.088890</td>\n",
              "      <td>9.991112</td>\n",
              "      <td>9.866667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100.0</td>\n",
              "      <td>59.633598</td>\n",
              "      <td>59.734398</td>\n",
              "      <td>62.084801</td>\n",
              "      <td>63.776001</td>\n",
              "      <td>66.071999</td>\n",
              "      <td>67.425606</td>\n",
              "      <td>67.504005</td>\n",
              "      <td>64.595200</td>\n",
              "      <td>62.120003</td>\n",
              "      <td>59.974400</td>\n",
              "      <td>58.443199</td>\n",
              "      <td>57.839996</td>\n",
              "      <td>58.841602</td>\n",
              "      <td>55.979202</td>\n",
              "      <td>47.184002</td>\n",
              "      <td>37.532803</td>\n",
              "      <td>27.992001</td>\n",
              "      <td>17.593599</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>2.369600</td>\n",
              "      <td>1.955200</td>\n",
              "      <td>1.840000</td>\n",
              "      <td>0.697600</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.395200</td>\n",
              "      <td>0.652800</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.798400</td>\n",
              "      <td>58.087994</td>\n",
              "      <td>59.945602</td>\n",
              "      <td>60.606400</td>\n",
              "      <td>62.156803</td>\n",
              "      <td>62.979198</td>\n",
              "      <td>62.777596</td>\n",
              "      <td>61.969601</td>\n",
              "      <td>60.603199</td>\n",
              "      <td>57.952003</td>\n",
              "      <td>55.684799</td>\n",
              "      <td>50.915207</td>\n",
              "      <td>...</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>1.323200</td>\n",
              "      <td>1.270400</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>1.374400</td>\n",
              "      <td>1.483200</td>\n",
              "      <td>1.963200</td>\n",
              "      <td>2.104000</td>\n",
              "      <td>1.683200</td>\n",
              "      <td>1.481600</td>\n",
              "      <td>1.894400</td>\n",
              "      <td>1.766400</td>\n",
              "      <td>8.995199</td>\n",
              "      <td>8.408000</td>\n",
              "      <td>8.472000</td>\n",
              "      <td>8.971200</td>\n",
              "      <td>8.904000</td>\n",
              "      <td>8.532800</td>\n",
              "      <td>9.126400</td>\n",
              "      <td>9.313601</td>\n",
              "      <td>9.080000</td>\n",
              "      <td>9.040000</td>\n",
              "      <td>9.014400</td>\n",
              "      <td>9.009600</td>\n",
              "      <td>8.692800</td>\n",
              "      <td>8.961599</td>\n",
              "      <td>8.964800</td>\n",
              "      <td>8.822399</td>\n",
              "      <td>7.756800</td>\n",
              "      <td>8.214400</td>\n",
              "      <td>8.492800</td>\n",
              "      <td>8.280001</td>\n",
              "      <td>7.944000</td>\n",
              "      <td>7.102400</td>\n",
              "      <td>6.172800</td>\n",
              "      <td>7.292800</td>\n",
              "      <td>7.235200</td>\n",
              "      <td>7.081600</td>\n",
              "      <td>6.713600</td>\n",
              "      <td>6.427200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Width          0           1  ...         781         782         783\n",
              "7   131.0  97.322128  101.073997  ...  104.243225  102.746399  104.808525\n",
              "9   184.0   0.810019    0.680529  ...   71.267960   76.353958   83.704620\n",
              "45  108.0  60.458160   54.718796  ...   82.632370   83.438957   83.175583\n",
              "48  105.0  78.608894   77.853333  ...   10.088890    9.991112    9.866667\n",
              "2   100.0  59.633598   59.734398  ...    7.081600    6.713600    6.427200\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VaZPe_AxNBK9",
        "outputId": "6c59865f-13e0-4103-a621-2cb146b99a57"
      },
      "source": [
        "PSD_new.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2.211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Area\n",
              "0           1  1.387\n",
              "1           2  1.626\n",
              "2           3  1.336\n",
              "3           4  0.640\n",
              "4           5  2.211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "\n",
        "# Area = np.array(PSD_new.iloc[:,1])\n",
        "Area = PSD_new['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aUb2_-jsY1Z",
        "outputId": "fa0984d3-039d-41d0-a190-03b89e1f847d"
      },
      "source": [
        "PSD_new.iloc[:,1].values"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.387, 1.626, 1.336, 0.64 , 2.211, 1.12 , 0.974, 1.237, 1.29 ,\n",
              "       3.755, 2.778, 1.256, 1.386, 1.302, 1.071, 1.497, 1.518, 1.244,\n",
              "       1.532, 1.325, 1.519, 1.895, 1.22 , 1.241, 1.301, 1.429, 0.667,\n",
              "       2.157, 1.052, 2.082, 1.517, 1.281, 0.784, 1.067, 2.764, 1.215,\n",
              "       0.943, 2.182, 1.486, 1.569, 2.667, 0.709, 1.006, 1.6  , 1.408,\n",
              "       3.16 , 2.465, 2.284, 1.273, 1.256, 3.021, 1.701, 1.955, 5.248,\n",
              "       1.627, 1.367, 1.592, 2.718, 1.658, 1.128, 2.192, 1.508, 2.547,\n",
              "       1.945, 1.606, 3.482, 1.756, 1.457, 1.864, 1.821, 1.314, 1.715,\n",
              "       1.015, 1.345, 1.265, 1.844, 1.396, 1.785, 1.694, 1.413, 1.368,\n",
              "       2.21 , 1.034, 1.367, 1.943, 1.008, 1.279, 1.579, 1.444, 1.879,\n",
              "       1.466, 2.154, 1.794, 3.149, 1.883, 1.692, 1.163, 1.297, 2.949,\n",
              "       1.09 , 1.444, 1.524])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J705kDqsE8f",
        "outputId": "f2f0722f-3441-4fc9-b10c-5e42d8697724"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mK1GBUHWiIr4",
        "outputId": "542274d8-f874-412f-e16e-067fd27d5b19"
      },
      "source": [
        "Freq = [10.52631579, 24.21052632, 36.84210526, 14.73684211,  7.36842105, 0.]\n",
        "Freq2 = [12.90153, 28.11527, 27.66761, 20.21617, 10.34227, 0.]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434, 0.]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d2be54d1-8bfb-4d46-e145-a7819a6cf05c"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f391962d290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "9401b144-cee0-4db5-a0a4-8d49f0cdcc1a"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.01960784, 0.05882353, 0.35294118, 0.67647059, 0.84313725,\n",
              "         0.90196078, 0.97058824, 0.99019608, 0.99019608, 1.        ],\n",
              "        [0.12      , 0.48      , 0.64      , 0.84      , 0.92      ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.76262599, 0.94485829, 1.12709058, 1.30932288, 1.49155518,\n",
              "        1.67378747, 1.85601977, 2.03825207, 2.22048437, 2.40271666,\n",
              "        2.58494896]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xENlBUUxfTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4dfa7957-4d71-4059-f111-4391c2039aa8"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r_squared = 0.7737267298130608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KukfpGTTKlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "2f830841-290e-49e5-e79f-f52872f957b0"
      },
      "source": [
        "df"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.773727</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.517007</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>6.611923</td>\n",
              "      <td>3 layers of Convolution: 32, 64, 128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    N1  N2  ...  loss test                                Details\n",
              "0  200  10  ...   6.611923  3 layers of Convolution: 32, 64, 128 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHa1j4HT9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "07450256-5e7e-4eca-b2f5-aab332278e32"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.76262599 0.94485829 1.12709058 1.30932288 1.49155518 1.67378747\n",
            " 1.85601977 2.03825207 2.22048437 2.40271666 2.58494896]\n",
            "[[ 1.96078431  3.92156863 29.41176471 32.35294118 16.66666667  5.88235294\n",
            "   6.8627451   1.96078431  0.          0.98039216]\n",
            " [12.         36.         16.         20.          8.          8.\n",
            "   0.          0.          0.          0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ada1186-a912-4c28-9e49-263c1c98e8cb"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "5f8c924c-a80d-4f1d-a761-e8d4f8494579"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3918f8b350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATo0lEQVR4nO3df4xfdZ3v8eebMjD3SgOFDrVS6BRsQBpuWxyKLM3SLcLtSlYkqQq5IeVGUtSF2Li5sUKy1L0moHYX1HjXLVdCtxaVIL3K6u6lwRKDCjiFAgO9CxQrDinttCDKvQK2fd8/5rROh5nOd2a+P+YDz0cyme/3c873+33NmTOvOXPO+Z6JzESSVJ4jWh1AkjQ2FrgkFcoCl6RCWeCSVCgLXJIKdWQzX2zq1KnZ2dnZzJeUpOJt3rx5d2Z2DB5vaoF3dnbS3d3dzJeUpOJFxK+HGncXiiQVygKXpEJZ4JJUqKbuA5f0zvbHP/6R3t5eXn/99VZHmZDa29uZMWMGbW1tNc1vgUtqmt7eXiZPnkxnZycR0eo4E0pmsmfPHnp7e5k1a1ZNj3EXiqSmef311znhhBMs7yFEBCeccMKo/jqxwCU1leU9vNEuGwtckgrlPnBJLdO58kd1fb7tN18y4jzHHHMMr732Wl1fdywWLVrE6tWr6erqGvNzWOAa1lh+uGr5AZJUH+5CkfSO9MADD3DBBRdw6aWXcuqpp7Jy5UrWr1/PggULOOuss9i2bRsA9957L+eeey7z58/ngx/8IDt37gSgr6+Piy66iDlz5nD11Vczc+ZMdu/eDcC3v/1tFixYwLx587jmmmvYt29fQ74GC1zSO9bjjz/ON7/5TbZu3cq6det45plneOSRR7j66qv5+te/DsDChQt56KGHeOyxx7j88sv58pe/DMAXvvAFFi9ezFNPPcXSpUt54YUXANi6dSvf+973+NnPfsaWLVuYNGkS69evb0h+d6FIesc655xzmD59OgCnnXYaF198MQBnnXUWmzZtAvrPXf/4xz/Ojh07ePPNNw+eo/3ggw+yYcMGAJYsWcKUKVMAuP/++9m8eTPnnHMOAH/4wx848cQTG5LfApf0jnX00UcfvH3EEUccvH/EEUewd+9eAK677jo++9nP8uEPf5gHHniAVatWHfY5M5Nly5Zx0003NSz3Ae5CkaTDePXVVznppJMAWLt27cHx888/n7vuuguA++67j1deeQWACy+8kLvvvptdu3YB8PLLL/PrXw95NdhxcwtcUsuUcNbSqlWr+OhHP8qUKVNYvHgxv/rVrwC48cYbueKKK1i3bh3nnXce7373u5k8eTJTp07li1/8IhdffDH79++nra2Nb3zjG8ycOfOQ5927d+8hfwGMRWTmuJ5gNLq6utJ/6FAOTyNUvW3dupX3ve99rY5RF2+88QaTJk3iyCOP5Be/+AWf+tSn2LJlS82Pfe9730tPTw/HHnvsIdOGWkYRsTkz33LCuFvgkjQGL7zwAh/72MfYv38/Rx11FLfddltNj+vu7ubKK6/k05/+9FvKe7QscEkag9mzZ/PYY4+N+nFdXV1s3bq1Lhk8iClJhbLAJalQFrgkFcoCl6RCeRBTUuusGt9ZGG99vldHnOWll15ixYoV/PKXv+S4445j2rRp3HrrrZx++ul87Wtf47rrrgPg2muvpauri6uuuoqrrrqKjRs38vzzz3P00Ueze/duurq62L59e33zj9KIW+AR0R4Rj0TE4xHxVER8oRqfFREPR8RzEfG9iDiq8XElaewyk8suu4xFixaxbds2Nm/ezE033cTOnTs58cQT+epXv8qbb7455GMnTZrE7bff3uTEh1fLLpQ3gMWZOReYByyJiA8AXwJuycz3Aq8An2hcTEkav02bNtHW1sYnP/nJg2Nz587l5JNPpqOjgwsvvPCQt8sPtGLFCm655ZaD10iZCEYs8Ox34N9XtFUfCSwG7q7G1wIfaUhCSaqTnp4e3v/+9w87/XOf+xyrV68e8vrdp5xyCgsXLmTdunWNjDgqNR3EjIhJEbEF2AVsBLYBv83MA7+KeoGTGhNRkprj1FNP5dxzz+XOO+8ccvrnP/95vvKVr7B///4mJxtaTQcxM3MfMC8ijgM2AGfU+gIRsRxYDv2/wTQ6Xo9Eqp85c+Zw9913H3ae66+/nqVLl3LBBRe8Zdrs2bOZN2/ewasQttqoTiPMzN8Cm4DzgOMi4sAvgBnAi8M8Zk1mdmVmV0dHx7jCStJ4LF68mDfeeIM1a9YcHHviiSf4zW9+c/D+GWecwZlnnsm999475HPccMMNrF69uuFZazHiFnhEdAB/zMzfRsR/AC6i/wDmJmAp8F1gGfCDRgaV9DZUw2l/9RQRbNiwgRUrVvClL32J9vZ2Ojs7ufXWWw+Z74YbbmD+/PlDPsecOXM4++yzefTRR5sR+bBq2YUyHVgbEZPo32K/KzP/JSKeBr4bEV8EHgO+1cCcklQX73nPe4bcBdLT03Pw9ty5cw/Zz33HHXccMu8999zTsHyjMWKBZ+YTwFt+FWXm88CCRoSSJI3Mt9JLUqEscElN1cz/Alaa0S4bC1xS07S3t7Nnzx5LfAiZyZ49e2hvb6/5MV7MSlLTzJgxg97eXvr6+lodZUJqb29nxowZNc9vgUtqmra2NmbNmtXqGG8b7kKRpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklSoEQs8Ik6OiE0R8XREPBURn6nGV0XEixGxpfr4UOPjSpIOqOV/Yu4F/iYzH42IycDmiNhYTbslM1c3Lp4kaTgjFnhm7gB2VLd/HxFbgZMaHUySdHij2gceEZ3AfODhaujaiHgiIm6PiCnDPGZ5RHRHRHdfX9+4wkqS/qTmAo+IY4DvAysy83fAPwKnAfPo30L/+6Eel5lrMrMrM7s6OjrqEFmSBDUWeES00V/e6zPzHoDM3JmZ+zJzP3AbsKBxMSVJg9VyFkoA3wK2ZuY/DBifPmC2y4Ce+seTJA2nlrNQzgeuBJ6MiC3V2PXAFRExD0hgO3BNQxJKkoZUy1koDwIxxKQf1z+OJKlWvhNTkgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVasQCj4iTI2JTRDwdEU9FxGeq8eMjYmNEPFt9ntL4uJKkA2rZAt8L/E1mngl8APjriDgTWAncn5mzgfur+5KkJhmxwDNzR2Y+Wt3+PbAVOAm4FFhbzbYW+EijQkqS3mpU+8AjohOYDzwMTMvMHdWkl4BpwzxmeUR0R0R3X1/fOKJKkgaqucAj4hjg+8CKzPzdwGmZmUAO9bjMXJOZXZnZ1dHRMa6wkqQ/qanAI6KN/vJen5n3VMM7I2J6NX06sKsxESVJQ6nlLJQAvgVszcx/GDDph8Cy6vYy4Af1jydJGs6RNcxzPnAl8GREbKnGrgduBu6KiE8AvwY+1piIkqShjFjgmfkgEMNMvrC+cSRJtfKdmJJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWq5XKyUtN1rvzRqB+z/eZLGpBEmrjcApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEKNWOARcXtE7IqIngFjqyLixYjYUn18qLExJUmD1bIFfgewZIjxWzJzXvXx4/rGkiSNZMQCz8yfAi83IYskaRTGsw/82oh4otrFMmW4mSJieUR0R0R3X1/fOF5OkjTQWAv8H4HTgHnADuDvh5sxM9dkZldmdnV0dIzx5SRJg42pwDNzZ2buy8z9wG3AgvrGkiSNZEwFHhHTB9y9DOgZbl5JUmOM+A8dIuI7wCJgakT0AjcCiyJiHpDAduCaBmaUJA1hxALPzCuGGP5WA7JIkkbBd2JKUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCjVjgEXF7ROyKiJ4BY8dHxMaIeLb6PKWxMSVJg9WyBX4HsGTQ2Erg/sycDdxf3ZckNdGIBZ6ZPwVeHjR8KbC2ur0W+Eidc0mSRjDWfeDTMnNHdfslYNpwM0bE8ojojojuvr6+Mb6cJGmwcR/EzMwE8jDT12RmV2Z2dXR0jPflJEmVsRb4zoiYDlB93lW/SJKkWoy1wH8ILKtuLwN+UJ84kqRa1XIa4XeAXwCnR0RvRHwCuBm4KCKeBT5Y3ZckNdGRI82QmVcMM+nCOmeRJI3CiAWuMVp17Cjnf7UxOSS9bflWekkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVyotZSRNM58ofjWr+7Tdf0qAkmujcApekQlngklQoC1ySCmWBS1KhLHBJKpRnoUiDjPYsEPBMELWGW+CSVCgLXJIKNa5dKBGxHfg9sA/Ym5ld9QglSRpZPfaB/0Vm7q7D80iSRsFdKJJUqPFugSdwX0Qk8E+ZuWbwDBGxHFgOcMopp4zz5TThrTp2lPO/2pgc0jvAeLfAF2bm2cBfAn8dEX8+eIbMXJOZXZnZ1dHRMc6XkyQdMK4Cz8wXq8+7gA3AgnqEkiSNbMwFHhHviojJB24DFwM99QomSTq88ewDnwZsiIgDz3NnZv5bXVJJkkY05gLPzOeBuXXMIkkaBU8jlKRCeTGrGozp4kbtDQhSK0/lk94R3AKXpEJZ4JJUKAtckgplgUtSoSxwSSrU2/ssFM/GkPQ25ha4JBXKApekQlngklQoC1ySCmWBS1KhijkLpbjrkaj5WnnW0dvkjKfR/pxtv/mSBiVRLdwCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYUq5jRCSWqUUk+fdAtckgplgUtSocZV4BGxJCL+PSKei4iV9QolSRrZmAs8IiYB3wD+EjgTuCIizqxXMEnS4Y1nC3wB8FxmPp+ZbwLfBS6tTyxJ0kgiM8f2wIilwJLMvLq6fyVwbmZeO2i+5cDy6u7pwL/X8PRTgd1jCtZ8pWQtJSeUk7WUnGDWRmhmzpmZ2TF4sOGnEWbmGmDNaB4TEd2Z2dWgSHVVStZSckI5WUvJCWZthImQczy7UF4ETh5wf0Y1JklqgvEU+C+B2RExKyKOAi4HflifWJKkkYx5F0pm7o2Ia4H/DUwCbs/Mp+qUa1S7XFqslKyl5IRyspaSE8zaCC3POeaDmJKk1vKdmJJUKAtckgrV1AIf6a33EXFLRGypPp6JiN8OmLZvwLSGHyyNiNsjYldE9AwzPSLia9XX8kREnD1g2rKIeLb6WNbinP+lyvdkRPw8IuYOmLa9Gt8SEd2NzFlj1kUR8eqA7/PfDpjWtMs21JDzvw3I2FOtm8dX05q9TE+OiE0R8XREPBURnxlinpavqzXmnBDrao1ZJ8S6SmY25YP+A53bgFOBo4DHgTMPM/919B8YPXD/tWZlrV7vz4GzgZ5hpn8I+FcggA8AD1fjxwPPV5+nVLentDDnnx14ffove/DwgGnbgakTaJkuAv5lvOtOo3MOmvevgJ+0cJlOB86ubk8Gnhm8bCbCulpjzgmxrtaYdUKsq83cAh/tW++vAL7TlGRDyMyfAi8fZpZLgX/Ofg8Bx0XEdOA/Axsz8+XMfAXYCCxpVc7M/HmVA+Ah+s/Xb4kalulwmnrZhlHmbPV6uiMzH61u/x7YCpw0aLaWr6u15Jwo62qNy3Q4TV1Xm1ngJwG/GXC/l2EWSkTMBGYBPxkw3B4R3RHxUER8pHExazbc11Pz19kCn6B/S+yABO6LiM3Rf8mDieC8iHg8Iv41IuZUYxNymUbEf6S/8L4/YLhlyzQiOoH5wMODJk2odfUwOQeaEOvqCFlbvq5O1P/Iczlwd2buGzA2MzNfjIhTgZ9ExJOZua1F+YoTEX9B/w/FwgHDC6tleiKwMSL+T7X12SqP0v99fi0iPgT8L2B2C/OM5K+An2XmwK31lizTiDiG/l8kKzLzd41+vbGqJedEWVdHyDoh1tVmboGP5q33lzPoz9LMfLH6/DzwAP2/FVtpuK9nwl1iICL+E/A/gUszc8+B8QHLdBewgf4//1omM3+Xma9Vt38MtEXEVCbgMq0cbj1t2jKNiDb6i2Z9Zt4zxCwTYl2tIeeEWVdHyjph1tVGHxAYsHP/SPoPksziTzv35wwx3xn0H7CIAWNTgKOr21OBZ2nggYEBr9vJ8AfcLuHQA0OPVOPHA7+qMk+pbh/fwpynAM8BfzZo/F3A5AG3f07/1SVbuUzffeD7Tv8P6AvV8q1p3WlWzmr6sfTvJ39XK5dptXz+Gbj1MPO0fF2tMeeEWFdrzDoh1tWm7ULJYd56HxF/B3Rn5oFTAy8HvpvVkqm8D/iniNhP/18NN2fm043MGxHfof9I89SI6AVuBNqqr+WbwI/pP7r/HPD/gP9aTXs5Iv47/deKAfi7PPRP7Gbn/FvgBOB/RATA3uy/gto0YEM1diRwZ2b+W6Ny1ph1KfCpiNgL/AG4vFoPGnnZhrHkBLgMuC8z/++AhzZ9mQLnA1cCT0bElmrsevrLcCKtq7XknCjrai1ZJ8a6emhPSpJK4TsxJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkq1P8Haw3U0YOGnFgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b5e819-0a51-478a-d7fe-b758934ebe1a"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.3289030245084366,\n",
              "  1.4388493665910183,\n",
              "  1.3042423209535017,\n",
              "  0.9027033336764101,\n",
              "  1.6778356991700483,\n",
              "  1.1941642642883694,\n",
              "  1.113613629842976,\n",
              "  1.254988970803089,\n",
              "  1.2815923738491737,\n",
              "  2.186553107171316,\n",
              "  1.8807071689325485,\n",
              "  1.2645903954195463,\n",
              "  1.3284238815238665,\n",
              "  1.2875394701698204,\n",
              "  1.1677497815933682,\n",
              "  1.3805939296073044,\n",
              "  1.3902437300372827,\n",
              "  1.2585348599266302,\n",
              "  1.3966398900698307,\n",
              "  1.2988619621707653,\n",
              "  1.3907015741893414,\n",
              "  1.5533154661153457,\n",
              "  1.2463355264843006,\n",
              "  1.2570164179581493,\n",
              "  1.2870449283923413,\n",
              "  1.3488733481786004,\n",
              "  0.9215480325725586,\n",
              "  1.6572198701420842,\n",
              "  1.157345238492556,\n",
              "  1.6281537802488464,\n",
              "  1.3897857350553149,\n",
              "  1.2771138777750963,\n",
              "  0.9991095050455518,\n",
              "  1.165567069812981,\n",
              "  1.875962180228586,\n",
              "  1.2437789380968078,\n",
              "  1.0957485526731296,\n",
              "  1.6667959343039342,\n",
              "  1.3755122549350303,\n",
              "  1.413404699896484,\n",
              "  1.8427506249649406,\n",
              "  0.9501193805081709,\n",
              "  1.1317592420667806,\n",
              "  1.4272992929222168,\n",
              "  1.3389254195014408,\n",
              "  2.0058506827187097,\n",
              "  1.7715912276177528,\n",
              "  1.7053090981329784,\n",
              "  1.273119766733618,\n",
              "  1.2645903954195463,\n",
              "  1.9612385537320356,\n",
              "  1.4716590860639265,\n",
              "  1.5777145844408116,\n",
              "  2.584948960960377,\n",
              "  1.4392917491892008,\n",
              "  1.319287102056625,\n",
              "  1.4237265731938766,\n",
              "  1.8602862904913782,\n",
              "  1.4529388029682806,\n",
              "  1.1984215478959244,\n",
              "  1.6706109906436855,\n",
              "  1.3856569681781365,\n",
              "  1.8008167925806498,\n",
              "  1.5736743355948497,\n",
              "  1.4299729748651446,\n",
              "  2.1055688292639205,\n",
              "  1.4952620641730152,\n",
              "  1.3620242349823046,\n",
              "  1.540557857201846,\n",
              "  1.5226848692236787,\n",
              "  1.293459223084363,\n",
              "  1.4777028859756633,\n",
              "  1.1368105109938904,\n",
              "  1.3086279790944384,\n",
              "  1.269113085619237,\n",
              "  1.5322707725763225,\n",
              "  1.3332075624036517,\n",
              "  1.507558485549488,\n",
              "  1.4686278591874,\n",
              "  1.341300666036808,\n",
              "  1.319769562157615,\n",
              "  1.6774562271083886,\n",
              "  1.1474012764748687,\n",
              "  1.319287102056625,\n",
              "  1.5728650404343092,\n",
              "  1.1328836926591555,\n",
              "  1.2761165219980004,\n",
              "  1.417901703622935,\n",
              "  1.355934328276106,\n",
              "  1.546744033302657,\n",
              "  1.3662244224803437,\n",
              "  1.6560670213972442,\n",
              "  1.5113542745679724,\n",
              "  2.0023564433863985,\n",
              "  1.5483895061438226,\n",
              "  1.467760644550703,\n",
              "  1.2168720518308382,\n",
              "  1.2850648580991957,\n",
              "  1.937726352564777,\n",
              "  1.1780624362746346,\n",
              "  1.355934328276106,\n",
              "  1.3929885377045959],\n",
              " [1.0243473938547305,\n",
              "  1.5103132050457497,\n",
              "  0.8903230478223723,\n",
              "  1.1849207925540384,\n",
              "  1.1259047242928895,\n",
              "  1.3694509380472293,\n",
              "  1.4124521414089608,\n",
              "  1.0220810227344332,\n",
              "  0.7626259889493925,\n",
              "  1.2444695748293981,\n",
              "  1.3725767369441892,\n",
              "  1.1061971943809115,\n",
              "  1.1240588720442846,\n",
              "  1.2181778216209818,\n",
              "  1.0021697531805316,\n",
              "  1.8100201300821994,\n",
              "  1.338704083814619,\n",
              "  0.9039831787806819,\n",
              "  0.9845605539395087,\n",
              "  1.6198339840178253,\n",
              "  1.2109974750482155,\n",
              "  1.087190109138031,\n",
              "  1.0969372164014848,\n",
              "  1.351367116018212,\n",
              "  1.7977618984957477]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fbf8207f-b995-4032-a49d-0bf6e0004206"
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4,1.6, 1.8,2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f391962d750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "90ca5b60-510b-491b-b126-d8b62e01d9c7"
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668c67ea-3e55-4bd3-896f-4d206ceca9bf"
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.92156863, 11.76470588, 40.19607843, 23.52941176,  8.82352941,\n",
              "        6.8627451 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8373c34c-666b-414a-8fa9-3da57d3e59be"
      },
      "source": [
        "bins_list"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "9c3eb759-96a9-4ec2-e0f2-eb9046786a17"
      },
      "source": [
        "df"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "      <th>0.8</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.4</th>\n",
              "      <th>1.6</th>\n",
              "      <th>1.8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.773727</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.517007</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>6.611923</td>\n",
              "      <td>3 layers of Convolution: 32, 64, 128</td>\n",
              "      <td>12.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    N1  N2       R^2  acc train  acc test  ...   1.0   1.2  1.4  1.6  1.8\n",
              "0  200  10  0.773727        1.0  0.517007  ...  36.0  28.0  8.0  8.0  4.0\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8330be4d-6ed2-479f-ca9f-2cb635b87173"
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_24951d4d-2e18-4bbf-a216-c70d8a8847e8\", \"output.xlsx\", 5239)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}