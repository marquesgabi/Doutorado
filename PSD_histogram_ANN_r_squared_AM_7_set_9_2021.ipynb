{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_ANN_r_squared_set_9_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/PSD_histogram_ANN_r_squared_AM_7_set_9_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fc0ca3-1b94-4cfd-e01b-ba2b661595e7"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fbd6521-203b-4ce7-f7f6-6d2e03ac0ac2"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e7bdff-bb27-4d54-ed3a-094f603c34e7"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[2] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10ca274-ad1b-4a72-c0bb-3d40e1988658"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN5MN5a_v4np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400e2756-c920-4a19-9bc0-6da69b68f142"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     169  109.969704  109.459793  ...   93.244423   77.996979   49.732361\n",
            "1     116   58.872768   58.652790  ...    9.456599    9.206897    9.206896\n",
            "2     133  114.110802  118.559540  ...  156.833786  159.986160  161.797775\n",
            "3     102   80.742798   81.458672  ...  116.524811  119.746262  121.302582\n",
            "4     106  185.266281  164.430405  ...  132.368103  146.658234  150.278748\n",
            "5     168   52.222221   49.166668  ...    8.416667    8.194445    7.694445\n",
            "6     147  171.086182  173.802719  ...  114.192749  115.963715  116.544220\n",
            "7     199   85.277115   97.118523  ...    7.067952    6.918033    7.070048\n",
            "8     102  113.290665  113.755875  ...   57.334488   55.519032   65.638222\n",
            "9     178  104.911880   86.208191  ...   25.681231   25.160967   24.251488\n",
            "10    185   78.093994  106.497551  ...    7.283944    7.288035    7.425478\n",
            "11    149  138.389435  142.935287  ...  183.049744  188.746597  202.389938\n",
            "12    153  107.958176  107.218811  ...    8.664744    8.668333    8.639627\n",
            "13    159  179.014267  183.181992  ...  111.277290  122.579918  130.510468\n",
            "14    134  179.197586  189.982193  ...  175.799515  174.896652  169.216980\n",
            "15    159  149.670853  156.327393  ...  104.858978  111.716507  111.019547\n",
            "16    140   85.159996   84.519997  ...   79.479996   84.839996   87.720001\n",
            "17    191  116.766495  106.094200  ...    0.577945    0.000000    0.000000\n",
            "18    107  252.498901  252.456268  ...  124.761902  125.082901  124.897537\n",
            "19    132  131.840225  134.945831  ...  124.269981  119.725433  119.352631\n",
            "20    123  119.185013  120.942566  ...   91.423431   85.442924   82.785912\n",
            "21    152  165.358734  166.098328  ...  115.889893  117.775620  120.892662\n",
            "22    130   72.821777   71.571594  ...   98.889709   98.772072   99.847572\n",
            "23    174   86.725983   93.909782  ...   69.803017   69.761536   71.722694\n",
            "24    117  143.464111  145.189575  ...  172.553802  174.183197  178.029068\n",
            "25    130    0.000000    0.000000  ...  138.333267  136.415405  134.433380\n",
            "26    105   54.644447    7.933334  ...   58.168896   56.973339   58.626671\n",
            "27    170  100.365814   94.728172  ...  146.404572  147.571503  144.509903\n",
            "28    108  138.041153  137.565155  ...  140.805206  140.622772  140.465012\n",
            "29    156  122.226830  123.048660  ...  133.364243   97.153198   67.967796\n",
            "30    188  128.470795  126.650070  ...    7.394749    6.783160    6.231779\n",
            "31    130    0.000000    0.000000  ...  155.584381  154.929703  156.662720\n",
            "32    165  107.541977  110.284081  ...   87.674713   90.333267   96.460785\n",
            "33    147  117.777786  120.843552  ...    9.578231    9.478458   10.131520\n",
            "34    117  142.189789  142.744827  ...  105.440430  108.896339  106.940033\n",
            "35    169  122.601891  121.717751  ...  108.003845  106.321831  100.349136\n",
            "36    162   95.535431   92.833412  ...    1.488645    1.644414    1.541991\n",
            "37    132  117.933891   62.301201  ...  208.921036  208.110199  188.525269\n",
            "38    185    1.224982    0.786180  ...  130.561462  129.828720  128.412842\n",
            "39    160  106.342499  110.498741  ...    0.000000    0.000000    0.000000\n",
            "40    181   80.981316   81.394135  ...   56.973564   50.777328   27.063032\n",
            "41    183  108.853127  112.142380  ...    7.646034    8.020694    7.841769\n",
            "42    141   95.118095   95.015297  ...  130.616165  135.253418  139.123734\n",
            "43    150  154.293686  152.189514  ...  117.959290  114.281242  103.054230\n",
            "44    154   92.892563   78.892570  ...    6.239670    6.090910    5.231405\n",
            "45    101  223.262543  115.668373  ...  128.189392  127.022644  124.409767\n",
            "46    158   97.219833   89.084602  ...    6.134754    5.979971    5.136517\n",
            "47    200   96.506012   93.391594  ...   99.814003   95.411209  109.302399\n",
            "48    139  128.717407  129.923035  ...   85.111519   81.194710   76.748138\n",
            "49    123   87.315880   88.887039  ...   79.348602   90.138481   94.771172\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpQ1Pz0fX5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7ede84cf-4a6b-4dbe-bb2e-2bacfc38798c"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "f0563e23-1faa-4c26-8242-2d3a2d7ab7bb"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = 'ANN without convolution '\n",
        "N1 = 200\n",
        "N2 = 10\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "a836f7da-8d17-4b44-c111-f62c1340b123"
      },
      "source": [
        "\n",
        "# gives us back a <keras.callbacks.History object at 0x112e61a90>\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 1s 23ms/step - loss: 0.6922 - accuracy: 0.4956 - val_loss: 0.6897 - val_accuracy: 0.4898\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6886 - accuracy: 0.5656 - val_loss: 0.6855 - val_accuracy: 0.5578\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6239 - val_loss: 0.6804 - val_accuracy: 0.6667\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.6501 - val_loss: 0.6742 - val_accuracy: 0.7551\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6739 - accuracy: 0.6181 - val_loss: 0.6671 - val_accuracy: 0.5986\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6657 - accuracy: 0.6472 - val_loss: 0.6575 - val_accuracy: 0.7279\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6588 - accuracy: 0.6764 - val_loss: 0.6467 - val_accuracy: 0.7415\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6735 - val_loss: 0.6337 - val_accuracy: 0.7823\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.7551 - val_loss: 0.6170 - val_accuracy: 0.7891\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6222 - accuracy: 0.6997 - val_loss: 0.6010 - val_accuracy: 0.7959\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 0.7638 - val_loss: 0.5805 - val_accuracy: 0.7823\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.7609 - val_loss: 0.5695 - val_accuracy: 0.7959\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7464 - val_loss: 0.5405 - val_accuracy: 0.8231\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7872 - val_loss: 0.5227 - val_accuracy: 0.8095\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7813 - val_loss: 0.5022 - val_accuracy: 0.8163\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.8047 - val_loss: 0.4780 - val_accuracy: 0.8639\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.8076 - val_loss: 0.4580 - val_accuracy: 0.9048\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.8163 - val_loss: 0.4498 - val_accuracy: 0.8163\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.8251 - val_loss: 0.4163 - val_accuracy: 0.9252\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.8426 - val_loss: 0.4032 - val_accuracy: 0.8980\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8280 - val_loss: 0.3872 - val_accuracy: 0.9048\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8397 - val_loss: 0.3737 - val_accuracy: 0.9184\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8601 - val_loss: 0.3580 - val_accuracy: 0.9320\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8542 - val_loss: 0.3892 - val_accuracy: 0.8367\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8805 - val_loss: 0.3395 - val_accuracy: 0.9320\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8397 - val_loss: 0.3290 - val_accuracy: 0.9048\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8834 - val_loss: 0.3169 - val_accuracy: 0.9184\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8601 - val_loss: 0.3032 - val_accuracy: 0.9456\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.8688 - val_loss: 0.2969 - val_accuracy: 0.9388\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8659 - val_loss: 0.2916 - val_accuracy: 0.9320\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8834 - val_loss: 0.2778 - val_accuracy: 0.9524\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8921 - val_loss: 0.2839 - val_accuracy: 0.9116\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8630 - val_loss: 0.2665 - val_accuracy: 0.9456\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3184 - accuracy: 0.8921 - val_loss: 0.2763 - val_accuracy: 0.9116\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8892 - val_loss: 0.2486 - val_accuracy: 0.9524\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3089 - accuracy: 0.8892 - val_loss: 0.2671 - val_accuracy: 0.9116\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3247 - accuracy: 0.8659 - val_loss: 0.2368 - val_accuracy: 0.9456\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.8805 - val_loss: 0.2301 - val_accuracy: 0.9320\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.8950 - val_loss: 0.2435 - val_accuracy: 0.9320\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2780 - accuracy: 0.8980 - val_loss: 0.2191 - val_accuracy: 0.9524\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.8834 - val_loss: 0.2155 - val_accuracy: 0.9524\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2782 - accuracy: 0.8980 - val_loss: 0.2206 - val_accuracy: 0.9388\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2629 - accuracy: 0.9096 - val_loss: 0.2104 - val_accuracy: 0.9252\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8892 - val_loss: 0.2042 - val_accuracy: 0.9524\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2600 - accuracy: 0.9096 - val_loss: 0.2182 - val_accuracy: 0.9320\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.9009 - val_loss: 0.1988 - val_accuracy: 0.9252\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2608 - accuracy: 0.9067 - val_loss: 0.2116 - val_accuracy: 0.9320\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2526 - accuracy: 0.8980 - val_loss: 0.1939 - val_accuracy: 0.9388\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2746 - accuracy: 0.8950 - val_loss: 0.2184 - val_accuracy: 0.9320\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.9067 - val_loss: 0.1880 - val_accuracy: 0.9456\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2623 - accuracy: 0.9096 - val_loss: 0.1851 - val_accuracy: 0.9524\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2371 - accuracy: 0.9009 - val_loss: 0.1948 - val_accuracy: 0.9388\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.9009 - val_loss: 0.1848 - val_accuracy: 0.9320\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2413 - accuracy: 0.9096 - val_loss: 0.2135 - val_accuracy: 0.9320\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2370 - accuracy: 0.9067 - val_loss: 0.1784 - val_accuracy: 0.9388\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2370 - accuracy: 0.9155 - val_loss: 0.1735 - val_accuracy: 0.9524\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9096 - val_loss: 0.1726 - val_accuracy: 0.9524\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2302 - accuracy: 0.9067 - val_loss: 0.1698 - val_accuracy: 0.9524\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.9096 - val_loss: 0.1722 - val_accuracy: 0.9524\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2097 - accuracy: 0.9300 - val_loss: 0.1678 - val_accuracy: 0.9592\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2212 - accuracy: 0.9213 - val_loss: 0.1649 - val_accuracy: 0.9592\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9125 - val_loss: 0.1663 - val_accuracy: 0.9592\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2297 - accuracy: 0.9300 - val_loss: 0.1613 - val_accuracy: 0.9592\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2412 - accuracy: 0.9155 - val_loss: 0.1613 - val_accuracy: 0.9524\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2084 - accuracy: 0.9329 - val_loss: 0.1576 - val_accuracy: 0.9592\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2250 - accuracy: 0.9329 - val_loss: 0.1604 - val_accuracy: 0.9592\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2168 - accuracy: 0.9125 - val_loss: 0.1560 - val_accuracy: 0.9524\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2312 - accuracy: 0.9067 - val_loss: 0.1532 - val_accuracy: 0.9592\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1992 - accuracy: 0.9184 - val_loss: 0.1555 - val_accuracy: 0.9592\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2186 - accuracy: 0.9096 - val_loss: 0.1542 - val_accuracy: 0.9388\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2150 - accuracy: 0.9213 - val_loss: 0.1508 - val_accuracy: 0.9660\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2198 - accuracy: 0.9213 - val_loss: 0.1487 - val_accuracy: 0.9660\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1960 - accuracy: 0.9213 - val_loss: 0.1527 - val_accuracy: 0.9388\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2099 - accuracy: 0.9155 - val_loss: 0.1448 - val_accuracy: 0.9660\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2182 - accuracy: 0.9096 - val_loss: 0.1451 - val_accuracy: 0.9524\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.9388 - val_loss: 0.1691 - val_accuracy: 0.9456\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9300 - val_loss: 0.1496 - val_accuracy: 0.9388\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9242 - val_loss: 0.1446 - val_accuracy: 0.9660\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9300 - val_loss: 0.1420 - val_accuracy: 0.9660\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9388 - val_loss: 0.1395 - val_accuracy: 0.9660\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9300 - val_loss: 0.1381 - val_accuracy: 0.9660\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1988 - accuracy: 0.9213 - val_loss: 0.1383 - val_accuracy: 0.9592\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1930 - accuracy: 0.9242 - val_loss: 0.1418 - val_accuracy: 0.9592\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9388 - val_loss: 0.1448 - val_accuracy: 0.9320\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1913 - accuracy: 0.9242 - val_loss: 0.1399 - val_accuracy: 0.9592\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1888 - accuracy: 0.9446 - val_loss: 0.1351 - val_accuracy: 0.9592\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1775 - accuracy: 0.9504 - val_loss: 0.1300 - val_accuracy: 0.9660\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1918 - accuracy: 0.9388 - val_loss: 0.1324 - val_accuracy: 0.9660\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9534 - val_loss: 0.1292 - val_accuracy: 0.9660\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1901 - accuracy: 0.9329 - val_loss: 0.1311 - val_accuracy: 0.9388\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1725 - accuracy: 0.9388 - val_loss: 0.1421 - val_accuracy: 0.9524\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1936 - accuracy: 0.9242 - val_loss: 0.1399 - val_accuracy: 0.9252\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9242 - val_loss: 0.1323 - val_accuracy: 0.9660\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9300 - val_loss: 0.1229 - val_accuracy: 0.9660\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1689 - accuracy: 0.9475 - val_loss: 0.1234 - val_accuracy: 0.9660\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.9388 - val_loss: 0.1210 - val_accuracy: 0.9660\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9417 - val_loss: 0.1222 - val_accuracy: 0.9592\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.9417 - val_loss: 0.1300 - val_accuracy: 0.9592\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1911 - accuracy: 0.9475 - val_loss: 0.1181 - val_accuracy: 0.9660\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.9417 - val_loss: 0.1234 - val_accuracy: 0.9524\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.9359 - val_loss: 0.1261 - val_accuracy: 0.9524\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1491 - accuracy: 0.9621 - val_loss: 0.1176 - val_accuracy: 0.9592\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1743 - accuracy: 0.9329 - val_loss: 0.1210 - val_accuracy: 0.9592\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9592 - val_loss: 0.1139 - val_accuracy: 0.9592\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1475 - accuracy: 0.9504 - val_loss: 0.1140 - val_accuracy: 0.9660\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9534 - val_loss: 0.1105 - val_accuracy: 0.9660\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1665 - accuracy: 0.9475 - val_loss: 0.1121 - val_accuracy: 0.9660\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9388 - val_loss: 0.1102 - val_accuracy: 0.9660\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.9475 - val_loss: 0.1149 - val_accuracy: 0.9524\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1657 - accuracy: 0.9446 - val_loss: 0.1218 - val_accuracy: 0.9592\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1654 - accuracy: 0.9504 - val_loss: 0.1178 - val_accuracy: 0.9524\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9359 - val_loss: 0.1210 - val_accuracy: 0.9524\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1563 - accuracy: 0.9475 - val_loss: 0.1100 - val_accuracy: 0.9592\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9388 - val_loss: 0.1075 - val_accuracy: 0.9660\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1554 - accuracy: 0.9504 - val_loss: 0.1218 - val_accuracy: 0.9592\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9300 - val_loss: 0.1088 - val_accuracy: 0.9592\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1687 - accuracy: 0.9359 - val_loss: 0.1077 - val_accuracy: 0.9592\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1654 - accuracy: 0.9359 - val_loss: 0.1216 - val_accuracy: 0.9728\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1602 - accuracy: 0.9388 - val_loss: 0.1176 - val_accuracy: 0.9524\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1592 - accuracy: 0.9475 - val_loss: 0.1107 - val_accuracy: 0.9524\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9592 - val_loss: 0.1053 - val_accuracy: 0.9592\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1474 - accuracy: 0.9504 - val_loss: 0.1095 - val_accuracy: 0.9592\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9534 - val_loss: 0.1222 - val_accuracy: 0.9728\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1647 - accuracy: 0.9359 - val_loss: 0.1032 - val_accuracy: 0.9660\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9738 - val_loss: 0.1041 - val_accuracy: 0.9592\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9534 - val_loss: 0.1006 - val_accuracy: 0.9592\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1468 - accuracy: 0.9534 - val_loss: 0.1043 - val_accuracy: 0.9592\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9534 - val_loss: 0.0985 - val_accuracy: 0.9660\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1510 - accuracy: 0.9504 - val_loss: 0.1076 - val_accuracy: 0.9592\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1505 - accuracy: 0.9446 - val_loss: 0.1061 - val_accuracy: 0.9592\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1365 - accuracy: 0.9534 - val_loss: 0.1012 - val_accuracy: 0.9592\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9592 - val_loss: 0.0983 - val_accuracy: 0.9592\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9475 - val_loss: 0.0999 - val_accuracy: 0.9592\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9534 - val_loss: 0.0970 - val_accuracy: 0.9592\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1412 - accuracy: 0.9534 - val_loss: 0.0964 - val_accuracy: 0.9660\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.9708 - val_loss: 0.0950 - val_accuracy: 0.9592\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9621 - val_loss: 0.0968 - val_accuracy: 0.9660\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9475 - val_loss: 0.1015 - val_accuracy: 0.9592\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1373 - accuracy: 0.9504 - val_loss: 0.0972 - val_accuracy: 0.9660\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.9563 - val_loss: 0.1217 - val_accuracy: 0.9660\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9388 - val_loss: 0.1008 - val_accuracy: 0.9592\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1316 - accuracy: 0.9563 - val_loss: 0.0981 - val_accuracy: 0.9592\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9679 - val_loss: 0.0954 - val_accuracy: 0.9592\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1391 - accuracy: 0.9475 - val_loss: 0.0939 - val_accuracy: 0.9592\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1438 - accuracy: 0.9446 - val_loss: 0.0988 - val_accuracy: 0.9524\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1273 - accuracy: 0.9621 - val_loss: 0.0938 - val_accuracy: 0.9592\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9592 - val_loss: 0.0960 - val_accuracy: 0.9660\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9592 - val_loss: 0.1108 - val_accuracy: 0.9728\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9446 - val_loss: 0.0990 - val_accuracy: 0.9524\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9563 - val_loss: 0.1057 - val_accuracy: 0.9660\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9621 - val_loss: 0.0981 - val_accuracy: 0.9660\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9504 - val_loss: 0.1080 - val_accuracy: 0.9524\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9446 - val_loss: 0.1075 - val_accuracy: 0.9660\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.9650 - val_loss: 0.0899 - val_accuracy: 0.9660\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.9534 - val_loss: 0.0889 - val_accuracy: 0.9660\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.9504 - val_loss: 0.0883 - val_accuracy: 0.9660\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1242 - accuracy: 0.9621 - val_loss: 0.0973 - val_accuracy: 0.9660\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.9592 - val_loss: 0.1007 - val_accuracy: 0.9524\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1217 - accuracy: 0.9563 - val_loss: 0.0887 - val_accuracy: 0.9660\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1040 - accuracy: 0.9650 - val_loss: 0.0884 - val_accuracy: 0.9660\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9592 - val_loss: 0.0962 - val_accuracy: 0.9728\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9446 - val_loss: 0.0947 - val_accuracy: 0.9728\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.9592 - val_loss: 0.0881 - val_accuracy: 0.9660\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9650 - val_loss: 0.0912 - val_accuracy: 0.9728\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9621 - val_loss: 0.0932 - val_accuracy: 0.9728\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9563 - val_loss: 0.0906 - val_accuracy: 0.9592\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9796 - val_loss: 0.0901 - val_accuracy: 0.9660\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9708 - val_loss: 0.0958 - val_accuracy: 0.9524\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9621 - val_loss: 0.0957 - val_accuracy: 0.9728\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9679 - val_loss: 0.0889 - val_accuracy: 0.9660\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9563 - val_loss: 0.1042 - val_accuracy: 0.9456\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9475 - val_loss: 0.0985 - val_accuracy: 0.9728\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.9708 - val_loss: 0.0890 - val_accuracy: 0.9660\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9650 - val_loss: 0.0899 - val_accuracy: 0.9592\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9708 - val_loss: 0.0919 - val_accuracy: 0.9728\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1239 - accuracy: 0.9534 - val_loss: 0.0982 - val_accuracy: 0.9728\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9592 - val_loss: 0.0909 - val_accuracy: 0.9524\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1091 - accuracy: 0.9504 - val_loss: 0.0873 - val_accuracy: 0.9660\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1084 - accuracy: 0.9563 - val_loss: 0.0931 - val_accuracy: 0.9796\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9679 - val_loss: 0.0868 - val_accuracy: 0.9660\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9650 - val_loss: 0.0866 - val_accuracy: 0.9660\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.9708 - val_loss: 0.0853 - val_accuracy: 0.9660\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.9650 - val_loss: 0.0888 - val_accuracy: 0.9592\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.9621 - val_loss: 0.0882 - val_accuracy: 0.9728\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9708 - val_loss: 0.0891 - val_accuracy: 0.9728\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9592 - val_loss: 0.0879 - val_accuracy: 0.9660\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9796 - val_loss: 0.0903 - val_accuracy: 0.9728\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9650 - val_loss: 0.0882 - val_accuracy: 0.9524\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0935 - accuracy: 0.9650 - val_loss: 0.0857 - val_accuracy: 0.9660\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9650 - val_loss: 0.0855 - val_accuracy: 0.9660\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9738 - val_loss: 0.0910 - val_accuracy: 0.9728\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9504 - val_loss: 0.1057 - val_accuracy: 0.9456\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.9679 - val_loss: 0.0889 - val_accuracy: 0.9728\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9767 - val_loss: 0.0912 - val_accuracy: 0.9728\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9796 - val_loss: 0.0933 - val_accuracy: 0.9728\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9621 - val_loss: 0.0861 - val_accuracy: 0.9660\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9650 - val_loss: 0.0870 - val_accuracy: 0.9660\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9621 - val_loss: 0.0893 - val_accuracy: 0.9728\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0893 - accuracy: 0.9650 - val_loss: 0.0993 - val_accuracy: 0.9456\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9650 - val_loss: 0.0887 - val_accuracy: 0.9660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJTKDERlGBIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa2d8a7-9f1a-42b3-8897-69dc367155f8"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   0   1\n",
            "Actual         \n",
            "0        69   3\n",
            "1         2  73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a46dde-d152-45af-b5e1-c6886c8ef63b"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNDIL0I5HBzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bcd14ea-ff10-4a3e-fcaa-4fd5ede15b48"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[2] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  #prediction = model.predict_classes(result)\n",
        "  prediction = np.argmax(model.predict(result), axis=-1)\n",
        "  loc_grao =[];k=0\n",
        "  for i in prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0   172.0  122.342361  131.372101  ...  181.855057  174.899963  159.308807\n",
            "3   193.0    0.187173    0.315928  ...    7.384923    7.383420    7.619452\n",
            "4   103.0  136.503815  136.014984  ...  146.499466  146.234589  145.218506\n",
            "5   169.0  176.904602  140.640839  ...  107.533974  119.726982  123.530304\n",
            "6   107.0  117.685814  115.097305  ...   93.725044   84.245613   83.938332\n",
            "11  143.0  106.582817  106.743027  ...    7.670546    8.964106    9.373025\n",
            "13  172.0  111.638733  121.967018  ...  114.441879  132.679291  148.480804\n",
            "14  178.0  141.126892  139.171570  ...  145.532394  144.001404  144.023376\n",
            "16  130.0   76.077156   64.618698  ...    7.052072    6.813965    5.904142\n",
            "17  128.0   83.059570   84.755859  ...   59.548828   59.777344   58.798828\n",
            "19  171.0  135.176193  135.834915  ...   48.182175   73.298073  150.721497\n",
            "20  151.0  140.393005  140.727829  ...  142.171494  138.417084  137.861679\n",
            "21  174.0   54.430443   50.211662  ...    8.152729    7.854803    7.512618\n",
            "27  127.0  234.744186  252.769226  ...  163.929489  165.517090  168.906265\n",
            "28  151.0   84.045830   85.736816  ...  105.848648  109.476425  109.374855\n",
            "29  172.0  119.490540  123.633858  ...   63.566254   66.693893   69.593292\n",
            "31  138.0  114.267792  114.308960  ...   97.105644   55.890774   61.469860\n",
            "33  120.0  154.575562  157.088913  ...   99.116669   96.313332   94.468887\n",
            "35  186.0  134.344681  135.781158  ...  104.966469  107.488503  104.989258\n",
            "36  200.0  123.355209  117.485596  ...  115.367989  116.674797  114.084793\n",
            "38  117.0  118.946304  109.462791  ...  115.311348  116.148804  115.714737\n",
            "40  123.0  112.048721  113.274582  ...  161.939468  182.450607  191.255417\n",
            "43  159.0   81.945847   77.845619  ...   90.732841   91.364380   90.640671\n",
            "44  127.0   95.361275  102.065353  ...   59.055550   60.184261   59.760433\n",
            "47  138.0  166.903183  171.554703  ...  110.316528  111.494011  112.955460\n",
            "48  164.0  147.001175  142.916122  ...   92.629395   57.355148    1.830458\n",
            "\n",
            "[26 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRbWgmX_LFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859cf0a1-2fdc-4883-d6f3-5138df638152"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_paper_fev_2021' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6ckWQjGGfa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de197a40-30f1-45df-b092-fafa2fadda89"
      },
      "source": [
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "\n",
        "%cd Doutorado\n",
        "\n",
        "PSD_imageJ = 'Amostra7.csv' \n",
        "PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "   Unnamed: 0   Area\n",
            "0           1  1.387\n",
            "1           2  1.626\n",
            "2           3  1.336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekBHQOT_6CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "02b2eaa1-2caf-48a2-91d0-e0a02c9fe20b"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>172.0</td>\n",
              "      <td>122.342361</td>\n",
              "      <td>131.372101</td>\n",
              "      <td>136.660919</td>\n",
              "      <td>144.073563</td>\n",
              "      <td>149.807465</td>\n",
              "      <td>151.860489</td>\n",
              "      <td>145.995682</td>\n",
              "      <td>106.234184</td>\n",
              "      <td>94.091949</td>\n",
              "      <td>113.922119</td>\n",
              "      <td>131.554916</td>\n",
              "      <td>148.676025</td>\n",
              "      <td>139.879929</td>\n",
              "      <td>133.356949</td>\n",
              "      <td>134.662537</td>\n",
              "      <td>136.847488</td>\n",
              "      <td>139.089233</td>\n",
              "      <td>141.762039</td>\n",
              "      <td>145.752319</td>\n",
              "      <td>146.690643</td>\n",
              "      <td>146.462418</td>\n",
              "      <td>149.498657</td>\n",
              "      <td>160.185516</td>\n",
              "      <td>167.687958</td>\n",
              "      <td>170.252029</td>\n",
              "      <td>156.316391</td>\n",
              "      <td>127.671181</td>\n",
              "      <td>133.031906</td>\n",
              "      <td>127.620346</td>\n",
              "      <td>137.196320</td>\n",
              "      <td>142.368851</td>\n",
              "      <td>146.205521</td>\n",
              "      <td>149.325058</td>\n",
              "      <td>156.938354</td>\n",
              "      <td>159.116287</td>\n",
              "      <td>142.534348</td>\n",
              "      <td>100.740417</td>\n",
              "      <td>104.626289</td>\n",
              "      <td>130.247711</td>\n",
              "      <td>...</td>\n",
              "      <td>150.446747</td>\n",
              "      <td>159.209854</td>\n",
              "      <td>170.239044</td>\n",
              "      <td>175.322876</td>\n",
              "      <td>187.562469</td>\n",
              "      <td>222.344513</td>\n",
              "      <td>241.067078</td>\n",
              "      <td>214.168198</td>\n",
              "      <td>122.147110</td>\n",
              "      <td>177.523529</td>\n",
              "      <td>175.289337</td>\n",
              "      <td>159.424561</td>\n",
              "      <td>107.959442</td>\n",
              "      <td>106.232567</td>\n",
              "      <td>107.758789</td>\n",
              "      <td>109.964851</td>\n",
              "      <td>116.596008</td>\n",
              "      <td>122.231476</td>\n",
              "      <td>118.822067</td>\n",
              "      <td>127.941605</td>\n",
              "      <td>144.603043</td>\n",
              "      <td>148.285034</td>\n",
              "      <td>148.018387</td>\n",
              "      <td>147.432129</td>\n",
              "      <td>143.030838</td>\n",
              "      <td>141.791245</td>\n",
              "      <td>145.036240</td>\n",
              "      <td>149.763657</td>\n",
              "      <td>156.056793</td>\n",
              "      <td>165.065430</td>\n",
              "      <td>173.572723</td>\n",
              "      <td>180.565720</td>\n",
              "      <td>193.873993</td>\n",
              "      <td>211.666321</td>\n",
              "      <td>220.799377</td>\n",
              "      <td>161.280701</td>\n",
              "      <td>164.837219</td>\n",
              "      <td>181.855057</td>\n",
              "      <td>174.899963</td>\n",
              "      <td>159.308807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>193.0</td>\n",
              "      <td>0.187173</td>\n",
              "      <td>0.315928</td>\n",
              "      <td>1.368574</td>\n",
              "      <td>5.062418</td>\n",
              "      <td>19.398935</td>\n",
              "      <td>47.040810</td>\n",
              "      <td>57.377460</td>\n",
              "      <td>61.014061</td>\n",
              "      <td>61.132332</td>\n",
              "      <td>54.725285</td>\n",
              "      <td>51.970421</td>\n",
              "      <td>60.586269</td>\n",
              "      <td>79.272705</td>\n",
              "      <td>90.152512</td>\n",
              "      <td>88.259605</td>\n",
              "      <td>90.744713</td>\n",
              "      <td>96.050575</td>\n",
              "      <td>95.988144</td>\n",
              "      <td>99.139999</td>\n",
              "      <td>104.026840</td>\n",
              "      <td>107.994423</td>\n",
              "      <td>109.543999</td>\n",
              "      <td>114.772453</td>\n",
              "      <td>126.287445</td>\n",
              "      <td>132.694153</td>\n",
              "      <td>134.745850</td>\n",
              "      <td>136.346069</td>\n",
              "      <td>137.946320</td>\n",
              "      <td>0.031303</td>\n",
              "      <td>0.889742</td>\n",
              "      <td>2.674917</td>\n",
              "      <td>10.215737</td>\n",
              "      <td>47.689739</td>\n",
              "      <td>60.540340</td>\n",
              "      <td>60.817230</td>\n",
              "      <td>60.328953</td>\n",
              "      <td>59.628716</td>\n",
              "      <td>60.256493</td>\n",
              "      <td>59.398857</td>\n",
              "      <td>...</td>\n",
              "      <td>0.196703</td>\n",
              "      <td>0.160622</td>\n",
              "      <td>0.160622</td>\n",
              "      <td>0.160622</td>\n",
              "      <td>0.218502</td>\n",
              "      <td>0.305699</td>\n",
              "      <td>0.273376</td>\n",
              "      <td>0.160622</td>\n",
              "      <td>0.160622</td>\n",
              "      <td>0.160622</td>\n",
              "      <td>0.247067</td>\n",
              "      <td>0.153856</td>\n",
              "      <td>1.873473</td>\n",
              "      <td>3.928616</td>\n",
              "      <td>5.589868</td>\n",
              "      <td>6.412978</td>\n",
              "      <td>6.680582</td>\n",
              "      <td>6.948187</td>\n",
              "      <td>6.606164</td>\n",
              "      <td>6.367124</td>\n",
              "      <td>7.475126</td>\n",
              "      <td>6.986523</td>\n",
              "      <td>7.465354</td>\n",
              "      <td>7.904346</td>\n",
              "      <td>6.359607</td>\n",
              "      <td>7.484146</td>\n",
              "      <td>6.889554</td>\n",
              "      <td>7.512711</td>\n",
              "      <td>7.405219</td>\n",
              "      <td>7.483396</td>\n",
              "      <td>7.051168</td>\n",
              "      <td>7.025611</td>\n",
              "      <td>7.112057</td>\n",
              "      <td>7.378157</td>\n",
              "      <td>7.456334</td>\n",
              "      <td>7.539021</td>\n",
              "      <td>8.142634</td>\n",
              "      <td>7.384923</td>\n",
              "      <td>7.383420</td>\n",
              "      <td>7.619452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>103.0</td>\n",
              "      <td>136.503815</td>\n",
              "      <td>136.014984</td>\n",
              "      <td>137.558395</td>\n",
              "      <td>137.970673</td>\n",
              "      <td>137.405029</td>\n",
              "      <td>136.197372</td>\n",
              "      <td>132.837860</td>\n",
              "      <td>130.777176</td>\n",
              "      <td>128.084366</td>\n",
              "      <td>124.624458</td>\n",
              "      <td>121.255440</td>\n",
              "      <td>118.718918</td>\n",
              "      <td>118.570267</td>\n",
              "      <td>117.470261</td>\n",
              "      <td>117.934006</td>\n",
              "      <td>133.528137</td>\n",
              "      <td>155.634644</td>\n",
              "      <td>165.175613</td>\n",
              "      <td>174.994720</td>\n",
              "      <td>183.153641</td>\n",
              "      <td>198.477509</td>\n",
              "      <td>210.075974</td>\n",
              "      <td>210.265442</td>\n",
              "      <td>204.302948</td>\n",
              "      <td>189.311050</td>\n",
              "      <td>174.088715</td>\n",
              "      <td>172.682724</td>\n",
              "      <td>166.701187</td>\n",
              "      <td>137.200012</td>\n",
              "      <td>138.064743</td>\n",
              "      <td>138.217819</td>\n",
              "      <td>136.863693</td>\n",
              "      <td>132.885666</td>\n",
              "      <td>129.117157</td>\n",
              "      <td>128.252518</td>\n",
              "      <td>129.478073</td>\n",
              "      <td>129.036560</td>\n",
              "      <td>129.001694</td>\n",
              "      <td>128.416733</td>\n",
              "      <td>...</td>\n",
              "      <td>141.593552</td>\n",
              "      <td>145.755112</td>\n",
              "      <td>148.531906</td>\n",
              "      <td>150.790359</td>\n",
              "      <td>151.573944</td>\n",
              "      <td>152.347824</td>\n",
              "      <td>151.904510</td>\n",
              "      <td>152.018753</td>\n",
              "      <td>151.183426</td>\n",
              "      <td>149.213013</td>\n",
              "      <td>147.640198</td>\n",
              "      <td>146.999985</td>\n",
              "      <td>136.685638</td>\n",
              "      <td>139.880661</td>\n",
              "      <td>142.932327</td>\n",
              "      <td>143.698273</td>\n",
              "      <td>144.661224</td>\n",
              "      <td>144.460449</td>\n",
              "      <td>146.399750</td>\n",
              "      <td>145.152313</td>\n",
              "      <td>144.026215</td>\n",
              "      <td>141.533783</td>\n",
              "      <td>136.277115</td>\n",
              "      <td>125.651993</td>\n",
              "      <td>119.938721</td>\n",
              "      <td>124.511261</td>\n",
              "      <td>133.245926</td>\n",
              "      <td>137.646515</td>\n",
              "      <td>140.828735</td>\n",
              "      <td>144.398712</td>\n",
              "      <td>146.221985</td>\n",
              "      <td>147.492218</td>\n",
              "      <td>151.092651</td>\n",
              "      <td>154.088043</td>\n",
              "      <td>153.319153</td>\n",
              "      <td>151.667740</td>\n",
              "      <td>148.937027</td>\n",
              "      <td>146.499466</td>\n",
              "      <td>146.234589</td>\n",
              "      <td>145.218506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>169.0</td>\n",
              "      <td>176.904602</td>\n",
              "      <td>140.640839</td>\n",
              "      <td>90.492897</td>\n",
              "      <td>97.753578</td>\n",
              "      <td>94.019646</td>\n",
              "      <td>95.961456</td>\n",
              "      <td>95.330620</td>\n",
              "      <td>98.520500</td>\n",
              "      <td>111.518784</td>\n",
              "      <td>127.484673</td>\n",
              "      <td>129.039032</td>\n",
              "      <td>121.322144</td>\n",
              "      <td>115.568314</td>\n",
              "      <td>116.047707</td>\n",
              "      <td>117.803741</td>\n",
              "      <td>119.396835</td>\n",
              "      <td>120.422523</td>\n",
              "      <td>121.499313</td>\n",
              "      <td>122.282234</td>\n",
              "      <td>124.249107</td>\n",
              "      <td>131.210800</td>\n",
              "      <td>138.110489</td>\n",
              "      <td>142.113983</td>\n",
              "      <td>136.225067</td>\n",
              "      <td>104.057457</td>\n",
              "      <td>73.525536</td>\n",
              "      <td>81.672241</td>\n",
              "      <td>79.988342</td>\n",
              "      <td>174.585236</td>\n",
              "      <td>143.386948</td>\n",
              "      <td>88.112877</td>\n",
              "      <td>99.591179</td>\n",
              "      <td>93.912216</td>\n",
              "      <td>94.001854</td>\n",
              "      <td>97.013832</td>\n",
              "      <td>101.976746</td>\n",
              "      <td>111.872620</td>\n",
              "      <td>128.615097</td>\n",
              "      <td>128.626450</td>\n",
              "      <td>...</td>\n",
              "      <td>85.670914</td>\n",
              "      <td>88.744255</td>\n",
              "      <td>90.948555</td>\n",
              "      <td>96.483521</td>\n",
              "      <td>101.251198</td>\n",
              "      <td>119.908600</td>\n",
              "      <td>126.819717</td>\n",
              "      <td>78.798775</td>\n",
              "      <td>80.414055</td>\n",
              "      <td>111.309753</td>\n",
              "      <td>117.326660</td>\n",
              "      <td>119.492058</td>\n",
              "      <td>74.615517</td>\n",
              "      <td>75.480270</td>\n",
              "      <td>75.288284</td>\n",
              "      <td>73.889038</td>\n",
              "      <td>73.013329</td>\n",
              "      <td>73.504005</td>\n",
              "      <td>75.715759</td>\n",
              "      <td>80.493263</td>\n",
              "      <td>88.078773</td>\n",
              "      <td>96.907379</td>\n",
              "      <td>103.866287</td>\n",
              "      <td>102.185242</td>\n",
              "      <td>92.670250</td>\n",
              "      <td>92.037071</td>\n",
              "      <td>91.617165</td>\n",
              "      <td>89.805672</td>\n",
              "      <td>87.194740</td>\n",
              "      <td>89.097397</td>\n",
              "      <td>91.692719</td>\n",
              "      <td>94.274704</td>\n",
              "      <td>101.874855</td>\n",
              "      <td>111.894897</td>\n",
              "      <td>100.873985</td>\n",
              "      <td>43.068096</td>\n",
              "      <td>57.029865</td>\n",
              "      <td>107.533974</td>\n",
              "      <td>119.726982</td>\n",
              "      <td>123.530304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>107.0</td>\n",
              "      <td>117.685814</td>\n",
              "      <td>115.097305</td>\n",
              "      <td>115.542229</td>\n",
              "      <td>116.424057</td>\n",
              "      <td>116.181061</td>\n",
              "      <td>118.522926</td>\n",
              "      <td>120.260727</td>\n",
              "      <td>119.271988</td>\n",
              "      <td>119.773430</td>\n",
              "      <td>118.531219</td>\n",
              "      <td>116.529388</td>\n",
              "      <td>115.463440</td>\n",
              "      <td>114.264130</td>\n",
              "      <td>113.208664</td>\n",
              "      <td>113.036942</td>\n",
              "      <td>113.429642</td>\n",
              "      <td>122.168312</td>\n",
              "      <td>137.576126</td>\n",
              "      <td>147.252594</td>\n",
              "      <td>153.990997</td>\n",
              "      <td>161.954834</td>\n",
              "      <td>167.461517</td>\n",
              "      <td>171.678848</td>\n",
              "      <td>170.407288</td>\n",
              "      <td>166.591766</td>\n",
              "      <td>148.880341</td>\n",
              "      <td>130.270599</td>\n",
              "      <td>130.354095</td>\n",
              "      <td>115.234787</td>\n",
              "      <td>113.721634</td>\n",
              "      <td>113.246475</td>\n",
              "      <td>114.842781</td>\n",
              "      <td>115.868019</td>\n",
              "      <td>118.728348</td>\n",
              "      <td>119.605293</td>\n",
              "      <td>117.584503</td>\n",
              "      <td>117.403091</td>\n",
              "      <td>116.128395</td>\n",
              "      <td>112.294785</td>\n",
              "      <td>...</td>\n",
              "      <td>89.745392</td>\n",
              "      <td>77.741379</td>\n",
              "      <td>79.250771</td>\n",
              "      <td>82.072678</td>\n",
              "      <td>84.906189</td>\n",
              "      <td>86.690620</td>\n",
              "      <td>86.742599</td>\n",
              "      <td>84.324570</td>\n",
              "      <td>83.108749</td>\n",
              "      <td>82.967064</td>\n",
              "      <td>85.133904</td>\n",
              "      <td>88.533142</td>\n",
              "      <td>130.684784</td>\n",
              "      <td>130.759552</td>\n",
              "      <td>131.199402</td>\n",
              "      <td>130.607910</td>\n",
              "      <td>130.616028</td>\n",
              "      <td>131.088913</td>\n",
              "      <td>131.635590</td>\n",
              "      <td>130.698578</td>\n",
              "      <td>132.528778</td>\n",
              "      <td>134.274078</td>\n",
              "      <td>134.589920</td>\n",
              "      <td>138.001740</td>\n",
              "      <td>138.269730</td>\n",
              "      <td>132.620834</td>\n",
              "      <td>117.582062</td>\n",
              "      <td>93.052048</td>\n",
              "      <td>75.593765</td>\n",
              "      <td>77.023933</td>\n",
              "      <td>77.170929</td>\n",
              "      <td>78.586601</td>\n",
              "      <td>85.523712</td>\n",
              "      <td>107.297318</td>\n",
              "      <td>115.915276</td>\n",
              "      <td>115.057556</td>\n",
              "      <td>108.273560</td>\n",
              "      <td>93.725044</td>\n",
              "      <td>84.245613</td>\n",
              "      <td>83.938332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "0  172.0  122.342361  131.372101  ...  181.855057  174.899963  159.308807\n",
              "3  193.0    0.187173    0.315928  ...    7.384923    7.383420    7.619452\n",
              "4  103.0  136.503815  136.014984  ...  146.499466  146.234589  145.218506\n",
              "5  169.0  176.904602  140.640839  ...  107.533974  119.726982  123.530304\n",
              "6  107.0  117.685814  115.097305  ...   93.725044   84.245613   83.938332\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "Area = np.array(PSD_new['Area'])\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J705kDqsE8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89884c4-ccd9-4c1e-aa8a-5b75768833db"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "85d3d39e-3436-4418-d218-efe0e9172b3a"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8040be5490>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "13911a18-21f9-4e7f-fd2a-8c0680fcea28"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.02941176, 0.07843137, 0.35294118, 0.68627451, 0.8627451 ,\n",
              "         0.91176471, 0.97058824, 0.99019608, 0.99019608, 1.        ],\n",
              "        [0.07692308, 0.34615385, 0.57692308, 0.80769231, 0.96153846,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.77401142, 0.95510518, 1.13619893, 1.31729269, 1.49838644,\n",
              "        1.67948019, 1.86057395, 2.0416677 , 2.22276145, 2.40385521,\n",
              "        2.58494896]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xENlBUUxfTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "89fce8f2-bd45-4270-80a7-27276dd93770"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r_squared = 0.8840628011552635\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KukfpGTTKlj"
      },
      "source": [
        "#df"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bT8GFymJAII"
      },
      "source": [
        "# r.history['accuracy']"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uPdRxL2VwLR"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e5839e21-83fc-48dd-9a45-953caa6ad41c"
      },
      "source": [
        "\n",
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n",
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c6892e4d-9e71-40ec-a7ec-e56de64fa321\", \"output.xlsx\", 5145)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHa1j4HT9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "e2841dd9-3785-43e9-8668-157a8ad44a6b"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.77401142 0.95510518 1.13619893 1.31729269 1.49838644 1.67948019\n",
            " 1.86057395 2.0416677  2.22276145 2.40385521 2.58494896]\n",
            "[[ 2.94117647  4.90196078 27.45098039 33.33333333 17.64705882  4.90196078\n",
            "   5.88235294  1.96078431  0.          0.98039216]\n",
            " [ 7.69230769 26.92307692 23.07692308 23.07692308 15.38461538  3.84615385\n",
            "   0.          0.          0.          0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPiklEQVR4nO3df4zkdX3H8edLOIpFAkfZ0guCh0qkmNSDbqi/YhBrixADJqaBNOTS0JxtxGhiTC/+oaftH9dEpWlqrWehnIlijUo1otYL0Bhrxe7RAw5Q+eG15XJyq8ivtqE5fPeP+V4d1t2d2d2ZnfnI85FMdubz/czNa7/7vdd99zvf71yqCklSe5436QCSpNWxwCWpURa4JDXKApekRlngktQoC1ySGjWwwJMcn+Q7Se5Mck+SD3TjNyT5QZJ93W3L+ONKko46dog5TwMXVdVTSTYA30zy1W7Ze6rqc+OLJ0laysACr96VPk91Dzd0N6/+kaQJyzBXYiY5BtgLvBT4aFX9SZIbgFfR20O/BdheVU8v8txtwDaAE0444TfPOeec0aWXpOeAvXv3/qiqZhaOD1Xg/z85ORm4CXgH8GPgh8BxwC7gwar64HLPn52drbm5uZXklqTnvCR7q2p24fiKzkKpqseA24CLq+pQ9TwN/B1wwWiiSpKGMcxZKDPdnjdJng+8Efhukk3dWIDLgf3jDCpJerZhzkLZBOzujoM/D/hsVX05ya1JZoAA+4A/GmNOSdICw5yFchdw3iLjF40lkSRpKF6JKUmNssAlqVEWuCQ1ygKXpEZZ4JLUqGFOI9Rz1ObtN6/4OQd2XjqGJJIW4x64JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRAws8yfFJvpPkziT3JPlAN35WktuTPJDk75McN/64kqSjhtkDfxq4qKpeAWwBLk7ySuDPgWur6qXAT4CrxxdTkrTQwAKvnqe6hxu6WwEXAZ/rxncDl48loSRpUUMdA09yTJJ9wGFgD/Ag8FhVHemmPAycvsRztyWZSzI3Pz8/isySJIYs8Kp6pqq2AC8ELgDOGfYFqmpXVc1W1ezMzMwqY0qSFlrRWShV9RhwG/Aq4OQkR/9X+xcCB0ecTZK0jGHOQplJcnJ3//nAG4H76BX5W7tpW4EvjiukJOnnHTt4CpuA3UmOoVf4n62qLye5F/hMkj8D/g24bow5JUkLDCzwqroLOG+R8YfoHQ+XJE2AV2JKUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJatQwn4WiCdq8/eYVP+fAzkvHkETStHEPXJIaZYFLUqMscElqlMfAx2XHSSuc//h4ckj6heUeuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjRpY4EnOSHJbknuT3JPknd34jiQHk+zrbpeMP64k6ahhLuQ5Ary7qu5IciKwN8mebtm1VfWh8cWTJC1lYIFX1SHgUHf/yST3AaePO5gkaXkrOgaeZDNwHnB7N3RNkruSXJ9k4xLP2ZZkLsnc/Pz8msJKkn5m6AJP8gLg88C7quoJ4GPAS4At9PbQP7zY86pqV1XNVtXszMzMCCJLkmDIAk+ygV55f6qqvgBQVY9U1TNV9VPgE8AF44spSVpomLNQAlwH3FdVH+kb39Q37S3A/tHHkyQtZZizUF4DXAXcnWRfN/Ze4MokW4ACDgBvG0tCSdKihjkL5ZtAFln0ldHHkSQNyysxJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqOGOQ9crdlx0grnP/6L8drSc4x74JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDVqYIEnOSPJbUnuTXJPknd246ck2ZPk/u7rxvHHlSQdNcwe+BHg3VV1LvBK4O1JzgW2A7dU1dnALd1jSdI6GVjgVXWoqu7o7j8J3AecDlwG7O6m7QYuH1dISdLPW9Ex8CSbgfOA24HTqupQt+iHwGkjTSZJWtbQBZ7kBcDngXdV1RP9y6qqgFrieduSzCWZm5+fX1NYSdLPDFXgSTbQK+9PVdUXuuFHkmzqlm8CDi/23KraVVWzVTU7MzMzisySJIY7CyXAdcB9VfWRvkVfArZ297cCXxx9PEnSUo4dYs5rgKuAu5Ps68beC+wEPpvkauDfgd8bT0RJ0mIGFnhVfRPIEovfMNo4kqRheSWmJDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1aphL6aV1t3n7zSt+zoGdl44hiTS93AOXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMGFniS65McTrK/b2xHkoNJ9nW3S8YbU5K00DCfRngD8FfAJxeMX1tVHxp5Imm1dpy0wvmPjyeHtE4G7oFX1TeAR9chiyRpBdZyDPyaJHd1h1g2jiyRJGkoqy3wjwEvAbYAh4APLzUxybYkc0nm5ufnV/lykqSFVlXgVfVIVT1TVT8FPgFcsMzcXVU1W1WzMzMzq80pSVpgVQWeZFPfw7cA+5eaK0kaj4FnoSS5EbgQODXJw8D7gQuTbAEKOAC8bYwZJUmLGFjgVXXlIsPXjSGLJGkFvBJTkhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEYNLPAk1yc5nGR/39gpSfYkub/7unG8MSVJCw2zB34DcPGCse3ALVV1NnBL91iStI4GFnhVfQN4dMHwZcDu7v5u4PIR55IkDbDaY+CnVdWh7v4PgdOWmphkW5K5JHPz8/OrfDlJ0kJrfhOzqgqoZZbvqqrZqpqdmZlZ68tJkjqrLfBHkmwC6L4eHl0kSdIwVlvgXwK2dve3Al8cTRxJ0rCGOY3wRuBfgJcleTjJ1cBO4I1J7gd+u3ssSVpHxw6aUFVXLrHoDSPOIklaAa/ElKRGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDVq4IU8Tdtx0grnPz6eHJI0Bu6BS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWrUL/al9FKDNm+/eUXzD+y8dExJNO3cA5ekRlngktSoNR1CSXIAeBJ4BjhSVbOjCCVJGmwUx8BfX1U/GsGfI0laAQ+hSFKj1roHXsDXkxTw8aratXBCkm3ANoAzzzxzjS83GSs9KwDgwPFjCKJ1saqft2eCaALWugf+2qo6H3gT8PYkr1s4oap2VdVsVc3OzMys8eUkSUetqcCr6mD39TBwE3DBKEJJkgZbdYEnOSHJiUfvA78D7B9VMEnS8tZyDPw04KYkR/+cT1fV10aSSpI00KoLvKoeAl4xwiySpBXwNEJJapQfZiWNwo6TVjj/8fHk0HOKe+CS1CgLXJIaZYFLUqMscElqlAUuSY1q5iwUP1BKkp7NPXBJapQFLkmNssAlqVEWuCQ1ygKXpEY1cxaKpPFb6dle/ldyk+UeuCQ1ygKXpEZZ4JLUKAtckhplgUtSozwLRdJzXqtn37gHLkmNssAlqVFrKvAkFyf5XpIHkmwfVShJ0mCrLvAkxwAfBd4EnAtcmeTcUQWTJC1vLXvgFwAPVNVDVfW/wGeAy0YTS5I0SKpqdU9M3gpcXFV/2D2+CvitqrpmwbxtwLbu4cuA7y3zx54K/GhVgdafWcejlayt5ASzjst6Zn1RVc0sHBz7aYRVtQvYNczcJHNVNTvmSCNh1vFoJWsrOcGs4zINWddyCOUgcEbf4xd2Y5KkdbCWAv9X4OwkZyU5DrgC+NJoYkmSBln1IZSqOpLkGuAfgWOA66vqnjXmGepQy5Qw63i0krWVnGDWcZl41lW/iSlJmiyvxJSkRlngktSodSnwQZfcJ7k2yb7u9v0kj/Ute6Zv2djfJE1yfZLDSfYvsTxJ/rL7Xu5Kcn7fsq1J7u9uW6cg6+93Ge9O8q0kr+hbdqAb35dkbgqyXpjk8b6f9fv6lq3bRzYMkfM9fRn3d9vnKd2y9V6nZyS5Lcm9Se5J8s5F5kzF9jpk1qnYXofMOhXbK1U11hu9NzgfBF4MHAfcCZy7zPx30HtD9Ojjp8adccHrvw44H9i/xPJLgK8CAV4J3N6NnwI81H3d2N3fOOGsrz6agd5HHtzet+wAcOoUrdcLgS+vdfsZd84Fc98M3DrBdboJOL+7fyLw/YXrZlq21yGzTsX2OmTWqdhe12MPfKWX3F8J3LgOuRZVVd8AHl1mymXAJ6vn28DJSTYBvwvsqapHq+onwB7g4klmrapvdVkAvk3vXP2JGGK9LmVdP7JhhTknva0eqqo7uvtPAvcBpy+YNhXb6zBZp2V7HXK9LmVdt9f1KPDTgf/se/wwS6yMJC8CzgJu7Rs+Pslckm8nuXx8MYe21Pcz9Pc5IVfT2xM7qoCvJ9mb3scdTINXJbkzyVeTvLwbm8r1muSX6RXe5/uGJ7ZOk2wGzgNuX7Bo6rbXZbL2m4rtdUDWiW+v0/Y/8lwBfK6qnukbe1FVHUzyYuDWJHdX1YMTytekJK+n9xfitX3Dr+3W668Ce5J8t9v7nJQ76P2sn0pyCfAPwNkTzDPIm4F/rqr+vfWJrNMkL6D3D8m7quqJcb/eWgyTdVq21wFZp2J7XY898JVccn8FC34lraqD3deHgH+i96/hJC31/UzlRwsk+Q3gb4HLqurHR8f71uth4CZ6v/pNTFU9UVVPdfe/AmxIcipTul5Zfltdt3WaZAO9kvlUVX1hkSlTs70OkXVqttdBWadme12HNwSOpfcGyVn87KD+yxeZdw69NyrSN7YR+KXu/qnA/YzxDYG+193M0m+2Xcqz3xT6Tjd+CvCDLvPG7v4pE856JvAA8OoF4ycAJ/bd/xa9T5acZNZfO/qzp/eX8z+6dTzU9rNeObvlJ9E7Tn7CJNdpt34+CfzFMnOmYnsdMutUbK9DZp2K7XU9Po1w0Uvuk3wQmKuqo6cGXgF8pro10vl14ONJfkrvt4WdVXXvOPMmuZHeO8ynJnkYeD+wofte/gb4Cr139h8A/hv4g27Zo0n+lN5nxAB8sJ796/Uksr4P+BXgr5MAHKnep6edBtzUjR0LfLqqvjbhrG8F/jjJEeB/gCu6bWEcH9mwlpwAbwG+XlX/1ffUdV+nwGuAq4C7k+zrxt5LrwinbXsdJuu0bK/DZJ2O7fXZfSlJaoVXYkpSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1Kj/A6MpgviaUMluAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad21f18-bc13-4581-e7ea-4d16f67325d2"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "199.99999999999994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "d925599d-f456-434e-b7d3-b302146c58ef"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8048f6a850>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c1d611-ec58-428a-9d38-79a6cfa9772e"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.3289030245084366,\n",
              "  1.4388493665910183,\n",
              "  1.3042423209535017,\n",
              "  0.9027033336764101,\n",
              "  1.6778356991700483,\n",
              "  1.1941642642883694,\n",
              "  1.113613629842976,\n",
              "  1.254988970803089,\n",
              "  1.2815923738491737,\n",
              "  2.186553107171316,\n",
              "  1.8807071689325485,\n",
              "  1.2645903954195463,\n",
              "  1.3284238815238665,\n",
              "  1.2875394701698204,\n",
              "  1.1677497815933682,\n",
              "  1.3805939296073044,\n",
              "  1.3902437300372827,\n",
              "  1.2585348599266302,\n",
              "  1.3966398900698307,\n",
              "  1.2988619621707653,\n",
              "  1.3907015741893414,\n",
              "  1.5533154661153457,\n",
              "  1.2463355264843006,\n",
              "  1.2570164179581493,\n",
              "  1.2870449283923413,\n",
              "  1.3488733481786004,\n",
              "  0.9215480325725586,\n",
              "  1.6572198701420842,\n",
              "  1.157345238492556,\n",
              "  1.6281537802488464,\n",
              "  1.3897857350553149,\n",
              "  1.2771138777750963,\n",
              "  0.9991095050455518,\n",
              "  1.165567069812981,\n",
              "  1.875962180228586,\n",
              "  1.2437789380968078,\n",
              "  1.0957485526731296,\n",
              "  1.6667959343039342,\n",
              "  1.3755122549350303,\n",
              "  1.413404699896484,\n",
              "  1.8427506249649406,\n",
              "  0.9501193805081709,\n",
              "  1.1317592420667806,\n",
              "  1.4272992929222168,\n",
              "  1.3389254195014408,\n",
              "  2.0058506827187097,\n",
              "  1.7715912276177528,\n",
              "  1.7053090981329784,\n",
              "  1.273119766733618,\n",
              "  1.2645903954195463,\n",
              "  1.9612385537320356,\n",
              "  1.4716590860639265,\n",
              "  1.5777145844408116,\n",
              "  2.584948960960377,\n",
              "  1.4392917491892008,\n",
              "  1.319287102056625,\n",
              "  1.4237265731938766,\n",
              "  1.8602862904913782,\n",
              "  1.4529388029682806,\n",
              "  1.1984215478959244,\n",
              "  1.6706109906436855,\n",
              "  1.3856569681781365,\n",
              "  1.8008167925806498,\n",
              "  1.5736743355948497,\n",
              "  1.4299729748651446,\n",
              "  2.1055688292639205,\n",
              "  1.4952620641730152,\n",
              "  1.3620242349823046,\n",
              "  1.540557857201846,\n",
              "  1.5226848692236787,\n",
              "  1.293459223084363,\n",
              "  1.4777028859756633,\n",
              "  1.1368105109938904,\n",
              "  1.3086279790944384,\n",
              "  1.269113085619237,\n",
              "  1.5322707725763225,\n",
              "  1.3332075624036517,\n",
              "  1.507558485549488,\n",
              "  1.4686278591874,\n",
              "  1.341300666036808,\n",
              "  1.319769562157615,\n",
              "  1.6774562271083886,\n",
              "  1.1474012764748687,\n",
              "  1.319287102056625,\n",
              "  1.5728650404343092,\n",
              "  1.1328836926591555,\n",
              "  1.2761165219980004,\n",
              "  1.417901703622935,\n",
              "  1.355934328276106,\n",
              "  1.546744033302657,\n",
              "  1.3662244224803437,\n",
              "  1.6560670213972442,\n",
              "  1.5113542745679724,\n",
              "  2.0023564433863985,\n",
              "  1.5483895061438226,\n",
              "  1.467760644550703,\n",
              "  1.2168720518308382,\n",
              "  1.2850648580991957,\n",
              "  1.937726352564777,\n",
              "  1.1780624362746346,\n",
              "  1.355934328276106,\n",
              "  1.3929885377045959],\n",
              " [1.4440887321885298,\n",
              "  1.5163452224403982,\n",
              "  0.7740114242103147,\n",
              "  1.381162924549276,\n",
              "  0.9641907312982639,\n",
              "  1.0194535400267202,\n",
              "  1.517992373791206,\n",
              "  1.5251123031480007,\n",
              "  1.2489460255064826,\n",
              "  0.9734179298467597,\n",
              "  1.366608694433346,\n",
              "  1.2799743818807834,\n",
              "  1.1919798578222593,\n",
              "  1.0706839693942078,\n",
              "  1.2086096108165936,\n",
              "  1.4440887321885298,\n",
              "  1.197969375581096,\n",
              "  1.0308892198767887,\n",
              "  1.4751132109973435,\n",
              "  1.711335128869588,\n",
              "  1.032587835660297,\n",
              "  0.9274866865263769,\n",
              "  1.4172235259328727,\n",
              "  1.061847361876213,\n",
              "  1.1870855865335546,\n",
              "  1.5487728762293815]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}