{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_r_squared_jun_23_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesgabi/Doutorado/blob/master/ANN_%20better_resolution/PSD_histogram_CNN_B_r_squared_jun_23_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3eaf253-df34-41ca-bcdd-480082cfaecd"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.11-cp37-cp37m-manylinux2010_x86_64.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n",
            "Installing collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc8cad6-209b-4f85-f7cf-ca58c208ee49"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_fev_2020'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 73 (delta 37), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n",
            "/content/marquesgabi_fev_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9c2382-1439-4002-a503-aa1dd3d31aae"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 361, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 361 (delta 38), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (361/361), 165.33 MiB | 27.77 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[4] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142fa372-a1d5-44c6-d6b6-6af5640dd3fe"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 21.71 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN5MN5a_v4np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e644adf-37fa-4d5a-8734-c8c17d99d888"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     161  110.714561   51.852551  ...   20.482044    7.345936    0.306238\n",
            "1     164  136.295654  138.676971  ...    0.826294    0.224271    1.370613\n",
            "2     148  112.550041  131.703430  ...    1.668371    1.700511    1.501096\n",
            "3     137  112.978363   90.153061  ...    0.384837    0.472428    1.450530\n",
            "4     102  108.257980  114.384087  ...   79.114189   78.451370   78.540573\n",
            "5     174  126.749382  123.952431  ...  237.446716  222.672226  208.078766\n",
            "6     179  129.599762  111.378365  ...    1.192222    0.155832    1.346931\n",
            "7     154  202.429764  203.900833  ...  135.214890  150.446289  161.785141\n",
            "8     170  235.882523  180.998627  ...    0.944498    0.183945    1.356540\n",
            "9     103  170.148346  169.199356  ...  141.111694  145.387115  158.838333\n",
            "10    198  127.963356  136.271698  ...    1.322824    0.238751    1.315580\n",
            "11    159   30.389301   51.157543  ...  181.252625  190.131958  203.708160\n",
            "12    132  203.631775  226.118469  ...  143.313141  143.275497  145.449966\n",
            "13    187  135.097595  141.097717  ...  106.207642  101.056335   86.013298\n",
            "14    187   99.879692  120.252533  ...  253.093430  251.733109  251.670990\n",
            "15    128   48.216797   90.711914  ...    0.000000    0.462891    1.000000\n",
            "16    179  190.945877  187.007599  ...   99.802292  104.786209  107.547913\n",
            "17    120  241.406677  250.634460  ...  133.178894  138.545563  142.726669\n",
            "18    154  143.173569  146.396698  ...  170.578522  165.165314  158.223145\n",
            "19    143  149.596954  155.072525  ...   90.370926   97.175415   96.632599\n",
            "20    134  138.534210  155.601242  ...    1.000000    1.000000    1.000000\n",
            "21    104  142.547348  142.673096  ...    0.176036    0.853550    1.248521\n",
            "22    115   76.111755   80.076057  ...    0.803176    0.428355    1.973913\n",
            "23    148  170.689575  177.754578  ...  120.795479  132.448517  139.959839\n",
            "24    112  148.312500  150.750000  ...  150.312500  158.875000  168.750000\n",
            "25    136  182.086502  171.187729  ...  122.179932  124.752594  118.358994\n",
            "26    179  149.953369  149.315765  ...  253.640564  254.040207  253.039062\n",
            "27    158  141.171280  140.859467  ...  121.648773  128.185547  126.017944\n",
            "28    192  156.943130  137.461365  ...    1.417535    0.210069    1.334201\n",
            "29    156  169.301788  169.788300  ...  161.856018  170.746887  168.122299\n",
            "30    134  135.063507  134.559143  ...    1.495879    1.000000    1.000000\n",
            "31    108  163.529480  159.788757  ...   58.717419   57.850479   59.775032\n",
            "32    104  185.897949  185.405334  ...  157.479309  161.505936  162.491135\n",
            "33    170  165.911438  171.374969  ...  127.450653  140.047897  167.714890\n",
            "34    176   95.682327  100.397209  ...  130.429245  152.157028  147.332657\n",
            "35    159  138.732056  132.300888  ...  120.151260  123.452515  115.036942\n",
            "36    122  121.989784  120.850845  ...  104.839828  117.071213  122.969627\n",
            "37    175  108.441597   86.012794  ...   12.620800    5.360000    2.044800\n",
            "38    174  145.528748  152.576447  ...  177.814117  187.552399  196.146942\n",
            "39    115   83.538376   82.509407  ...  123.384117   87.792435   96.222679\n",
            "40    159  231.237122  244.730423  ...  131.266434  127.099670  160.170120\n",
            "41    139  206.175903  232.311096  ...    1.081103    0.841830    1.389938\n",
            "42    100   99.268799  102.081596  ...    1.056000    1.000000    1.000000\n",
            "43    168  165.833328  159.194443  ...    0.361111    0.694444    1.722222\n",
            "44    195  194.959503  186.581818  ...  206.247894  183.200012  192.794601\n",
            "45    155  157.416672  129.335312  ...    0.684246    0.297149    1.393923\n",
            "46    104  131.179001  112.322502  ...  182.008881  196.800323  200.072510\n",
            "47    176  164.527878  157.536163  ...    1.104339    0.153409    1.343492\n",
            "48    127  110.932167  109.789383  ...    0.182466    0.591915    1.489553\n",
            "49    104   69.607994   72.915688  ...    0.041420    0.915681    1.610947\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpQ1Pz0fX5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e79674a3-ffdc-4f39-95f3-6424adf29911"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "4cb26207-0460-4779-bb3b-6fff34772d36"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 22.55 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 32, 64, 128 '\n",
        "N1 = 200\n",
        "N2 = 10\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=32, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "dc405df4-86b9-4ecf-c005-fde148d5b8e6"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 22s 142ms/step - loss: 0.7939 - accuracy: 0.6252 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.4327 - accuracy: 0.7717 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.3400 - accuracy: 0.8185 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.1567 - accuracy: 0.9683 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.1170 - accuracy: 0.9715 - val_loss: 0.6934 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0832 - accuracy: 0.9611 - val_loss: 0.6948 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0929 - accuracy: 0.9510 - val_loss: 0.6960 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0445 - accuracy: 0.9782 - val_loss: 0.6947 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0365 - accuracy: 0.9911 - val_loss: 0.6941 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0508 - accuracy: 0.9806 - val_loss: 0.6952 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0180 - accuracy: 0.9973 - val_loss: 0.6973 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0395 - accuracy: 0.9897 - val_loss: 0.7016 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7503 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 7.8670e-04 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0034 - accuracy: 0.9979 - val_loss: 0.7215 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0165 - accuracy: 0.9901 - val_loss: 0.7301 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.0458 - accuracy: 0.9875 - val_loss: 0.7676 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.1373 - accuracy: 0.9682 - val_loss: 1.1844 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0762 - accuracy: 0.9762 - val_loss: 1.8234 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0695 - accuracy: 0.9715 - val_loss: 2.6762 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0176 - accuracy: 0.9990 - val_loss: 2.5404 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 2.0450 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3284 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0093 - accuracy: 0.9925 - val_loss: 2.5124 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0060 - accuracy: 0.9973 - val_loss: 2.0527 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0442 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9892 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.1027 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.3090 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 4.3482e-04 - accuracy: 1.0000 - val_loss: 2.4022 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 7.6707e-04 - accuracy: 1.0000 - val_loss: 2.5107 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 6.7419e-04 - accuracy: 1.0000 - val_loss: 2.5316 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9032 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 2.6288e-04 - accuracy: 1.0000 - val_loss: 1.4900 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 5.2560e-04 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 3.8631e-04 - accuracy: 1.0000 - val_loss: 1.1109 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 3.5160e-04 - accuracy: 1.0000 - val_loss: 1.1387 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 3.3682e-04 - accuracy: 1.0000 - val_loss: 1.0575 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 3.1152e-04 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 8.1256e-04 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.5170\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 2.0219e-04 - accuracy: 1.0000 - val_loss: 0.8879 - val_accuracy: 0.5306\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 2.0280e-04 - accuracy: 1.0000 - val_loss: 0.8275 - val_accuracy: 0.5646\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 2.3482e-04 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.5714\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.7641e-04 - accuracy: 1.0000 - val_loss: 0.9335 - val_accuracy: 0.5918\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 4.8574e-04 - accuracy: 1.0000 - val_loss: 1.0258 - val_accuracy: 0.5986\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 2.5040e-04 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.6054\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 2.1584e-04 - accuracy: 1.0000 - val_loss: 0.9851 - val_accuracy: 0.6190\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 1.4889e-04 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.6190\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 2.3397e-04 - accuracy: 1.0000 - val_loss: 1.0233 - val_accuracy: 0.6259\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 4.2150e-04 - accuracy: 1.0000 - val_loss: 1.1562 - val_accuracy: 0.6259\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.6425e-04 - accuracy: 1.0000 - val_loss: 1.0686 - val_accuracy: 0.6395\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.1164e-04 - accuracy: 1.0000 - val_loss: 0.8234 - val_accuracy: 0.6667\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 7.2587e-05 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.7687\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 8.8911e-05 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.8503\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 1.2562e-04 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.8980\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 1.3581e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9048\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 1.8147e-04 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9660\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.3141e-04 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9796\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.1047e-04 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9796\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.2456e-04 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9796\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 6.3455e-05 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9864\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 8.8954e-05 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9864\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 7.1193e-05 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9796\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.2099e-04 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9796\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 1.5821e-04 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9320\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.1546e-04 - accuracy: 1.0000 - val_loss: 0.5442 - val_accuracy: 0.8707\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 6.3111e-05 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9116\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.6134e-04 - accuracy: 1.0000 - val_loss: 1.4336 - val_accuracy: 0.7347\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 4.6321e-05 - accuracy: 1.0000 - val_loss: 2.2102 - val_accuracy: 0.6395\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 7.0299e-05 - accuracy: 1.0000 - val_loss: 2.3010 - val_accuracy: 0.6395\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 7.1804e-05 - accuracy: 1.0000 - val_loss: 2.0943 - val_accuracy: 0.6667\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 7.1565e-05 - accuracy: 1.0000 - val_loss: 2.0949 - val_accuracy: 0.6871\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 4.0887e-04 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9320\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.0073 - accuracy: 0.9966 - val_loss: 2.9707 - val_accuracy: 0.5238\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.0886 - accuracy: 0.9716 - val_loss: 88.3019 - val_accuracy: 0.5102\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 141.8221 - val_accuracy: 0.5102\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0224 - accuracy: 0.9884 - val_loss: 192.9786 - val_accuracy: 0.5102\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 188.1017 - val_accuracy: 0.5102\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 190.6160 - val_accuracy: 0.5102\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 181.6088 - val_accuracy: 0.5102\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 163.5093 - val_accuracy: 0.5102\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 154.7573 - val_accuracy: 0.5102\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 6.3359e-04 - accuracy: 1.0000 - val_loss: 144.7106 - val_accuracy: 0.5102\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 5.3057e-04 - accuracy: 1.0000 - val_loss: 128.0145 - val_accuracy: 0.5102\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 8.3187e-04 - accuracy: 1.0000 - val_loss: 109.5224 - val_accuracy: 0.5102\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 8.2878e-04 - accuracy: 1.0000 - val_loss: 94.3101 - val_accuracy: 0.5102\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 2.7434e-04 - accuracy: 1.0000 - val_loss: 80.1679 - val_accuracy: 0.5102\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 2.7625e-04 - accuracy: 1.0000 - val_loss: 65.4187 - val_accuracy: 0.5102\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 7.6150e-04 - accuracy: 1.0000 - val_loss: 52.7166 - val_accuracy: 0.5102\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.3494e-04 - accuracy: 1.0000 - val_loss: 45.3125 - val_accuracy: 0.5102\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 7.0813e-04 - accuracy: 1.0000 - val_loss: 39.9783 - val_accuracy: 0.5102\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 2.4013e-04 - accuracy: 1.0000 - val_loss: 40.1647 - val_accuracy: 0.5102\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 8.9172e-04 - accuracy: 1.0000 - val_loss: 47.5530 - val_accuracy: 0.5102\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 6.4977e-04 - accuracy: 1.0000 - val_loss: 55.1842 - val_accuracy: 0.5102\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 9.6026e-04 - accuracy: 1.0000 - val_loss: 51.3848 - val_accuracy: 0.5102\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 8.4932e-04 - accuracy: 1.0000 - val_loss: 46.9190 - val_accuracy: 0.5102\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 5.7428e-04 - accuracy: 1.0000 - val_loss: 45.7077 - val_accuracy: 0.5102\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 9.7021e-05 - accuracy: 1.0000 - val_loss: 41.4850 - val_accuracy: 0.5102\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.8310e-04 - accuracy: 1.0000 - val_loss: 36.7900 - val_accuracy: 0.5102\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 2.3518e-04 - accuracy: 1.0000 - val_loss: 34.3891 - val_accuracy: 0.5102\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 7.3424e-05 - accuracy: 1.0000 - val_loss: 31.7419 - val_accuracy: 0.5102\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.3005e-04 - accuracy: 1.0000 - val_loss: 28.6459 - val_accuracy: 0.5102\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.8484e-04 - accuracy: 1.0000 - val_loss: 25.2121 - val_accuracy: 0.5102\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 4.4768e-04 - accuracy: 1.0000 - val_loss: 34.7928 - val_accuracy: 0.5102\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 25.9278 - val_accuracy: 0.5102\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 25.9909 - val_accuracy: 0.5102\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 55.0724 - val_accuracy: 0.5102\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 91.1839 - val_accuracy: 0.5102\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 147.9729 - val_accuracy: 0.5102\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0119 - accuracy: 0.9919 - val_loss: 137.5668 - val_accuracy: 0.5102\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 7.8623e-04 - accuracy: 1.0000 - val_loss: 83.3324 - val_accuracy: 0.5102\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.1084e-04 - accuracy: 1.0000 - val_loss: 55.1989 - val_accuracy: 0.5102\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 7.1867e-05 - accuracy: 1.0000 - val_loss: 46.1323 - val_accuracy: 0.5102\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 39.3747 - val_accuracy: 0.5102\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 3.4745e-04 - accuracy: 1.0000 - val_loss: 32.9631 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 7.9830e-04 - accuracy: 1.0000 - val_loss: 26.4923 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 2.2354e-04 - accuracy: 1.0000 - val_loss: 22.7741 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 1.6888e-04 - accuracy: 1.0000 - val_loss: 20.1322 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 1.7039e-04 - accuracy: 1.0000 - val_loss: 18.2309 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 8.6930e-05 - accuracy: 1.0000 - val_loss: 17.5687 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 1.3002e-04 - accuracy: 1.0000 - val_loss: 17.1596 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 2.6046e-04 - accuracy: 1.0000 - val_loss: 17.6694 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 2.2479e-04 - accuracy: 1.0000 - val_loss: 12.9058 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 9.7489e-05 - accuracy: 1.0000 - val_loss: 10.7300 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 6.6815e-05 - accuracy: 1.0000 - val_loss: 9.5866 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 6.2317e-05 - accuracy: 1.0000 - val_loss: 8.5868 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 4.2939e-04 - accuracy: 1.0000 - val_loss: 14.0112 - val_accuracy: 0.5102\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 7.8775e-05 - accuracy: 1.0000 - val_loss: 19.8788 - val_accuracy: 0.5102\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 9.3921e-05 - accuracy: 1.0000 - val_loss: 20.8811 - val_accuracy: 0.5102\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 6.1318e-05 - accuracy: 1.0000 - val_loss: 19.1909 - val_accuracy: 0.5102\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 4.3240e-05 - accuracy: 1.0000 - val_loss: 16.9252 - val_accuracy: 0.5102\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 6.3004e-05 - accuracy: 1.0000 - val_loss: 15.0856 - val_accuracy: 0.5102\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 1.0279e-04 - accuracy: 1.0000 - val_loss: 13.8968 - val_accuracy: 0.5102\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 5.9512e-05 - accuracy: 1.0000 - val_loss: 12.2429 - val_accuracy: 0.5102\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 3.3693e-05 - accuracy: 1.0000 - val_loss: 9.3328 - val_accuracy: 0.5102\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 2.9699e-05 - accuracy: 1.0000 - val_loss: 7.7384 - val_accuracy: 0.5170\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 3.7703e-05 - accuracy: 1.0000 - val_loss: 6.4378 - val_accuracy: 0.5170\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 3.3577e-05 - accuracy: 1.0000 - val_loss: 5.1136 - val_accuracy: 0.5374\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.6308e-05 - accuracy: 1.0000 - val_loss: 3.8134 - val_accuracy: 0.5850\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 6.2063e-05 - accuracy: 1.0000 - val_loss: 2.2901 - val_accuracy: 0.6531\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.8977e-04 - accuracy: 1.0000 - val_loss: 1.7133 - val_accuracy: 0.7279\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 3.7363e-05 - accuracy: 1.0000 - val_loss: 1.5265 - val_accuracy: 0.7687\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 4.3602e-05 - accuracy: 1.0000 - val_loss: 1.3230 - val_accuracy: 0.7891\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 2.2002e-05 - accuracy: 1.0000 - val_loss: 1.1572 - val_accuracy: 0.8299\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 2.1409e-05 - accuracy: 1.0000 - val_loss: 1.0329 - val_accuracy: 0.8503\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 2.1895e-05 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.8571\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 7.8885e-05 - accuracy: 1.0000 - val_loss: 0.5390 - val_accuracy: 0.8980\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 3.7527e-05 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9184\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 9.1446e-05 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9524\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.4809e-05 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9592\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.9097e-05 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9592\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 2.2018e-05 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9592\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 2.5502e-05 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9592\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 2.8331e-05 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9592\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.7251e-05 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9592\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 4.4689e-05 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9592\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 3.1750e-05 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9592\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.4177e-05 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9592\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 2.8959e-05 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9592\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 2.8608e-05 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9592\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 1.5878e-05 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9592\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 9.9977e-06 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9592\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 4.6501e-05 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9524\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 3.7293e-05 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9524\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.2882e-05 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9524\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 4.0559e-05 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9524\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 5.7905e-05 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9456\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 3.1761e-05 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9524\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 1.7414e-05 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9524\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.1962e-05 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9524\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 4.6512e-05 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9524\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 1.5847e-04 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9728\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 5.3073e-05 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9728\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.3198e-05 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.8844\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 2.5812e-05 - accuracy: 1.0000 - val_loss: 0.6269 - val_accuracy: 0.8435\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.4922e-05 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.8503\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.6684e-05 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.8639\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 6.9056e-06 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.8980\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 9.3870e-05 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9456\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 6.9522e-05 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9456\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 5.3683e-05 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9252\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.1992e-05 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9252\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 8.1471e-06 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9320\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 3.5277e-05 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9456\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 1.7441e-05 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9456\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 1.0881e-05 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9456\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 2.7694e-04 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9728\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 2.9277e-05 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9524\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 2.0301e-05 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9456\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 1.0603e-05 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9456\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 2.1147e-05 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpf0XlSARX78",
        "outputId": "973848c3-e563-4e9f-cfad-c1aefc7c5285"
      },
      "source": [
        "pred_test= model.predict_classes(X_test)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predict   0   1\n",
            "Actual         \n",
            "0        61  11\n",
            "1         1  74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFNNrlWV9tH",
        "outputId": "50ad64ab-8f76-4cd2-f0b8-9acdb86b3328"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QISvYcJBgWbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091e3322-9d6e-4e32-96df-ab2541b71b93"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[4] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  prediction = model.predict_classes(result)\n",
        "  loc_grao =[];k=0\n",
        "  for i in prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0   147.0  221.587311  202.390015  ...    0.963719    1.000000    1.154195\n",
            "3   159.0  171.473404  239.484482  ...    0.145327    1.383213    1.021043\n",
            "6   190.0  100.268700   92.051964  ...  132.283752  129.448959  134.117996\n",
            "7   158.0   99.483093  100.108948  ...   40.292583   85.311974  114.493835\n",
            "12  116.0  168.456604  131.580261  ...    1.000000    1.000000    1.000000\n",
            "13  165.0  114.177002   94.075409  ...  180.909348  198.985245  213.409775\n",
            "15  138.0  166.765991  167.702789  ...  180.735565  190.348038  197.816620\n",
            "17  122.0  198.316315  198.984406  ...  133.372742  130.738235  133.769135\n",
            "27  108.0  132.481476  127.035660  ...  206.399170  210.556915  208.486969\n",
            "28  100.0  138.408005  134.318420  ...  140.585587  138.001602  138.399994\n",
            "29  109.0  177.572693  167.623337  ...  142.489426  127.141991  111.611649\n",
            "30  133.0  189.229919  190.620514  ...  154.667587  147.905807  144.548477\n",
            "34  115.0  233.839844  193.640228  ...  150.595596  187.822983  186.127411\n",
            "39  178.0  162.677460  164.194931  ...  130.715195  134.145065  136.627075\n",
            "43  126.0  207.716064  209.320984  ...  142.012344  144.814819  156.345673\n",
            "48  144.0  226.139679  236.997696  ...  170.293991  171.173615  168.292450\n",
            "3   183.0  184.171661  176.667725  ...  225.111694  189.956909  155.179535\n",
            "7   163.0  155.296844  151.307465  ...  127.323196  160.609238  186.110168\n",
            "9   160.0  118.046249  111.300621  ...  176.013733  180.861252  186.125000\n",
            "10  172.0  179.205521  175.857773  ...  198.968628  189.122772  182.513260\n",
            "17  194.0  249.523956  244.039642  ...   80.785622   87.925911   89.721420\n",
            "28  125.0  134.335434  140.433212  ...  176.307861  187.949249  194.463821\n",
            "31  198.0   57.852764   62.372303  ...    1.000000    1.412305    1.603306\n",
            "34  187.0  195.268295  185.889862  ...  144.393723  147.688934  156.810455\n",
            "36  151.0  188.313065  238.253677  ...    0.484716    1.365510    1.013508\n",
            "37  126.0  133.271606  144.506180  ...  146.543213  138.234573  113.987656\n",
            "38  150.0   99.657959  134.555740  ...  126.913948  118.598587  115.561073\n",
            "40  166.0  161.704880  163.249374  ...  139.972839  145.134247  144.843369\n",
            "45  139.0  151.950516  145.864594  ...  137.610886  126.772217  121.948029\n",
            "47  146.0  175.287857  191.048782  ...  132.094025  135.255951  130.650589\n",
            "48  187.0  183.522171  187.754715  ...  167.466080  172.736847  177.994476\n",
            "\n",
            "[31 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "dd9b85b6-3208-4991-9d16-4a04a7ac37e7"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_paper_fev_2021'...\n",
            "remote: Enumerating objects: 655, done.\u001b[K\n",
            "remote: Counting objects: 100% (416/416), done.\u001b[K\n",
            "remote: Compressing objects: 100% (414/414), done.\u001b[K\n",
            "remote: Total 655 (delta 260), reused 0 (delta 0), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (655/655), 5.44 MiB | 10.54 MiB/s, done.\n",
            "Resolving deltas: 100% (397/397), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "a6d45532-4732-43a0-f357-2d7684121ce1"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "%cd marquesgabi_out_2020\n",
        "PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "PSD_new = pd.read_csv(PSD_imageJ)\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_out_2020'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 146 (delta 75), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 1.00 MiB | 7.08 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020\n",
            "   Juntas   Area\n",
            "0       1  2.001\n",
            "1       2  0.820\n",
            "2       3  1.270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "PekBHQOT_6CP",
        "outputId": "f77bd565-d8f9-49cc-a6cc-71b4da3f0cc5"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>147.0</td>\n",
              "      <td>221.587311</td>\n",
              "      <td>202.390015</td>\n",
              "      <td>144.802719</td>\n",
              "      <td>103.083900</td>\n",
              "      <td>114.791389</td>\n",
              "      <td>137.580505</td>\n",
              "      <td>148.963730</td>\n",
              "      <td>138.746033</td>\n",
              "      <td>173.387756</td>\n",
              "      <td>198.770981</td>\n",
              "      <td>192.882111</td>\n",
              "      <td>174.578262</td>\n",
              "      <td>146.444443</td>\n",
              "      <td>110.222229</td>\n",
              "      <td>150.705215</td>\n",
              "      <td>247.312927</td>\n",
              "      <td>248.739243</td>\n",
              "      <td>250.517029</td>\n",
              "      <td>253.573730</td>\n",
              "      <td>254.154205</td>\n",
              "      <td>253.630371</td>\n",
              "      <td>254.210876</td>\n",
              "      <td>254.394577</td>\n",
              "      <td>254.462585</td>\n",
              "      <td>254.129257</td>\n",
              "      <td>253.761887</td>\n",
              "      <td>253.360550</td>\n",
              "      <td>252.018143</td>\n",
              "      <td>230.376450</td>\n",
              "      <td>165.156464</td>\n",
              "      <td>100.993202</td>\n",
              "      <td>108.907043</td>\n",
              "      <td>108.210884</td>\n",
              "      <td>119.961449</td>\n",
              "      <td>130.750580</td>\n",
              "      <td>142.374146</td>\n",
              "      <td>162.575974</td>\n",
              "      <td>176.485275</td>\n",
              "      <td>176.750580</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.936508</td>\n",
              "      <td>0.954648</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.417234</td>\n",
              "      <td>0.179138</td>\n",
              "      <td>1.083900</td>\n",
              "      <td>1.365079</td>\n",
              "      <td>1.004535</td>\n",
              "      <td>0.079365</td>\n",
              "      <td>0.963719</td>\n",
              "      <td>1.598639</td>\n",
              "      <td>1.317460</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.979592</td>\n",
              "      <td>0.081633</td>\n",
              "      <td>0.081633</td>\n",
              "      <td>0.979592</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.417234</td>\n",
              "      <td>0.179138</td>\n",
              "      <td>1.083900</td>\n",
              "      <td>1.092971</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.963719</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.154195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>159.0</td>\n",
              "      <td>171.473404</td>\n",
              "      <td>239.484482</td>\n",
              "      <td>202.451447</td>\n",
              "      <td>180.314651</td>\n",
              "      <td>191.642456</td>\n",
              "      <td>199.651062</td>\n",
              "      <td>199.607452</td>\n",
              "      <td>199.671204</td>\n",
              "      <td>187.115372</td>\n",
              "      <td>160.734924</td>\n",
              "      <td>137.927643</td>\n",
              "      <td>138.962326</td>\n",
              "      <td>136.229736</td>\n",
              "      <td>144.593948</td>\n",
              "      <td>139.053192</td>\n",
              "      <td>144.166290</td>\n",
              "      <td>153.869263</td>\n",
              "      <td>139.815399</td>\n",
              "      <td>175.771530</td>\n",
              "      <td>237.543060</td>\n",
              "      <td>231.119141</td>\n",
              "      <td>235.953445</td>\n",
              "      <td>241.911819</td>\n",
              "      <td>242.637894</td>\n",
              "      <td>246.830536</td>\n",
              "      <td>247.788818</td>\n",
              "      <td>236.648132</td>\n",
              "      <td>230.472946</td>\n",
              "      <td>128.422333</td>\n",
              "      <td>166.145035</td>\n",
              "      <td>241.620560</td>\n",
              "      <td>220.501129</td>\n",
              "      <td>215.138351</td>\n",
              "      <td>208.737579</td>\n",
              "      <td>209.016815</td>\n",
              "      <td>199.643906</td>\n",
              "      <td>146.795364</td>\n",
              "      <td>142.146988</td>\n",
              "      <td>151.483353</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.361971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.743009</td>\n",
              "      <td>0.997231</td>\n",
              "      <td>0.815276</td>\n",
              "      <td>0.890669</td>\n",
              "      <td>1.008860</td>\n",
              "      <td>1.234445</td>\n",
              "      <td>0.145327</td>\n",
              "      <td>1.383213</td>\n",
              "      <td>1.258059</td>\n",
              "      <td>5.846406</td>\n",
              "      <td>1.463827</td>\n",
              "      <td>2.008346</td>\n",
              "      <td>0.717258</td>\n",
              "      <td>1.030735</td>\n",
              "      <td>1.782129</td>\n",
              "      <td>0.951663</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350896</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.898066</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.008860</td>\n",
              "      <td>1.234445</td>\n",
              "      <td>0.145327</td>\n",
              "      <td>1.383213</td>\n",
              "      <td>1.021043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>190.0</td>\n",
              "      <td>100.268700</td>\n",
              "      <td>92.051964</td>\n",
              "      <td>67.384483</td>\n",
              "      <td>47.182381</td>\n",
              "      <td>55.210743</td>\n",
              "      <td>76.605095</td>\n",
              "      <td>91.000763</td>\n",
              "      <td>96.252411</td>\n",
              "      <td>96.777061</td>\n",
              "      <td>92.494957</td>\n",
              "      <td>85.344040</td>\n",
              "      <td>87.350243</td>\n",
              "      <td>85.625153</td>\n",
              "      <td>107.780487</td>\n",
              "      <td>102.243973</td>\n",
              "      <td>87.412071</td>\n",
              "      <td>73.040337</td>\n",
              "      <td>78.188919</td>\n",
              "      <td>81.907257</td>\n",
              "      <td>77.628471</td>\n",
              "      <td>64.611183</td>\n",
              "      <td>58.859386</td>\n",
              "      <td>80.821159</td>\n",
              "      <td>95.967300</td>\n",
              "      <td>102.403091</td>\n",
              "      <td>98.745033</td>\n",
              "      <td>115.027573</td>\n",
              "      <td>98.106812</td>\n",
              "      <td>100.138382</td>\n",
              "      <td>96.405205</td>\n",
              "      <td>75.140060</td>\n",
              "      <td>55.151581</td>\n",
              "      <td>58.728081</td>\n",
              "      <td>79.965530</td>\n",
              "      <td>98.557114</td>\n",
              "      <td>100.809074</td>\n",
              "      <td>96.360222</td>\n",
              "      <td>95.267029</td>\n",
              "      <td>84.482880</td>\n",
              "      <td>...</td>\n",
              "      <td>141.286972</td>\n",
              "      <td>134.173615</td>\n",
              "      <td>138.929626</td>\n",
              "      <td>146.766312</td>\n",
              "      <td>154.182922</td>\n",
              "      <td>156.266708</td>\n",
              "      <td>152.550690</td>\n",
              "      <td>147.557877</td>\n",
              "      <td>139.481781</td>\n",
              "      <td>129.641769</td>\n",
              "      <td>126.677330</td>\n",
              "      <td>134.941711</td>\n",
              "      <td>155.616058</td>\n",
              "      <td>134.597107</td>\n",
              "      <td>126.169189</td>\n",
              "      <td>120.393456</td>\n",
              "      <td>120.850182</td>\n",
              "      <td>118.856827</td>\n",
              "      <td>127.872131</td>\n",
              "      <td>130.052948</td>\n",
              "      <td>141.950241</td>\n",
              "      <td>157.195450</td>\n",
              "      <td>174.547928</td>\n",
              "      <td>140.277100</td>\n",
              "      <td>132.070343</td>\n",
              "      <td>135.619598</td>\n",
              "      <td>141.224472</td>\n",
              "      <td>142.635010</td>\n",
              "      <td>141.835907</td>\n",
              "      <td>130.016510</td>\n",
              "      <td>144.991226</td>\n",
              "      <td>157.428467</td>\n",
              "      <td>164.159225</td>\n",
              "      <td>161.467346</td>\n",
              "      <td>158.564880</td>\n",
              "      <td>156.357651</td>\n",
              "      <td>142.684860</td>\n",
              "      <td>132.283752</td>\n",
              "      <td>129.448959</td>\n",
              "      <td>134.117996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>158.0</td>\n",
              "      <td>99.483093</td>\n",
              "      <td>100.108948</td>\n",
              "      <td>182.102707</td>\n",
              "      <td>225.514969</td>\n",
              "      <td>242.705658</td>\n",
              "      <td>251.720245</td>\n",
              "      <td>239.680344</td>\n",
              "      <td>185.759171</td>\n",
              "      <td>176.704849</td>\n",
              "      <td>183.956573</td>\n",
              "      <td>182.020187</td>\n",
              "      <td>180.298996</td>\n",
              "      <td>171.202057</td>\n",
              "      <td>152.456345</td>\n",
              "      <td>170.516586</td>\n",
              "      <td>222.757553</td>\n",
              "      <td>230.638672</td>\n",
              "      <td>231.374466</td>\n",
              "      <td>235.176254</td>\n",
              "      <td>234.322861</td>\n",
              "      <td>201.033005</td>\n",
              "      <td>146.912521</td>\n",
              "      <td>195.041641</td>\n",
              "      <td>195.457947</td>\n",
              "      <td>189.602783</td>\n",
              "      <td>177.713028</td>\n",
              "      <td>164.639465</td>\n",
              "      <td>146.302994</td>\n",
              "      <td>125.463860</td>\n",
              "      <td>103.770866</td>\n",
              "      <td>114.719917</td>\n",
              "      <td>172.444000</td>\n",
              "      <td>228.075958</td>\n",
              "      <td>218.657593</td>\n",
              "      <td>177.670410</td>\n",
              "      <td>171.451843</td>\n",
              "      <td>176.215820</td>\n",
              "      <td>177.779358</td>\n",
              "      <td>177.971802</td>\n",
              "      <td>...</td>\n",
              "      <td>88.678741</td>\n",
              "      <td>96.081390</td>\n",
              "      <td>96.490135</td>\n",
              "      <td>99.029800</td>\n",
              "      <td>88.979172</td>\n",
              "      <td>58.351387</td>\n",
              "      <td>48.346096</td>\n",
              "      <td>79.905457</td>\n",
              "      <td>112.794106</td>\n",
              "      <td>120.892159</td>\n",
              "      <td>124.599266</td>\n",
              "      <td>121.897141</td>\n",
              "      <td>120.248840</td>\n",
              "      <td>116.593330</td>\n",
              "      <td>110.590118</td>\n",
              "      <td>111.189713</td>\n",
              "      <td>102.318390</td>\n",
              "      <td>82.656784</td>\n",
              "      <td>62.496552</td>\n",
              "      <td>66.168404</td>\n",
              "      <td>65.745552</td>\n",
              "      <td>68.462425</td>\n",
              "      <td>72.746826</td>\n",
              "      <td>73.742188</td>\n",
              "      <td>73.351219</td>\n",
              "      <td>76.283127</td>\n",
              "      <td>83.506012</td>\n",
              "      <td>86.462914</td>\n",
              "      <td>89.749725</td>\n",
              "      <td>95.376366</td>\n",
              "      <td>98.364845</td>\n",
              "      <td>98.881104</td>\n",
              "      <td>97.983810</td>\n",
              "      <td>73.457619</td>\n",
              "      <td>48.431976</td>\n",
              "      <td>44.976448</td>\n",
              "      <td>39.461945</td>\n",
              "      <td>40.292583</td>\n",
              "      <td>85.311974</td>\n",
              "      <td>114.493835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>116.0</td>\n",
              "      <td>168.456604</td>\n",
              "      <td>131.580261</td>\n",
              "      <td>70.086800</td>\n",
              "      <td>76.795471</td>\n",
              "      <td>79.537453</td>\n",
              "      <td>78.638527</td>\n",
              "      <td>80.363846</td>\n",
              "      <td>80.868011</td>\n",
              "      <td>76.759811</td>\n",
              "      <td>75.350769</td>\n",
              "      <td>70.164085</td>\n",
              "      <td>61.390011</td>\n",
              "      <td>54.004757</td>\n",
              "      <td>46.175980</td>\n",
              "      <td>44.267536</td>\n",
              "      <td>50.843040</td>\n",
              "      <td>55.721756</td>\n",
              "      <td>53.354336</td>\n",
              "      <td>50.210461</td>\n",
              "      <td>49.166470</td>\n",
              "      <td>47.651604</td>\n",
              "      <td>46.643276</td>\n",
              "      <td>47.883469</td>\n",
              "      <td>46.719376</td>\n",
              "      <td>44.321045</td>\n",
              "      <td>59.608803</td>\n",
              "      <td>85.137924</td>\n",
              "      <td>94.214020</td>\n",
              "      <td>153.841843</td>\n",
              "      <td>117.881088</td>\n",
              "      <td>71.121284</td>\n",
              "      <td>76.161713</td>\n",
              "      <td>75.852554</td>\n",
              "      <td>76.108208</td>\n",
              "      <td>72.833527</td>\n",
              "      <td>69.212837</td>\n",
              "      <td>67.718185</td>\n",
              "      <td>59.601665</td>\n",
              "      <td>46.156960</td>\n",
              "      <td>...</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>1.130797</td>\n",
              "      <td>1.890606</td>\n",
              "      <td>1.535077</td>\n",
              "      <td>1.539833</td>\n",
              "      <td>1.854935</td>\n",
              "      <td>2.032105</td>\n",
              "      <td>1.931034</td>\n",
              "      <td>1.871581</td>\n",
              "      <td>1.392390</td>\n",
              "      <td>1.310345</td>\n",
              "      <td>0.877527</td>\n",
              "      <td>0.008323</td>\n",
              "      <td>0.560048</td>\n",
              "      <td>1.353151</td>\n",
              "      <td>1.137931</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.177170</td>\n",
              "      <td>1.537455</td>\n",
              "      <td>1.485137</td>\n",
              "      <td>0.840666</td>\n",
              "      <td>0.167658</td>\n",
              "      <td>0.983353</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.142687</td>\n",
              "      <td>1.312723</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>1.243757</td>\n",
              "      <td>1.180737</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Width           0           1  ...         781         782         783\n",
              "0   147.0  221.587311  202.390015  ...    0.963719    1.000000    1.154195\n",
              "3   159.0  171.473404  239.484482  ...    0.145327    1.383213    1.021043\n",
              "6   190.0  100.268700   92.051964  ...  132.283752  129.448959  134.117996\n",
              "7   158.0   99.483093  100.108948  ...   40.292583   85.311974  114.493835\n",
              "12  116.0  168.456604  131.580261  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "Area = np.array(PSD_new['Area'])\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J705kDqsE8f",
        "outputId": "64e5c0b5-d700-42c9-d3c6-694e53fb1adc"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wCFDX8esLoQ"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn-F050Hr9Ui"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Vfk_fNXGDK5_",
        "outputId": "6eab0c95-c525-4aa3-c4e8-a4bf748b89c1"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc17547ea10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "386d74e6-b42a-4172-eab3-8ee17844121b"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.07368421, 0.2       , 0.41052632, 0.75789474, 0.88421053,\n",
              "         0.96842105, 0.97894737, 0.97894737, 0.98947368, 1.        ],\n",
              "        [0.03225806, 0.19354839, 0.4516129 , 0.70967742, 0.80645161,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.75356807, 0.90995518, 1.06634229, 1.22272941, 1.37911652,\n",
              "        1.53550363, 1.69189074, 1.84827785, 2.00466497, 2.16105208,\n",
              "        2.31743919]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9xENlBUUxfTu",
        "outputId": "aa5b59c4-968a-469e-d666-46e809ba8fe3"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r_squared = 0.9880826834483198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "1ad40645-6418-4b8e-ec0d-af5f915b2fb6"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_13a16a6a-e6af-4921-b611-a70474c468d3\", \"output.xlsx\", 5149)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "-KukfpGTTKlj",
        "outputId": "d536ac2a-ce12-4a17-ae12-8046aa47f385"
      },
      "source": [
        "df"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.988083</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.278604</td>\n",
              "      <td>3 layers of Convolution: 32, 64, 128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    N1  N2  ...  loss test                                Details\n",
              "0  200  10  ...   0.278604  3 layers of Convolution: 32, 64, 128 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "ZZHa1j4HT9Dq",
        "outputId": "44084e84-497c-43fb-e22c-964f2d4c9d2b"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.75356807 0.90995518 1.06634229 1.22272941 1.37911652 1.53550363\n",
            " 1.69189074 1.84827785 2.00466497 2.16105208 2.31743919]\n",
            "[[ 7.36842105 12.63157895 21.05263158 34.73684211 12.63157895  8.42105263\n",
            "   1.05263158  0.          1.05263158  1.05263158]\n",
            " [ 3.22580645 16.12903226 25.80645161 25.80645161  9.67741935 19.35483871\n",
            "   0.          0.          0.          0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o_vDGeWUwIZ",
        "outputId": "509de9f3-6f3b-47c2-f0bf-c9e89b60df69"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200.00000000000003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "KcH52-6iJQ8t",
        "outputId": "957733a1-8633-4d4c-8191-8200ab3b77f0"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc16b43c610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r11AxFK_JIii",
        "outputId": "9b282f7e-9a07-4a61-c5a1-20701536d735"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.59616801403081,\n",
              "  1.0217907939900581,\n",
              "  1.2716187407449044,\n",
              "  1.104429030701514,\n",
              "  1.2163487785097904,\n",
              "  1.6013445735058454,\n",
              "  1.1715597420637607,\n",
              "  1.2534662333717612,\n",
              "  1.2676073151634049,\n",
              "  1.309600575274104,\n",
              "  1.292966945531582,\n",
              "  1.7658322811231006,\n",
              "  1.3564037533648712,\n",
              "  1.2407040781688483,\n",
              "  2.130217298173151,\n",
              "  1.4228319915327,\n",
              "  1.0651086490865755,\n",
              "  1.3008210311003705,\n",
              "  1.336545951796433,\n",
              "  0.8927754224911278,\n",
              "  1.4494292838262302,\n",
              "  1.4052738287907582,\n",
              "  1.6421697097891788,\n",
              "  1.2329833804288621,\n",
              "  1.19042665178928,\n",
              "  1.1682948223612457,\n",
              "  1.1518314137121108,\n",
              "  0.9607802401865855,\n",
              "  2.317439190074449,\n",
              "  1.0591147430338594,\n",
              "  1.4308630919602832,\n",
              "  0.7535680705496237,\n",
              "  0.8608283307581511,\n",
              "  1.2776122636975893,\n",
              "  1.3745862957220916,\n",
              "  1.259546137598783,\n",
              "  1.2978813187979172,\n",
              "  1.2412170838050638,\n",
              "  1.6009469708743893,\n",
              "  1.3149369953539032,\n",
              "  1.417901703622935,\n",
              "  1.2478669653497139,\n",
              "  1.1055812783082735,\n",
              "  0.9561307405997607,\n",
              "  0.9487783503683882,\n",
              "  1.1238565871041026,\n",
              "  1.2058356273089446,\n",
              "  1.2801012827406097,\n",
              "  0.8733100751144249,\n",
              "  0.9194732501297403,\n",
              "  1.6425573339441792,\n",
              "  1.085826790250066,\n",
              "  1.0639125693728595,\n",
              "  1.0875842666474016,\n",
              "  1.417901703622935,\n",
              "  1.550443891425932,\n",
              "  0.7825779328716171,\n",
              "  1.4690612745308145,\n",
              "  1.053086721720641,\n",
              "  1.2676073151634049,\n",
              "  0.7744003006005755,\n",
              "  1.3787482149724068,\n",
              "  1.363892581861956,\n",
              "  1.299352006316543,\n",
              "  1.2870449283923413,\n",
              "  1.11817763925502,\n",
              "  0.9474354220939228,\n",
              "  1.5218484589055707,\n",
              "  1.3526437911676632,\n",
              "  1.1556938532445284,\n",
              "  1.6013445735058454,\n",
              "  1.274619025074578,\n",
              "  1.422384489715834,\n",
              "  1.3408259533459403,\n",
              "  1.172646028567008,\n",
              "  1.1490645795125545,\n",
              "  1.459060149136146,\n",
              "  1.2483770274864237,\n",
              "  1.336545951796433,\n",
              "  0.9601174044814821,\n",
              "  1.4867225193896279,\n",
              "  1.4277452542806772,\n",
              "  1.35028849808504,\n",
              "  0.7560982446653928,\n",
              "  1.259040600296622,\n",
              "  1.13456827900627,\n",
              "  1.6549133695530214,\n",
              "  1.1204526724091788,\n",
              "  1.1176081573544434,\n",
              "  0.9153095762832032,\n",
              "  1.1639273497938836,\n",
              "  1.3066806149514323,\n",
              "  1.1529362882239027,\n",
              "  1.3047303442899274,\n",
              "  1.3066806149514323],\n",
              " [1.165815279659191,\n",
              "  1.3422976015132204,\n",
              "  1.5114940036320106,\n",
              "  1.3155072111897816,\n",
              "  1.1284628622646895,\n",
              "  1.3699247827188596,\n",
              "  1.1212180551421778,\n",
              "  1.0228797448976787,\n",
              "  0.93024509869626,\n",
              "  0.8004037157725786,\n",
              "  0.9892540314090146,\n",
              "  1.1273946542393656,\n",
              "  0.9343483792851481,\n",
              "  1.6230992870014183,\n",
              "  1.086709274924659,\n",
              "  1.217325365035155,\n",
              "  1.5824421746700241,\n",
              "  1.3437283036578398,\n",
              "  1.253101952579379,\n",
              "  1.4199518446155939,\n",
              "  1.67318729631257,\n",
              "  1.0710058308623602,\n",
              "  1.6228780449258868,\n",
              "  1.6043482821829942,\n",
              "  1.244803520566465,\n",
              "  1.0297427721491643,\n",
              "  1.2987715627398513,\n",
              "  1.466869307255598,\n",
              "  1.079957821936167,\n",
              "  1.28852841031114,\n",
              "  1.6275245726746708]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8",
        "outputId": "51a435e6-0cef-4ac7-a452-0c75901535d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4,1.6, 1.8,2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc16aba48d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm",
        "outputId": "b71219a3-de92-41b8-b014-699a03fd18e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs",
        "outputId": "706e4592-9eb2-4dd7-e365-2145c8532200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10.52631579, 24.21052632, 36.84210526, 14.73684211,  7.36842105,\n",
              "        0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx",
        "outputId": "b61810cd-56a0-47aa-ce63-22042230ed0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bins_list"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC",
        "outputId": "d0bde7d1-11bc-47b4-8160-ed463abfbc1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "      <th>0.8</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.4</th>\n",
              "      <th>1.6</th>\n",
              "      <th>1.8</th>\n",
              "      <th>2.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.988083</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.278604</td>\n",
              "      <td>3 layers of Convolution: 32, 64, 128</td>\n",
              "      <td>12.903226</td>\n",
              "      <td>29.032258</td>\n",
              "      <td>29.032258</td>\n",
              "      <td>12.903226</td>\n",
              "      <td>16.129032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    N1  N2       R^2  acc train  ...        1.4        1.6  1.8  2.0\n",
              "0  200  10  0.988083        1.0  ...  12.903226  16.129032  0.0  0.0\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2",
        "outputId": "a7a81395-6a62-4cdd-8210-bd9a150a91c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        }
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_de2e8e57-13e2-4f59-ba5a-14d59376ff36\", \"output.xlsx\", 5270)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}